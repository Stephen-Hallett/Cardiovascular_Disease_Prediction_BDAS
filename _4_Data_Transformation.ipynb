{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 22:19:35 WARN Utils: Your hostname, Stephens-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.8 instead (on interface en0)\n",
      "23/10/11 22:19:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/11 22:19:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/11 22:19:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/10/11 22:19:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/10/11 22:19:44 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------------------+-----------+-------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+-------+-------------------+----------------+-------------------+---------+----------------------------+--------------------------------+-------------------------------+------------------------------+------------------+-------------------------+-----------------------+----------------------------------+-----------------------+-----------------------------+\n",
      "|age|sex|resting_blood_pressure|cholesterol|fasting_blood_sugar|rest_ecg_type|max_heart_rate_achieved|exercise_induced_angina|st_depression|num_major_vessels|target|retired|high_blood_pressure|vessels_coloured|non_zero_depression|partition|chest_pain_type_asymptomatic|chest_pain_type_non-anginal_pain|chest_pain_type_atypical_angina|chest_pain_type_typical_angina|st_slope_type_flat|st_slope_type_downsloping|st_slope_type_upsloping|thalassemia_type_reversible_defect|thalassemia_type_normal|thalassemia_type_fixed_defect|\n",
      "+---+---+----------------------+-----------+-------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+-------+-------------------+----------------+-------------------+---------+----------------------------+--------------------------------+-------------------------------+------------------------------+------------------+-------------------------+-----------------------+----------------------------------+-----------------------+-----------------------------+\n",
      "| 29|  1|                   130|        204|                  0|            0|                    202|                      0|          0.0|                0|     1|      0|                  1|               0|                  0|    train|                           0|                               0|                              1|                             0|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "| 34|  0|                   118|        210|                  0|            1|                    192|                      0|          0.7|                0|     1|      0|                  0|               0|                  1|    train|                           0|                               0|                              1|                             0|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "| 34|  1|                   118|        182|                  0|            0|                    174|                      0|          0.0|                0|     1|      0|                  0|               0|                  0|    train|                           0|                               0|                              0|                             1|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "| 35|  1|                   120|        198|                  0|            1|                    130|                      1|          1.6|                0|     0|      0|                  0|               0|                  1|    train|                           1|                               0|                              0|                             0|                 1|                        0|                      0|                                 1|                      0|                            0|\n",
      "| 35|  0|                   138|        183|                  0|            1|                    182|                      0|          1.4|                0|     1|      0|                  1|               0|                  1|    train|                           1|                               0|                              0|                             0|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "+---+---+----------------------+-----------+-------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+-------+-------------------+----------------+-------------------+---------+----------------------------+--------------------------------+-------------------------------+------------------------------+------------------+-------------------------+-----------------------+----------------------------------+-----------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "\n",
    "import seaborn as sns; sns.set_palette(\"Set1\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"dataTransformation\").getOrCreate()\n",
    "\n",
    "heart = spark.read.csv(\"cleaned_heart.csv\", header=True)\n",
    "heart.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- resting_blood_pressure: integer (nullable = true)\n",
      " |-- cholesterol: integer (nullable = true)\n",
      " |-- fasting_blood_sugar: integer (nullable = true)\n",
      " |-- rest_ecg_type: integer (nullable = true)\n",
      " |-- max_heart_rate_achieved: integer (nullable = true)\n",
      " |-- exercise_induced_angina: integer (nullable = true)\n",
      " |-- st_depression: float (nullable = true)\n",
      " |-- num_major_vessels: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- retired: integer (nullable = true)\n",
      " |-- high_blood_pressure: integer (nullable = true)\n",
      " |-- vessels_coloured: integer (nullable = true)\n",
      " |-- non_zero_depression: integer (nullable = true)\n",
      " |-- partition: string (nullable = true)\n",
      " |-- chest_pain_type_asymptomatic: integer (nullable = true)\n",
      " |-- chest_pain_type_non-anginal_pain: integer (nullable = true)\n",
      " |-- chest_pain_type_atypical_angina: integer (nullable = true)\n",
      " |-- chest_pain_type_typical_angina: integer (nullable = true)\n",
      " |-- st_slope_type_flat: integer (nullable = true)\n",
      " |-- st_slope_type_downsloping: integer (nullable = true)\n",
      " |-- st_slope_type_upsloping: integer (nullable = true)\n",
      " |-- thalassemia_type_reversible_defect: integer (nullable = true)\n",
      " |-- thalassemia_type_normal: integer (nullable = true)\n",
      " |-- thalassemia_type_fixed_defect: integer (nullable = true)\n",
      "\n",
      "+---+---+----------------------+-----------+-------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+-------+-------------------+----------------+-------------------+----------------------------+--------------------------------+-------------------------------+------------------------------+------------------+-------------------------+-----------------------+----------------------------------+-----------------------+-----------------------------+\n",
      "|age|sex|resting_blood_pressure|cholesterol|fasting_blood_sugar|rest_ecg_type|max_heart_rate_achieved|exercise_induced_angina|st_depression|num_major_vessels|target|retired|high_blood_pressure|vessels_coloured|non_zero_depression|chest_pain_type_asymptomatic|chest_pain_type_non-anginal_pain|chest_pain_type_atypical_angina|chest_pain_type_typical_angina|st_slope_type_flat|st_slope_type_downsloping|st_slope_type_upsloping|thalassemia_type_reversible_defect|thalassemia_type_normal|thalassemia_type_fixed_defect|\n",
      "+---+---+----------------------+-----------+-------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+-------+-------------------+----------------+-------------------+----------------------------+--------------------------------+-------------------------------+------------------------------+------------------+-------------------------+-----------------------+----------------------------------+-----------------------+-----------------------------+\n",
      "| 29|  1|                   130|        204|                  0|            0|                    202|                      0|          0.0|                0|     1|      0|                  1|               0|                  0|                           0|                               0|                              1|                             0|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "| 34|  0|                   118|        210|                  0|            1|                    192|                      0|          0.7|                0|     1|      0|                  0|               0|                  1|                           0|                               0|                              1|                             0|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "| 34|  1|                   118|        182|                  0|            0|                    174|                      0|          0.0|                0|     1|      0|                  0|               0|                  0|                           0|                               0|                              0|                             1|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "| 35|  1|                   120|        198|                  0|            1|                    130|                      1|          1.6|                0|     0|      0|                  0|               0|                  1|                           1|                               0|                              0|                             0|                 1|                        0|                      0|                                 1|                      0|                            0|\n",
      "| 35|  0|                   138|        183|                  0|            1|                    182|                      0|          1.4|                0|     1|      0|                  1|               0|                  1|                           1|                               0|                              0|                             0|                 0|                        0|                      1|                                 0|                      1|                            0|\n",
      "+---+---+----------------------+-----------+-------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+-------+-------------------+----------------+-------------------+----------------------------+--------------------------------+-------------------------------+------------------------------+------------------+-------------------------+-----------------------+----------------------------------+-----------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "float_cols = [\"st_depression\"]\n",
    "\n",
    "int_cols = ['age',\n",
    "            'sex',\n",
    "            'resting_blood_pressure',\n",
    "            'cholesterol',\n",
    "            'fasting_blood_sugar',\n",
    "            'rest_ecg_type',\n",
    "            'max_heart_rate_achieved',\n",
    "            'exercise_induced_angina',\n",
    "            'num_major_vessels',\n",
    "            'target',\n",
    "            'retired',\n",
    "            'high_blood_pressure',\n",
    "            'vessels_coloured',\n",
    "            'non_zero_depression',\n",
    "            'chest_pain_type_asymptomatic',\n",
    "            'chest_pain_type_non-anginal_pain',\n",
    "            'chest_pain_type_atypical_angina',\n",
    "            'chest_pain_type_typical_angina',\n",
    "            'st_slope_type_flat',\n",
    "            'st_slope_type_downsloping',\n",
    "            'st_slope_type_upsloping',\n",
    "            'thalassemia_type_reversible_defect',\n",
    "            'thalassemia_type_normal',\n",
    "            'thalassemia_type_fixed_defect']\n",
    "\n",
    "string_cols = ['partition']\n",
    "\n",
    "for column in [col for col in float_cols]:\n",
    "    heart = heart.withColumn(column, heart[column].cast('float'))\n",
    "\n",
    "for column in [col for col in int_cols]:\n",
    "    heart = heart.withColumn(column, heart[column].cast('int'))\n",
    "\n",
    "for column in [col for col in string_cols]:\n",
    "    heart = heart.withColumn(column, heart[column].cast('string'))\n",
    "    \n",
    "heart.printSchema()\n",
    "\n",
    "train = heart.filter(col(\"partition\") == \"train\").drop(\"partition\")\n",
    "test = heart.filter(col(\"partition\") == \"test\").drop(\"partition\")\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 22:20:01 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "feature_columns = [col_name for col_name in train.columns if col_name != \"target\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "lasso_train = assembler.transform(train)\n",
    "\n",
    "lasso = LogisticRegression(featuresCol=\"features\",\n",
    "                         labelCol=\"target\", \n",
    "                         elasticNetParam=1.0, \n",
    "                         regParam=0.03,\n",
    "                         fitIntercept=True)\n",
    "\n",
    "\n",
    "lasso_model = lasso.fit(lasso_train)\n",
    "\n",
    "coefficients = lasso_model.coefficients.toArray()\n",
    "coef_scores = sorted(list(zip(feature_columns, coefficients)), key=lambda x: x[1])\n",
    "feature_importance = pd.DataFrame.from_records(coef_scores, columns = [\"Coefficient\", \"Importance\"])\n",
    "\n",
    "# Create a barplot to visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(y=\"Coefficient\", x=\"Importance\", data=feature_importance)\n",
    "plt.title(\"Feature Coefficients Using Lasso Model\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age',\n",
      " 'fasting_blood_sugar',\n",
      " 'retired',\n",
      " 'high_blood_pressure',\n",
      " 'non_zero_depression',\n",
      " 'chest_pain_type_atypical_angina',\n",
      " 'chest_pain_type_typical_angina',\n",
      " 'st_slope_type_downsloping',\n",
      " 'thalassemia_type_normal',\n",
      " 'thalassemia_type_fixed_defect']\n",
      "root\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- resting_blood_pressure: integer (nullable = true)\n",
      " |-- cholesterol: integer (nullable = true)\n",
      " |-- rest_ecg_type: integer (nullable = true)\n",
      " |-- max_heart_rate_achieved: integer (nullable = true)\n",
      " |-- exercise_induced_angina: integer (nullable = true)\n",
      " |-- st_depression: float (nullable = true)\n",
      " |-- num_major_vessels: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- vessels_coloured: integer (nullable = true)\n",
      " |-- chest_pain_type_asymptomatic: integer (nullable = true)\n",
      " |-- chest_pain_type_non-anginal_pain: integer (nullable = true)\n",
      " |-- st_slope_type_flat: integer (nullable = true)\n",
      " |-- st_slope_type_upsloping: integer (nullable = true)\n",
      " |-- thalassemia_type_reversible_defect: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "dropped_variables = [coef for coef, score in coef_scores if score == 0]\n",
    "pprint(dropped_variables)\n",
    "\n",
    "heart = heart.drop(*dropped_variables)\n",
    "\n",
    "train = heart.filter(col(\"partition\") == \"train\").drop(\"partition\")\n",
    "test = heart.filter(col(\"partition\") == \"test\").drop(\"partition\")\n",
    "\n",
    "print(train.printSchema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77de5333f78846b3baefa0d4b77f72aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 22:20:32 WARN CacheManager: Asked to cache already cached data.        \n",
      "23/10/11 22:20:32 WARN CacheManager: Asked to cache already cached data.\n",
      "23/10/11 22:20:32 WARN CacheManager: Asked to cache already cached data.\n",
      "23/10/11 22:20:32 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d9232b4ed043f19089ae719face45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b6cdf5971c4adc89ca1c59b2788238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2750d1ba433941d5b4ebc42afd4b61d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "continuous_cols = [\"st_depression\", \n",
    "                    \"cholesterol\",\n",
    "                    \"resting_blood_pressure\", \n",
    "                    \"max_heart_rate_achieved\"]\n",
    "\n",
    "transform_data = train.select(continuous_cols)\n",
    "\n",
    "\n",
    "transform_report = ProfileReport(transform_data)\n",
    "transform_report.to_file(\"pre_transform.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import sqrt, log\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Square root transformation for 'st_depression'\n",
    "train = train.withColumn(\"st_depression_sqrt\", sqrt(train[\"st_depression\"]))\n",
    "train = train.withColumn(\"resting_blood_pressure_log\", log(train[\"resting_blood_pressure\"]))\n",
    "\n",
    "# Show histograms (you may need to adjust the number of bins)\n",
    "depress_sqrt = train.select(\"st_depression_sqrt\").toPandas()\n",
    "sns.histplot(depress_sqrt, bins=50)\n",
    "plt.title(\"st_depression With Square Root Transformation\")\n",
    "plt.show()\n",
    "\n",
    "rbp_log = train.select(\"resting_blood_pressure_log\").toPandas()\n",
    "sns.histplot(rbp_log, bins=50)\n",
    "plt.title(\"resting_blood_pressure_log With Log Transformation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMwAAAK9CAYAAADYGvA9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAADtQ0lEQVR4nOzdd1zW1f//8eclKHuIgRPBgYKGkyw1xdQEV5o5MnMv3JYrP+agzFFamqaZliNnORuONCUVcyaoSThxFGXmIBcqvH9/+OX9uy4BBUdoPe6323W7eZ33eZ/365zrzXXrenXOeVsMwzAEAAAAAAAAQJKUK6cDAAAAAAAAAB4lJMwAAAAAAAAAKyTMAAAAAAAAACskzAAAAAAAAAArJMwAAAAAAAAAKyTMAAAAAAAAACskzAAAAAAAAAArJMwAAAAAAAAAKyTMAAAAAAAAACskzAAAAKzUqlVLtWrVyukwbMyZM0cWi0UJCQk5HQqy6fPPP1dgYKBy584tT09Ps/y9995T8eLFZWdnpwoVKkiS/P391aFDh2y1n5CQIIvFojlz5jywmB9XUVFRslgsioqKyulQcB/u5zv4Xv6GACAzJMwAAMAja9SoUbJYLDp79myGx5988slHJrl15coVjRo1Kkd/rKeNV0avjz/++KFcc/Xq1Ro1atRDaftBiYmJ0auvvipfX185ODjIy8tLdevW1ezZs5WSkvLQrvvLL7+oQ4cOKlGihGbOnKlPPvlEkvTdd99p8ODBql69umbPnq0xY8Y8tBgelGnTpj3QpFxaEnj37t0ZHm/UqJH8/f0f2PUetrv153GTloi1WCwaPXp0hnXatGkji8UiV1fXfzg6APhn2Od0AAAAAP8GV65cUWRkpCTleBJv+vTp6X7EPv300w/lWqtXr9ZHH330yCbNZs2apYiICOXPn19t27ZVQECA/v77b33//ffq3LmzEhMT9b///e+hXDsqKkqpqamaPHmySpYsaZZv3LhRuXLl0qeffqo8efKY5fHx8cqVK3v/P9vPz09Xr15V7ty5H1jcGZk2bZqeeOKJR3r2Ts2aNXX16lWbMcX9cXR01KJFi/Tmm2/alF++fFmrVq2So6NjDkUGAA8fCTMAAIB/mebNm+uJJ57I6TDuy+XLl+Xi4nJfbWzfvl0RERGqWrWqVq9eLTc3N/NY//79tXv3bh04cOB+Q83UmTNnJMlmKWZauZOTU7rEjoODQ7avYbFYSFr8n1y5cjEWD1iDBg20fPlyxcbGqnz58mb5qlWrdP36dYWHh2vjxo05GCEAPDwsyQQAAP8aaXsYLVmyRP/73/9UoEABubi46IUXXtCpU6fS1f/kk09UokQJOTk5qUqVKtqyZUu6OtevX9eIESNUuXJleXh4yMXFRTVq1NCmTZvMOgkJCfL29pYkRUZGmkuZrGdd/fLLL2revLm8vLzk6OiokJAQffXVV+mu9/PPP6t27dpycnJSkSJFNHr0aKWmpj6A0fn/5s+fr8qVK8vJyUleXl56+eWX043Pli1b1KJFCxUtWlQODg7y9fXVa6+9pqtXr5p1OnTooI8++kiSbJZ/SpnvJ5XRnlsdOnSQq6urjh49qgYNGsjNzU1t2rSRJKWmpmrSpEkqW7asHB0dlT9/fnXv3l3nz5+/az/TPosFCxbYJMvShISE2MyYunz5sgYMGGAu3SxdurQmTJggwzCyPYb+/v4aOXKkJMnb29u8HywWi2bPnq3Lly+b45U2Fhntv3ThwgW99tpr8vf3l4ODg4oUKaJ27dqZy5Qz28MsK/db2jLC6Ohovf766/L29paLi4tefPFF/fnnnzZ9+fnnn/XDDz+YMafNorxx44YiIyMVEBAgR0dH5cuXT88++6zWr19/x8/mXixevFiVK1eWm5ub3N3dFRwcrMmTJ5vHM7rnatWqpSeffFIHDx7Uc889J2dnZxUuXFjvvvtuuvZPnDihF154QS4uLvLx8dFrr72mdevWPbB90bLyXZLVvmZ13Ddu3KgaNWrIxcVFnp6eatKkieLi4rIcc9WqVVWsWDEtXLjQpnzBggUKDw+Xl5dXhudNmzZNZcuWlYODgwoVKqRevXrpwoUL6epl5TtYkpKTkzVy5EiVLFnS/D4aPHiwkpOTs9wXAMguZpgBAIB/nXfeeUcWi0VDhgzRmTNnNGnSJNWtW1cxMTFycnKSJH366afq3r27qlWrpv79++vYsWN64YUX5OXlJV9fX7OtpKQkzZo1S61bt1bXrl31999/69NPP1VYWJh27typChUqyNvbW9OnT1ePHj304osvqlmzZpKkcuXKSbqVBKtevboKFy6sN954Qy4uLvriiy/UtGlTLVu2TC+++KIk6ffff9dzzz2nmzdvmvU++eQTM+asOnfunM17Ozs75c2b1xyb4cOHq2XLlurSpYv+/PNPTZkyRTVr1tTevXvN2VBffvmlrly5oh49eihfvnzauXOnpkyZotOnT+vLL7+UJHXv3l2//fab1q9fr88//zybn5KtmzdvKiwsTM8++6wmTJggZ2dn8xpz5sxRx44d1bdvXx0/flxTp07V3r17FR0dnelSxCtXruj7779XzZo1VbRo0bte3zAMvfDCC9q0aZM6d+6sChUqaN26dRo0aJB+/fVXffDBB2bdrIzhpEmTNG/ePK1YscJcIluuXDmVLFlSn3zyiXbu3KlZs2ZJkqpVq5ZhTJcuXVKNGjUUFxenTp06qVKlSjp79qy++uornT59OtNZhFm939L06dNHefPm1ciRI5WQkKBJkyapd+/eWrJkiSRp0qRJ6tOnj1xdXTVs2DBJUv78+SXd2jdv7Nix6tKli6pUqaKkpCTt3r1bP/30k55//vm7jntWrV+/Xq1bt1adOnU0fvx4SVJcXJyio6PVr1+/O557/vx5hYeHq1mzZmrZsqWWLl2qIUOGKDg4WPXr15d0K1lau3ZtJSYmql+/fipQoIAWLlyYYTLrXmXluySrfc3KuG/YsEH169dX8eLFNWrUKF29elVTpkxR9erV9dNPP2V5j7jWrVtr/vz5GjdunLmn5HfffafPP/9ca9euTVd/1KhRioyMVN26ddWjRw/Fx8dr+vTp2rVrl83fbFa/g1NTU/XCCy9o69at6tatm4KCgrR//3598MEHOnTokFauXHmPnwgA3IUBAADwiBo5cqQhyfjzzz8zPF62bFkjNDTUfL9p0yZDklG4cGEjKSnJLP/iiy8MScbkyZMNwzCM69evGz4+PkaFChWM5ORks94nn3xiSLJp8+bNmzZ1DMMwzp8/b+TPn9/o1KmTWfbnn38akoyRI0emi7NOnTpGcHCwce3aNbMsNTXVqFatmhEQEGCW9e/f35Bk7Nixwyw7c+aM4eHhYUgyjh8/nvFA/Z+08br95efnZxiGYSQkJBh2dnbGO++8Y3Pe/v37DXt7e5vyK1eupGt/7NixhsViMU6cOGGW9erVy8joPynTPotNmzbZlB8/ftyQZMyePdssa9++vSHJeOONN2zqbtmyxZBkLFiwwKZ87dq1GZZbi42NNSQZ/fr1y7SOtZUrVxqSjNGjR9uUN2/e3LBYLMaRI0cMw8jeGGZ2/7Zv395wcXFJF4Ofn5/Rvn178/2IESMMScby5cvT1U1NTTUMI+PxzOr9Nnv2bEOSUbduXbM9wzCM1157zbCzszMuXLhglt3+t5amfPnyRsOGDdOV303atXft2pXh8YYNG5r3rWEYRr9+/Qx3d3fj5s2bmbaZ0T0XGhpqSDLmzZtnliUnJxsFChQwXnrpJbNs4sSJhiRj5cqVZtnVq1eNwMDADO/j7PbHMLL+XZKVvmZl3CtUqGD4+PgYf/31l1kWGxtr5MqVy2jXrt0dz027r9577z3jwIEDhiRjy5YthmEYxkcffWS4uroaly9fTncvnzlzxsiTJ49Rr149IyUlxSyfOnWqIcn47LPPDMPI3nfw559/buTKlcu8fpqPP/7YkGRER0ebZbf/DQHA/WBJJgAA+Ndp166dzRK85s2bq2DBglq9erUkaffu3Tpz5owiIiJs9pHq0KGDPDw8bNqys7Mz66SmpurcuXO6efOmQkJC9NNPP901lnPnzmnjxo1q2bKl/v77b509e1Znz57VX3/9pbCwMB0+fFi//vqrpFsb6D/zzDOqUqWKeb63t7e5PDGrli1bpvXr15uvBQsWSJKWL1+u1NRUtWzZ0ozj7NmzKlCggAICAmxm01jPart8+bLOnj2ratWqyTAM7d27N1vxZFWPHj1s3n/55Zfy8PDQ888/bxNv5cqV5erqesfZP0lJSZKU4VLMjKxevVp2dnbq27evTfmAAQNkGIbWrFkjKXtjeL+WLVum8uXLp5sRJslc+nq77Nxvabp162bTXo0aNZSSkqITJ07cNUZPT0/9/PPPOnz4cDZ7lz2enp66fPnyPS31dHV11auvvmq+z5Mnj6pUqaJjx46ZZWvXrlXhwoX1wgsvmGWOjo7q2rXr/QVuJavfJVnp693GPTExUTExMerQoYPNssly5crp+eefN78Ls6Js2bIqV66cFi1aJElauHChmjRpYs4CtbZhwwZdv35d/fv3t3mARdeuXeXu7q5vv/1WUva+g7/88ksFBQUpMDDQ5m+udu3akvRA/+YAwBpLMgEAwGMto8RBQEBAujolS5ZUQkKCJJmJgNvr5c6dW8WLF0/X3ty5czVx4kT98ssvunHjhllerFixu8Z35MgRGYah4cOHa/jw4RnWOXPmjAoXLqwTJ05k+DTL0qVL3/U61mrWrJnhcr3Dhw/LMIx0/U5jvbzx5MmTGjFihL766qt0+4VdvHgxW/Fkhb29vYoUKZIu3osXL8rHxyfDc9I21c+Iu7u7JOnvv//O0vVPnDihQoUKpUuwBQUFmcfTYsrqGN6vo0eP6qWXXsrWOdm539LcvmQ1bfluVvaJe+utt9SkSROVKlVKTz75pMLDw9W2bVtzOfL9sP7b7tmzp7744gvVr19fhQsXVr169dSyZUuFh4fftZ0iRYqk+57Imzev9u3bZ74/ceKESpQoka6e9dNNH4SsfJdkpa93G/e0+zWj746goCCtW7cuWw/WeOWVVzRx4kS99tpr2rZtW6ZPls3sunny5FHx4sXN49n5Dj58+LDi4uLMfSJvd6fvAQC4HyTMAADAIyvtiXfWG81bu3LlykN/Kt78+fPVoUMHNW3aVIMGDZKPj4/s7Ow0duxYHT169K7np23YP3DgQIWFhWVY50H/KL9TLBaLRWvWrJGdnV26466urpKklJQUPf/88zp37pyGDBmiwMBAubi46Ndff1WHDh2y9BCCzGZApaSkZFju4OBgMyMlLV4fHx9zhtztMvsBLd0aU3t7e+3fv/+usWZHVscwp9zL/ZZRPyRl+LCD29WsWVNHjx7VqlWr9N1332nWrFn64IMP9PHHH6tLly6Znpfdv20fHx/FxMRo3bp1WrNmjdasWaPZs2erXbt2mjt37h1jvJ/+PUhZ/S7JSl/vddzvVevWrTV06FB17dpV+fLlU7169R74NTKTmpqq4OBgvf/++xket97vDAAeJBJmAADgkeXn5ydJio+PT/ej6MqVKzp16lSGP9xuX6ZkGIaOHDlizr5Ia/fw4cPmsh7p1pPnjh8/rvLly5tlS5cuVfHixbV8+XKbJFDaExDTZJYgSpstkTt3btWtW/eu/c1oiVV8fPwdz8uqEiVKyDAMFStWTKVKlcq03v79+3Xo0CHNnTtX7dq1M8szWiKWWb/TZind/mS8rCzzs453w4YNql69erYffODs7KzatWtr48aNOnXq1F1/VPv5+WnDhg36+++/bWaZ/fLLL+bxtJiyMoYPQokSJXTgwIFsnZOd+y07MvucJcnLy0sdO3ZUx44ddenSJdWsWVOjRo26Y+LG+m+7Ro0a6Y4fOnRITz75pE1Znjx51LhxYzVu3Fipqanq2bOnZsyYoeHDh9930tnPz08HDx6UYRg2fT1y5Mh9tWstq98lUtb6eqdxtx7f2/3yyy964oknsjy7TLo1C7F69eqKiopSjx49ZG+f8c9I6+tazxS7fv26jh8/bt6T2fkOLlGihGJjY1WnTp073ocA8KCxhxkAAHhk1alTR3ny5NH06dPTzWr65JNPdPPmTfMpd9bmzZtnsxRv6dKlSkxMNOuGhITI29tbH3/8sa5fv27WmzNnTroET9rsFOvZKDt27NCPP/5oUy9tP5/bz/fx8VGtWrU0Y8YMJSYmpov1zz//NP/doEEDbd++XTt37rQ5ntkMq+xq1qyZ7OzsFBkZmW52jWEY+uuvvyRl3GfDMDR58uR0bab96L69335+frKzs9PmzZttyqdNm5bleFu2bKmUlBS9/fbb6Y7dvHkz3TVvN3LkSBmGobZt2+rSpUvpju/Zs8ecsdOgQQOlpKRo6tSpNnU++OADWSwW897J6hg+CC+99JJiY2O1YsWKdMcymx2VnfstO1xcXDIc79v76+rqqpIlSyo5OfmO7VWuXFk+Pj6aNWtWurorV67Ur7/+avO3fft1cuXKZSbA73atrAgLC9Ovv/6qr776yiy7du2aZs6ced9tp8nqd0lW+nq3cS9YsKAqVKiguXPn2nxuBw4c0HfffacGDRpkO/7Ro0dr5MiR6tOnT6Z16tatqzx58ujDDz+06eenn36qixcvqmHDhpKy9x3csmVL/frrrxl+FlevXtXly5ez3RcAyApmmAEAgEeWj4+PRowYoTfffFM1a9bUCy+8IGdnZ23btk2LFi1SvXr11Lhx43TneXl56dlnn1XHjh31xx9/aNKkSSpZsqS5gXfu3Lk1evRode/eXbVr11arVq10/PhxzZ49O93+OY0aNdLy5cv14osvqmHDhjp+/Lg+/vhjlSlTxiYJ4+TkpDJlymjJkiUqVaqUvLy89OSTT+rJJ5/URx99pGeffVbBwcHq2rWrihcvrj/++EM//vijTp8+rdjYWEnS4MGD9fnnnys8PFz9+vWTi4uLPvnkE/n5+dnst3SvSpQoodGjR2vo0KFKSEhQ06ZN5ebmpuPHj2vFihXq1q2bBg4cqMDAQJUoUUIDBw7Ur7/+Knd3dy1btizDPa0qV64sSerbt6/CwsJkZ2enl19+WR4eHmrRooWmTJkii8WiEiVK6JtvvsnWfkOhoaHq3r27xo4dq5iYGNWrV0+5c+fW4cOH9eWXX2ry5Mlq3rx5pudXq1ZNH330kXr27KnAwEC1bdtWAQEB+vvvvxUVFaWvvvpKo0ePliQ1btxYzz33nIYNG6aEhASVL19e3333nVatWqX+/furRIkS2RrDB2HQoEFaunSpWrRooU6dOqly5co6d+6cvvrqK3388cc2s3CsZfV+y47KlStr+vTpGj16tEqWLCkfHx/Vrl1bZcqUUa1atVS5cmV5eXlp9+7dWrp0qXr37n3H9vLkyaMJEyaoffv2euqpp9SqVSvly5dPe/fu1WeffaZy5cqpW7duZv0uXbro3Llzql27tooUKaITJ05oypQpqlChgrnP3P3o3r27pk6dqtatW6tfv34qWLCgFixYYC4LzerMps8++0xr165NV96vX78sf5dkpa9ZGff33ntP9evXV9WqVdW5c2ddvXpVU6ZMkYeHh0aNGpXtMQoNDVVoaOgd63h7e2vo0KGKjIxUeHi4XnjhBcXHx2vatGl66qmnzIcvZOc7uG3btvriiy8UERGhTZs2qXr16kpJSdEvv/yiL774QuvWrVNISEi2+wMAd/UPPpETAADgnsyfP9945plnDBcXF8PBwcEIDAw0IiMjjWvXrtnU27RpkyHJWLRokTF06FDDx8fHcHJyMho2bGicOHEiXbvTpk0zihUrZjg4OBghISHG5s2bjdDQUCM0NNSsk5qaaowZM8bw8/MzHBwcjIoVKxrffPON0b59e8PPz8+mvW3bthmVK1c28uTJY0gyRo4caR47evSo0a5dO6NAgQJG7ty5jcKFCxuNGjUyli5datPGvn37jNDQUMPR0dEoXLiw8fbbbxuffvqpIck4fvz4Hcdp5MiRhiTjzz//vGO9ZcuWGc8++6zh4uJiuLi4GIGBgUavXr2M+Ph4s87BgweNunXrGq6ursYTTzxhdO3a1YiNjTUkGbNnzzbr3bx50+jTp4/h7e1tWCwWw/o/L//880/jpZdeMpydnY28efMa3bt3Nw4cOJCujfbt2xsuLi6ZxvvJJ58YlStXNpycnAw3NzcjODjYGDx4sPHbb7/dsZ9p9uzZY7zyyitGoUKFjNy5cxt58+Y16tSpY8ydO9dISUkx6/3999/Ga6+9ZtYLCAgw3nvvPSM1NfWexjCzzyOz/vr5+Rnt27e3Kfvrr7+M3r17G4ULFzby5MljFClSxGjfvr1x9uxZwzAM4/jx4+nG0zCydr/Nnj3bkGTs2rXL5ty0v6NNmzaZZb///rvRsGFDw83NzZBk/o2MHj3aqFKliuHp6Wk4OTkZgYGBxjvvvGNcv349/QeRgTVr1hjPPfec4e7ubuTOndsoVqyY8frrrxvnz5+3qbd06VKjXr16ho+Pj5EnTx6jaNGiRvfu3Y3ExMQ7xh0aGmqULVs23XUz+vs9duyY0bBhQ8PJycnw9vY2BgwYYCxbtsyQZGzfvv2O/Ugby8xep06dyvJ3SVb6mtVx37Bhg1G9enXDycnJcHd3Nxo3bmwcPHjwjn0xjP9/X7333nt3rJfZvTx16lQjMDDQyJ07t5E/f36jR48e6T5Tw8jad7BhGMb169eN8ePHG2XLljUcHByMvHnzGpUrVzYiIyONixcvmvUy+hsCgHtlMYx/eLdLAACAhyQqKkrPPfecvvzyyzvOPAKArJg0aZJee+01nT592ubJogCAfz/2MAMAAADwn3f7EzuvXbumGTNmKCAggGQZAPwHsYcZAAAAgP+8Zs2aqWjRoqpQoYIuXryo+fPn65dffnlgD90AADxeSJgBAAAA+M8LCwvTrFmztGDBAqWkpKhMmTJavHixWrVqldOhAQByAHuYAQAAAAAAAFbYwwwAAAAAAACwQsIMAAAAAAAAsMIeZgByRGpqqn777Te5ubnJYrHkdDgAAAAAgH85wzD0999/q1ChQsqV685zyEiYAcgRv/32m3x9fXM6DAAAAADAf8ypU6dUpEiRO9YhYQYgR7i5uUm69UXl7u6ew9EAAAAAAP7tkpKS5Ovra/4evRMSZgByRNoyTHd3dxJmAAAAAIB/TFa2BWLTfwAAAAAAAMAKM8wAIAv+nD4/p0MAAAB4bHj3eDWnQwCA+8IMMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwMojlTCLioqSxWLRhQsX7qsdf39/TZo06YHElBMSEhJksVgUExOT06HAyu33lcVi0cqVKzOt/098jrVq1VL//v2zdc7KlStVsmRJ2dnZZftcAAAAAAD+C3I0YXYvP/b/C3x9fZWYmKgnn3zygbTXoUMHNW3a9IG09V+2a9cudevWLafDuG/du3dX8+bNderUKb399tv33d6DSnQDAAAAAPCosM/pAJCenZ2dChQokNNh/OOuX7+uPHnyPLLX9vb2/oeieXguXbqkM2fOKCwsTIUKFcrpcAAAAAAAeCTl2AyzDh066IcfftDkyZNlsVhksViUkJAgSdqzZ49CQkLk7OysatWqKT4+3jzv6NGjatKkifLnzy9XV1c99dRT2rBhwx2v9f777ys4OFguLi7y9fVVz549denSJfP4iRMn1LhxY+XNm1cuLi4qW7asVq9eLUk6f/682rRpI29vbzk5OSkgIECzZ882zz116pRatmwpT09PeXl5qUmTJmY/0vrZtGlTjRkzRvnz55enp6feeust3bx5U4MGDZKXl5eKFCli0+btS/lSUlLUuXNnFStWTE5OTipdurQmT56cpXEeNWqU5s6dq1WrVpnjHBUVpdq1a6t37942df/880/lyZNH33//vaRbSxDffvtttW7dWi4uLipcuLA++ugjm3MuXLigLl26yNvbW+7u7qpdu7ZiY2OzHFuFChU0a9YsFStWTI6Ojndt89ChQ7JYLPrll19s2vrggw9UokQJ8/2BAwdUv359ubq6Kn/+/Grbtq3Onj1rHq9Vq5Z69+6t/v3764knnlBYWJgMw9CoUaNUtGhROTg4qFChQurbt695TkZLfRMTE1W/fn05OTmpePHiWrp06R37fLe47uTy5ctq166dXF1dVbBgQU2cODFdneTkZA0cOFCFCxeWi4uLnn76aUVFRUm6NRPMzc1NklS7dm3zXpCkrVu3qkaNGnJycpKvr6/69u2ry5cv27Q7ZMgQ+fr6ysHBQSVLltSnn36qhIQEPffcc5KkvHnzymKxqEOHDlnqDwAAAAAAj6ocS5hNnjxZVatWVdeuXZWYmKjExET5+vpKkoYNG6aJEydq9+7dsre3V6dOnczzLl26pAYNGuj777/X3r17FR4ersaNG+vkyZOZXitXrlz68MMP9fPPP2vu3LnauHGjBg8ebB7v1auXkpOTtXnzZu3fv1/jx4+Xq6urJGn48OE6ePCg1qxZo7i4OE2fPl1PPPGEJOnGjRsKCwuTm5ubtmzZoujoaLm6uio8PFzXr18329+4caN+++03bd68We+//75GjhypRo0aKW/evNqxY4ciIiLUvXt3nT59OsP4U1NTVaRIEX355Zc6ePCgRowYof/973/64osv7jrOAwcOVMuWLRUeHm6Oc7Vq1dSlSxctXLhQycnJZt358+ercOHCql27tln23nvvqXz58tq7d6/eeOMN9evXT+vXrzePt2jRQmfOnNGaNWu0Z88eVapUSXXq1NG5c+fuGpskHTlyRMuWLdPy5cvNBOGd2ixVqpRCQkK0YMECm3YWLFigV155RdKthFvt2rVVsWJF7d69W2vXrtUff/yhli1b2pwzd+5c5cmTR9HR0fr444+1bNkyffDBB5oxY4YOHz6slStXKjg4+I7xDx8+XC+99JJiY2PVpk0bvfzyy4qLi8uwblbjysygQYP0ww8/aNWqVfruu+8UFRWln376yaZO79699eOPP2rx4sXat2+fWrRoofDwcB0+fNgm+bxs2TLzXjh69KjCw8P10ksvad++fVqyZIm2bt1qk1Bt166dFi1apA8//FBxcXGaMWOGXF1d5evrq2XLlkmS4uPjlZiYmGkyNzk5WUlJSTYvAAAAAAAeRRbDMIycunitWrVUoUIFc9ZOVFSUnnvuOW3YsEF16tSRJK1evVoNGzbU1atXzRlIt3vyyScVERFh/sD39/dX//79M90fbenSpYqIiDBn9pQrV04vvfSSRo4cma7uCy+8oCeeeEKfffZZumPz58/X6NGjFRcXJ4vFIunW0j5PT0+tXLlS9erVU4cOHRQVFaVjx44pV65b+cnAwED5+Pho8+bNkm7NIPPw8NCsWbP08ssvKyEhQcWKFdPevXtVoUKFDPvQu3dv/f7773ed0STdmuV24cIFmw3qr127pkKFCunjjz82Ezbly5dXs2bNzHHw9/dXUFCQ1qxZY5738ssvKykpSatXr9bWrVvVsGFDnTlzRg4ODmadkiVLavDgwXfd72vUqFEaM2aMfv31V3O5Y1banDRpkqZOnaojR45IujXrrHTp0oqLi1NgYKBGjx6tLVu2aN26deb5p0+flq+vr+Lj41WqVCnVqlVLSUlJNgmn999/XzNmzNCBAweUO3fudPHefl9ZLBZFRERo+vTpZp1nnnlGlSpV0rRp09J9jlmJKzOXLl1Svnz5NH/+fLVo0UKSdO7cORUpUsQck5MnT6p48eI6efKkzXLLunXrqkqVKhozZowuXLigvHnzatOmTapVq5YkqUuXLrKzs9OMGTPMc7Zu3arQ0FBdvnxZJ0+eVOnSpbV+/XrVrVs3XWxpf7fnz5+Xp6dnpn0YNWqUIiMj05VfvHhR7u7umZ73qPhz+vycDgEAAOCx4d3j1ZwOAQDSSUpKkoeHR5Z+hz5ST8lMU65cOfPfBQsWlCSdOXNG0q3EwcCBAxUUFCRPT0+5uroqLi7ujjPM0hJwhQsXlpubm9q2bau//vpLV65ckST17dtXo0ePVvXq1TVy5Ejt27fPPLdHjx5avHixKlSooMGDB2vbtm3msdjYWB05ckRubm5ydXWVq6urvLy8dO3aNR09etSsV7ZsWTNZJkn58+e3mblkZ2enfPnymX3MyEcffaTKlSvL29tbrq6u+uSTT+7Y57txdHRU27ZtzUTgTz/9pAMHDqRbTle1atV079NmUMXGxpqJnLT+u7q66vjx4zb9vxM/Pz+bvcGy0mZaUnH79u2Sbs0uq1SpkgIDA802Nm3aZHN+2jHruCpXrmwTS4sWLXT16lUVL15cXbt21YoVK3Tz5s07xn+n8bldVuPKyNGjR3X9+nU9/fTTZpmXl5dKly5tvt+/f79SUlJUqlQpm2v88MMPd2w/NjZWc+bMsTknLCxMqampOn78uGJiYmRnZ6fQ0NA7xng3Q4cO1cWLF83XqVOn7qs9AAAAAAAelkdy03/r2T1pM7dSU1Ml3VpiuH79ek2YMEElS5aUk5OTmjdvbrME0lpCQoIaNWqkHj166J133pGXl5e2bt2qzp076/r163J2dlaXLl0UFhamb7/9Vt99953Gjh2riRMnqk+fPqpfv75OnDih1atXa/369apTp4569eqlCRMm6NKlS6pcuXK65YGS7Qbxt89WslgsGZal9fF2ixcv1sCBAzVx4kRVrVpVbm5ueu+997Rjx44sjGbmunTpogoVKuj06dOaPXu2ateuLT8/vyyff+nSJRUsWNDcB8vanWYaWXNxccl2mwUKFFDt2rW1cOFCPfPMM1q4cKF69Ohh00bjxo01fvz4dG2kJWAzunbaTK8NGzZo/fr16tmzp9577z398MMPGc44y66sxnU/7dvZ2WnPnj2ys7OzOZa2xDiz87p3726zX1uaokWLmjP57peDg4PNrEEAAAAAAB5VOZowy5Mnj1JSUrJ1TnR0tDp06KAXX3xR0q0f+9ab7N9uz549Sk1N1cSJE81ZXhnt/eXr66uIiAhFRERo6NChmjlzpvr06SPpVvKrffv2at++vWrUqKFBgwZpwoQJqlSpkpYsWSIfH5+HuqQsOjpa1apVU8+ePc2yrM7gkjIf5+DgYIWEhGjmzJlauHChpk6dmq5O2iwu6/dBQUGSpEqVKun333+Xvb29/P39sxzPnWS1zTZt2mjw4MFq3bq1jh07ppdfftmmjWXLlsnf31/29tm7xZ2cnNS4cWM1btxYvXr1UmBgoPbv369KlSplWH/79u1q166dzfuKFStm2rd7jatEiRLKnTu3duzYoaJFi0q69UCKQ4cOmTO/KlasqJSUFJ05c0Y1atTIctuVKlXSwYMHVbJkyQyPBwcHKzU1VT/88EOGSzLTni6a3b9lAAAAAAAeVTm6JNPf3187duxQQkKCzp49m+kMK2sBAQHmBvGxsbF65ZVX7nheyZIldePGDU2ZMkXHjh3T559/ro8//timTv/+/bVu3TodP35cP/30kzZt2mQmhUaMGKFVq1bpyJEj+vnnn/XNN9+Yx9q0aaMnnnhCTZo00ZYtW3T8+HFFRUWpb9++mW7gfy8CAgK0e/durVu3TocOHdLw4cO1a9euLJ/v7++vffv2KT4+XmfPntWNGzfMY126dNG4ceNkGIaZhLQWHR2td999V4cOHdJHH32kL7/8Uv369ZN0a2+sqlWrqmnTpvruu++UkJCgbdu2adiwYdq9e/c99TWrbTZr1kx///23evTooeeee85mz65evXrp3Llzat26tXbt2qWjR49q3bp16tix4x2TOnPmzNGnn36qAwcO6NixY5o/f76cnJzuOOvuyy+/1GeffaZDhw5p5MiR2rlzZ7qnj95vXNKtGWKdO3fWoEGDtHHjRnP5rPVS31KlSqlNmzZq166dli9fruPHj2vnzp0aO3asvv3220zbHjJkiLZt26bevXsrJiZGhw8f1qpVq2z2BGzfvr06deqklStXmvd5WuLZz89PFotF33zzjf7880+bJ9ACAAAAAPA4ytGE2cCBA2VnZ6cyZcrI29s7S3tyvf/++8qbN6+qVaumxo0bKywsLNPZP9Ktjezff/99jR8/Xk8++aQWLFigsWPH2tRJSUlRr169FBQUpPDwcJUqVUrTpk2TdGv2zNChQ1WuXDnVrFlTdnZ2Wrx4sSTJ2dlZmzdvVtGiRdWsWTMFBQWpc+fOunbt2gOdcda9e3c1a9ZMrVq10tNPP62//vrLZrbZ3XTt2lWlS5dWSEiIvL29FR0dbR5r3bq17O3t1bp16wwfqjBgwADt3r1bFStW1OjRo/X+++8rLCxM0q1lpKtXr1bNmjXVsWNHlSpVSi+//LJOnDih/Pnz31Nfs9qmm5ubGjdubD6d0lqhQoUUHR2tlJQU1atXT8HBwerfv788PT1tEky38/T01MyZM1W9enWVK1dOGzZs0Ndff618+fJlek5kZKQWL16scuXKad68eVq0aJHKlCmTYd17jSvNe++9pxo1aqhx48aqW7eunn322XT7sM2ePVvt2rXTgAEDVLp0aTVt2lS7du0yZ6VlpFy5cvrhhx906NAh1ahRQxUrVtSIESNskpDTp09X8+bN1bNnTwUGBqpr1666fPmyJKlw4cKKjIzUG2+8ofz582eaMAQAAAAA4HGRo0/JRM5LSEhQiRIltGvXrnSJx7s9bRS4H9l5OsmjgKdkAgAAZB1PyQTwKMrO79BHctN/PHw3btzQX3/9pTfffFPPPPPMHWfpAQAAAAAA/Jfk6JJMPBiurq6ZvrZs2ZLhOdHR0SpYsKB27dqVbk+3B6Vs2bKZxpXRk0X/y06ePHnHzzEry5UBAAAAAMCDwQyzf4GYmJhMjxUuXDjD8lq1auluq3Hv9PTRrFi9erXNAwas3eseZ/9WhQoVuuPnaL2fGAAAAAAAeLhImP0LlCxZMqdDyNCdni4JW/b29o/s5wgAAAAAwH8NSzIBAAAAAAAAKyTMAAAAAAAAACskzAAAAAAAAAArJMwAAAAAAAAAK2z6DwBZ4N3j1ZwOAQAAAADwD2GGGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGDFPqcDAADgvyxx2pCcDgEAgAeuYM/xOR0CANwXZpgBAAAAAAAAVkiYAQAAAAAAAFZImAEAAAAAAABWSJgBAAAAAAAAVkiYAQAAAAAAAFZImAEAAAAAAABWSJgBAAAAAAAAVkiYAQAAAAAAAFZImAEAAAAAAABWSJgBAAAAAAAAVkiYAXcQFRUli8WiCxcu5GgcCQkJslgsiomJydE47sRisWjlypU5HQYAAAAAAPeNhBkAAAAAAABghYQZANONGzdyOgQAAAAAAHIcCTPkuE8++USFChVSamqqTXmTJk3UqVMnSdKqVatUqVIlOTo6qnjx4oqMjNTNmzclSYZhaNSoUSpatKgcHBxUqFAh9e3b12xn2rRpCggIkKOjo/Lnz6/mzZubx1JTUzV27FgVK1ZMTk5OKl++vJYuXZpprCdOnFDjxo2VN29eubi4qGzZslq9enWW+vnzzz+rUaNGcnd3l5ubm2rUqKGjR4+acbz11lsqUqSIHBwcVKFCBa1du/aO7f3www+qUqWKHBwcVLBgQb3xxhvmmEiSv7+/Jk2aZHNOhQoVNGrUKPO9xWLR9OnT9cILL8jFxUXvvPOOpDuPtyQdPnxYNWvWlKOjo8qUKaP169fftf/JyclKSkqyeQEAAAAA8Ciyz+kAgBYtWqhPnz7atGmT6tSpI0k6d+6c1q5dq9WrV2vLli1q166dPvzwQzPJ1K1bN0nSyJEjtWzZMn3wwQdavHixypYtq99//12xsbGSpN27d6tv3776/PPPVa1aNZ07d05btmwxrz127FjNnz9fH3/8sQICArR582a9+uqr8vb2VmhoaLpYe/XqpevXr2vz5s1ycXHRwYMH5erqetc+/vrrr6pZs6Zq1aqljRs3yt3dXdHR0WYSavLkyZo4caJmzJihihUr6rPPPtMLL7ygn3/+WQEBARm216BBA3Xo0EHz5s3TL7/8oq5du8rR0dEmIZYVo0aN0rhx4zRp0iTZ29vfdbxTU1PVrFkz5c+fXzt27NDFixfVv3//u15n7NixioyMzFZsAAAAAADkBBJmyHF58+ZV/fr1tXDhQjNhtnTpUj3xxBN67rnnVK9ePb3xxhtq3769JKl48eJ6++23NXjwYI0cOVInT55UgQIFVLduXeXOnVtFixZVlSpVJEknT56Ui4uLGjVqJDc3N/n5+alixYqSbs14GjNmjDZs2KCqVauabW/dulUzZszIMGF28uRJvfTSSwoODjbrZ8VHH30kDw8PLV68WLlz55YklSpVyjw+YcIEDRkyRC+//LIkafz48dq0aZMmTZqkjz76KF1706ZNk6+vr6ZOnSqLxaLAwED99ttvGjJkiEaMGKFcubI+efSVV15Rx44dzfedOnW643hv2LBBv/zyi9atW6dChQpJksaMGaP69evf8TpDhw7V66+/br5PSkqSr69vluMEAAAAAOCfwpJMPBLatGmjZcuWKTk5WZK0YMECvfzyy8qVK5diY2P11ltvydXV1Xx17dpViYmJunLlilq0aKGrV6+qePHi6tq1q1asWGHO3Hr++efl5+en4sWLq23btlqwYIGuXLkiSTpy5IiuXLmi559/3qbtefPmmUslb9e3b1+NHj1a1atX18iRI7Vv374s9S8mJkY1atQwk2XWkpKS9Ntvv6l69eo25dWrV1dcXFyG7cXFxalq1aqyWCw29S9duqTTp09nKaY0ISEhNu/vNt5xcXHy9fU1k2WSzITjnTg4OMjd3d3mBQAAAADAo4iEGR4JjRs3lmEY+vbbb3Xq1Clt2bJFbdq0kSRdunRJkZGRiomJMV/79+/X4cOH5ejoKF9fX8XHx2vatGlycnJSz549VbNmTd24cUNubm766aeftGjRIhUsWFAjRoxQ+fLldeHCBV26dEmS9O2339q0ffDgwUz3MevSpYuOHTumtm3bav/+/QoJCdGUKVPu2j8nJ6cHN1hZlCtXLhmGYVOW0ab+Li4uNu/vNt4AAAAAAPzbsSQTjwRHR0c1a9ZMCxYs0JEjR1S6dGlVqlRJklSpUiXFx8erZMmSmZ7v5OSkxo0bq3HjxurVq5cCAwO1f/9+VapUSfb29qpbt67q1q2rkSNHytPTUxs3btTzzz8vBwcHnTx5MsPll5nx9fVVRESEIiIiNHToUM2cOVN9+vS54znlypXT3LlzdePGjXSzzNzd3VWoUCFFR0fbxBEdHW0uLb1dUFCQli1bJsMwzFlm0dHRcnNzU5EiRSRJ3t7eSkxMNM9JSkrS8ePH79q/u413UFCQTp06pcTERBUsWFCStH379ru2CwAAAADA44KEGR4Zbdq0UaNGjfTzzz/r1VdfNctHjBihRo0aqWjRomrevLm5TPPAgQMaPXq05syZo5SUFD399NNydnbW/Pnz5eTkJD8/P33zzTc6duyYatasqbx582r16tVKTU1V6dKl5ebmpoEDB+q1115Tamqqnn32WV28eFHR0dFyd3c39/Cy1r9/f9WvX1+lSpXS+fPntWnTJgUFBd21b71799aUKVP08ssva+jQofLw8ND27dtVpUoVlS5dWoMGDdLIkSNVokQJVahQQbNnz1ZMTIwWLFiQYXs9e/bUpEmT1KdPH/Xu3Vvx8fEaOXKkXn/9dXP/stq1a2vOnDlq3LixPD09NWLECNnZ2d011ruNd926dVWqVCm1b99e7733npKSkjRs2LC7tgsAAAAAwOOChBkeGbVr15aXl5fi4+P1yiuvmOVhYWH65ptv9NZbb2n8+PHKnTu3AgMD1aVLF0mSp6enxo0bp9dff10pKSkKDg7W119/rXz58snT01PLly/XqFGjdO3aNQUEBGjRokUqW7asJOntt9+Wt7e3xo4dq2PHjsnT01OVKlXS//73vwxjTElJUa9evXT69Gm5u7srPDxcH3zwwV37li9fPm3cuFGDBg1SaGio7OzsVKFCBXPfsr59++rixYsaMGCAzpw5ozJlyuirr77K8AmZklS4cGGtXr1agwYNUvny5eXl5aXOnTvrzTffNOsMHTpUx48fV6NGjeTh4aG33347SzPM7jbeuXLl0ooVK9S5c2dVqVJF/v7++vDDDxUeHn7XtgEAAAAAeBxYjNs3OQKAf0BSUpI8PDx08eJFHgCA/7TEaUNyOgQAAB64gj3H53QIAJBOdn6Hsuk/AAAAAAAAYIWEGfAAREREyNXVNcNXRERETocHAAAAAACygT3MgAfgrbfe0sCBAzM8xnJDAAAAAAAeLyTMgAfAx8dHPj4+OR0GAAAAAAB4AFiSCQAAAAAAAFghYQYAAAAAAABYIWEGAAAAAAAAWCFhBgAAAAAAAFhh038AAHJQwZ7jczoEAAAAALdhhhkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABgxT6nAwAAAHhU7ZrROKdDAIDH0lPdv87pEADgvjDDDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDPfMYrFo5cqVD/06o0aNUoUKFe67HX9/f02aNOm+27kfCQkJslgsiomJydE4bvdPfZYAAAAAADwO7HM6ADy+EhMTlTdv3od+nYEDB6pPnz4P/Tr/Zf/UZwkAAAAAwOOAhBkydOPGDeXOnfuOdQoUKPCPxOLq6ipXV9d/5Fr/Vf/UZwkAAAAAwOOAJZmPidTUVI0dO1bFihWTk5OTypcvr6VLl8owDNWtW1dhYWEyDEOSdO7cORUpUkQjRowwz581a5aCgoLk6OiowMBATZs2zTyWtkxwyZIlCg0NlaOjoxYsWCBJ+uyzz1S2bFk5ODioYMGC6t27t3me9TK+69evq3fv3ipYsKAcHR3l5+ensWPHmnUvXLigLl26yNvbW+7u7qpdu7ZiY2Oz1Pfbl2R26NBBTZs21YQJE1SwYEHly5dPvXr10o0bN8w6Z86cUePGjeXk5KRixYqZ/bm9z9ZLIy9cuCCLxaKoqCiz7Oeff1ajRo3k7u4uNzc31ahRQ0ePHs3SuErSzp07VbFiRTk6OiokJER79+7NUp8lKSUlRZ07dzY/89KlS2vy5Mk2dbIyFomJiWrYsKE5FgsXLky3PNX6s0wbm+XLl+u5556Ts7Ozypcvrx9//NGs/9dff6l169YqXLiwnJ2dFRwcrEWLFmW5bwAAAAAAPMqYYfaYGDt2rObPn6+PP/5YAQEB2rx5s1599VV5e3tr7ty5Cg4O1ocffqh+/fopIiJChQsXNhNmCxYs0IgRIzR16lRVrFhRe/fuVdeuXeXi4qL27dub13jjjTc0ceJEM8Ezffp0vf766xo3bpzq16+vixcvKjo6OsP4PvzwQ3311Vf64osvVLRoUZ06dUqnTp0yj7do0UJOTk5as2aNPDw8NGPGDNWpU0eHDh2Sl5dXtsdj06ZNKliwoDZt2qQjR46oVatWqlChgrp27SrpViLpt99+06ZNm5Q7d2717dtXZ86cydY1fv31V9WsWVO1atXSxo0b5e7urujoaN28eVPS3cf10qVLatSokZ5//nnNnz9fx48fV79+/bJ8/dTUVBUpUkRffvml8uXLp23btqlbt24qWLCgWrZsmeWxaNeunc6ePauoqCjlzp1br7/+epbGYtiwYZowYYICAgI0bNgwtW7dWkeOHJG9vb2uXbumypUra8iQIXJ3d9e3336rtm3bqkSJEqpSpUqG7SUnJys5Odl8n5SUlOWxAAAAAADgn0TC7DGQnJysMWPGaMOGDapataokqXjx4tq6datmzJihhQsXasaMGWrXrp1+//13rV69Wnv37pW9/a2Pd+TIkZo4caKaNWsmSSpWrJgOHjyoGTNm2CTM+vfvb9aRpNGjR2vAgAE2SZ6nnnoqwxhPnjypgIAAPfvss7JYLPLz8zOPbd26VTt37tSZM2fk4OAgSZowYYJWrlyppUuXqlu3btkek7x582rq1Kmys7NTYGCgGjZsqO+//15du3bVoUOHtGbNGu3cudOM99NPP1VQUFC2rvHRRx/Jw8NDixcvNpenlipVyjx+t3FduHChUlNT9emnn8rR0VFly5bV6dOn1aNHjyxdP3fu3IqMjDTfFytWTD/++KO++OILm4TZncbil19+0YYNG7Rr1y6FhIRIujUrLiAg4K7XHzhwoBo2bChJioyMVNmyZXXkyBEFBgaqcOHCGjhwoFm3T58+Wrdunb744otME2Zjx4616Q8AAAAAAI8qEmaPgSNHjujKlSt6/vnnbcqvX7+uihUrSro1g2vFihUaN26cpk+fbiZELl++rKNHj6pz587mjCNJunnzpjw8PGzaS0uoSLeWNP7222+qU6dOlmLs0KGDnn/+eZUuXVrh4eFq1KiR6tWrJ0mKjY3VpUuXlC9fPptzrl69arO8MTvKli0rOzs7833BggW1f/9+SVJcXJzs7e1VuXJl83hgYKA8PT2zdY2YmBjVqFEjw73csjKucXFxKleunBwdHc3jaQnPrProo4/02Wef6eTJk7p69aquX7+e7omhdxqL+Ph42dvbq1KlSubxkiVLZmmD/3Llytm0Kd26LwIDA5WSkqIxY8boiy++0K+//qrr168rOTlZzs7OmbY3dOhQvf766+b7pKQk+fr63jUOAAAAAAD+aSTMHgOXLl2SJH377bcqXLiwzbG0GVtXrlzRnj17ZGdnp8OHD6c7d+bMmXr66adtzrVOskiSi4uL+W8nJ6dsxVipUiUdP35ca9as0YYNG9SyZUvVrVtXS5cu1aVLl1SwYEGbvcHSZDeJleb2JJbFYlFqamqWz8+V69b2fWn7vkmy2fdLuvMYZGdc79XixYs1cOBATZw4UVWrVpWbm5vee+897dixw6be/Y5FZqzbtVgskmS2+95772ny5MmaNGmSgoOD5eLiov79++v69euZtufg4GDerwAAAAAAPMpImD0GypQpIwcHB508eVKhoaEZ1hkwYIBy5cqlNWvWqEGDBmrYsKFq166t/Pnzq1ChQjp27JjatGmT5Wu6ubnJ399f33//vZ577rksnePu7q5WrVqpVatWat68ucLDw3Xu3DlVqlRJv//+u+zt7eXv75/lGO5VYGCgbt68qT179phLMuPj43XhwgWzjre3t6RbG+KnzdKzfgCAdGuG1dy5czN8YmhWxjUoKEiff/65rl27Zs4y2759e5b7ER0drWrVqqlnz55mWXZn5JUuXVo3b97U3r17zRl3R44c0fnz57PVTkaxNWnSRK+++qqkW4m0Q4cOqUyZMvfVLgAAAAAAjwISZo8BNzc3DRw4UK+99ppSU1P17LPPmhvwu7u764knntBnn32mH3/8UZUqVdKgQYPUvn177du3T3nz5lVkZKT69u0rDw8PhYeHKzk5Wbt379b58+dtlsjdbtSoUYqIiJCPj4/q16+vv//+W9HR0erTp0+6uu+//74KFiyoihUrKleuXPryyy9VoEABeXp6qm7duqpataqaNm2qd999V6VKldJvv/2mb7/9Vi+++KLNUtAHIW1ZaPfu3TV9+nTZ29urf//+NjPGnJyc9Mwzz2jcuHEqVqyYzpw5ozfffNOmnd69e2vKlCl6+eWXNXToUHl4eGj79u2qUqWKSpcufddxfeWVVzRs2DB17dpVQ4cOVUJCgiZMmJDlfgQEBGjevHlat26dihUrps8//1y7du1SsWLFstxGYGCg6tatq27dumn69OnKnTu3BgwYICcnJ3PW2L0ICAjQ0qVLtW3bNuXNm1fvv/++/vjjDxJmAAAAAIB/hVw5HQCy5u2339bw4cM1duxYBQUFKTw8XN9++638/f3VuXNnjRo1ytynKjIyUvnz51dERIQkqUuXLpo1a5Zmz56t4OBghYaGas6cOXdNvLRv316TJk3StGnTVLZsWTVq1Mhmuac1Nzc3vfvuuwoJCdFTTz2lhIQErV69Wrly5ZLFYtHq1atVs2ZNdezYUaVKldLLL7+sEydOKH/+/A92oP7P7NmzVahQIYWGhqpZs2bq1q2bfHx8bOp89tlnunnzpipXrqz+/ftr9OjRNsfz5cunjRs36tKlSwoNDVXlypU1c+ZMc7bZ3cbV1dVVX3/9tfbv36+KFStq2LBhGj9+fJb70L17dzVr1kytWrXS008/rb/++stmtllWzZs3T/nz51fNmjX14osvqmvXrnJzc7PZWy273nzzTVWqVElhYWGqVauWChQooKZNm95zewAAAAAAPEoshvUmTgD+9U6fPi1fX19t2LAhyw91eBiSkpLk4eGhixcvyt3dPcfiAIA72TWjcU6HAACPpae6f53TIQBAOtn5HcqSTOBfLm2WXHBwsBITEzV48GD5+/urZs2aOR0aAAAAAACPJJZkIseVLVtWrq6uGb4WLFiQ0+E9NBEREZn2O2057YNw48YN/e9//1PZsmX14osvytvbW1FRUekeZAAAAAAAAG5hSSZy3IkTJ3Tjxo0Mj+XPn19ubm7/cET/jDNnzigpKSnDY+7u7un2XPu3YUkmgMcBSzIB4N6wJBPAo4glmXis+Pn55XQIOcLHx+dfnxQDAAAAAOBxxJJMAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAqb/gMAAGSCp7wBAAD8NzHDDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDAAAAAAAALBin9MBAAAA4O5WfVY/p0MAgCxr0mlNTocAAPeFGWYAAAAAAACAFRJmAAAAAAAAgBUSZgAAAAAAAIAVEmYAAAAAAACAFRJmAAAAAAAAgBUSZgAAAAAAAIAVEmYAAAAAAACAFRJmAAAAAAAAgBUSZgAAAAAAAIAVEmYAAAAAAACAFRJmVhISEmSxWBQTE5PToTxwtWrVUv/+/XM6DDzmLBaLVq5cmdNhAAAAAADwUJEw+4flVOJq+fLlevvttx9IW//mxGJO6dChg5o2bZrTYZhGjRqlChUqpCtPTExU/fr1//mAAAAAAAD4B9nndAD4Z3h5eeV0CPgXKFCgQE6HAAAAAADAQ/efnGGWmpqqd999VyVLlpSDg4OKFi2qd955xzx+7NgxPffcc3J2dlb58uX1448/2py/detW1ahRQ05OTvL19VXfvn11+fJl8/i0adMUEBAgR0dH5c+fX82bN5d0axbRDz/8oMmTJ8tischisSghIeGOsUZFRclisejbb79VuXLl5OjoqGeeeUYHDhww6/z1119q3bq1ChcuLGdnZwUHB2vRokU27dw+s83f319jxoxRp06d5ObmpqJFi+qTTz7J0vgVK1ZMklSxYkVZLBbVqlVLmzdvVu7cufX777/b1O3fv79q1KghSZozZ448PT21cuVKc3zCwsJ06tQpm3NWrVqlSpUqydHRUcWLF1dkZKRu3ryZpdjef/99BQcHy8XFRb6+vurZs6cuXbpkHj9x4oQaN26svHnzysXFRWXLltXq1atlGIZKliypCRMm2LQXExMji8WiI0eOSLq1JHHGjBlq1KiRnJ2dFRQUpB9//FFHjhxRrVq15OLiomrVquno0aNmG2mztWbMmCFfX185OzurZcuWunjxonl87ty5WrVqlXlfREVFSZL279+v2rVry8nJSfny5VO3bt1s+pM2M23MmDHKnz+/PD099dZbb+nmzZsaNGiQvLy8VKRIEc2ePdumX0OGDFGpUqXk7Oys4sWLa/jw4bpx44b5OUVGRio2NtaMZ86cOWb/rZdknj59Wq1bt5aXl5dcXFwUEhKiHTt2ZPjZJCcnKykpyeYFAAAAAMCj6D+ZMBs6dKjGjRun4cOH6+DBg1q4cKHy589vHh82bJgGDhyomJgYlSpVSq1btzYTNkePHlV4eLheeukl7du3T0uWLNHWrVvVu3dvSdLu3bvVt29fvfXWW4qPj9fatWtVs2ZNSdLkyZNVtWpVde3aVYmJiUpMTJSvr2+WYh40aJAmTpyoXbt2ydvbW40bNzYTHNeuXVPlypX17bff6sCBA+rWrZvatm2rnTt33rHNiRMnKiQkRHv37lXPnj3Vo0cPxcfH3zWWtHY3bNigxMRELV++XDVr1lTx4sX1+eefm/Vu3LihBQsWqFOnTmbZlStX9M4772jevHmKjo7WhQsX9PLLL5vHt2zZonbt2qlfv346ePCgZsyYoTlz5tgkNO8kV65c+vDDD/Xzzz9r7ty52rhxowYPHmwe79Wrl5KTk7V582bt379f48ePl6urqywWizp16pQusTR79mzVrFlTJUuWNMvefvtttWvXTjExMQoMDNQrr7yi7t27a+jQodq9e7cMwzDvhzRHjhzRF198oa+//lpr1641x1ySBg4cqJYtWyo8PNy8L6pVq6bLly8rLCxMefPm1a5du/Tll19qw4YN6dreuHGjfvvtN23evFnvv/++Ro4cqUaNGilv3rzasWOHIiIi1L17d50+fdo8x83NTXPmzNHBgwc1efJkzZw5Ux988IEkqVWrVhowYIDKli1rxtOqVat0Y33p0iWFhobq119/1VdffaXY2FgNHjxYqampGX42Y8eOlYeHh/nK6r0PAAAAAMA/zWIYhpHTQfyT/v77b3l7e2vq1Knq0qWLzbGEhAQVK1ZMs2bNUufOnSVJBw8eVNmyZRUXF6fAwEB16dJFdnZ2mjFjhnne1q1bFRoaqsuXL2v16tXq2LGjTp8+LTc3t3TXr1WrlipUqKBJkyZlKd6oqCg999xzWrx4sZm0OHfunIoUKaI5c+aoZcuWGZ7XqFEjBQYGmjOmbr+uv7+/atSoYSa4DMNQgQIFFBkZqYiIiDvGlDZOe/futdnn6t133zWTMNKtfdPat2+v33//XS4uLpozZ446duyo7du36+mnn5Yk/fLLLwoKCtKOHTtUpUoV1a1bV3Xq1NHQoUPNdufPn6/Bgwfrt99+y9KYWVu6dKkiIiJ09uxZSVK5cuX00ksvaeTIkenq/vbbbypatKi2bdumKlWq6MaNGypUqJAmTJig9u3bS7o1w+rNN98094Pbvn27qlatqk8//dRMDC5evFgdO3bU1atXJd2aQTZ69GidOHFChQsXliStXbtWDRs21K+//qoCBQqoQ4cOunDhgs3srZkzZ2rIkCE6deqUXFxcJEmrV69W48aN9dtvvyl//vzq0KGDoqKidOzYMeXKdSv/HRgYKB8fH23evFmSlJKSIg8PD82aNcsmOWltwoQJWrx4sXbv3m3GvHLlynT71FksFq1YsUJNmzbVJ598ooEDByohISFLS36Tk5OVnJxsvk9KSpKvr68uXrwod3f3u54PAP91qz5jD0kAj48mndbkdAgAkE5SUpI8PDyy9Dv0PzfDLC4uTsnJyapTp06mdcqVK2f+u2DBgpKkM2fOSJJiY2M1Z84cubq6mq+wsDClpqbq+PHjev755+Xn56fixYurbdu2WrBgga5cuXLfcVetWtX8t5eXl0qXLq24uDhJtxIib7/9toKDg+Xl5SVXV1etW7dOJ0+evGOb1v20WCwqUKCA2c970aFDBx05ckTbt2+XJDOhl5bskSR7e3s99dRT5vvAwEB5enqafYmNjdVbb71lM75pM/KyMo4bNmxQnTp1VLhwYbm5ualt27b666+/zHP79u2r0aNHq3r16ho5cqT27dtnnluoUCE1bNhQn332mSTp66+/VnJyslq0aGFzDetxS5uZGBwcbFN27do1myWHRYsWNZNl0q3PMzU19Y4z+uLi4lS+fHmb8atevXq688qWLWsmy9Kubx2PnZ2d8uXLZ/PZLlmyRNWrV1eBAgXk6uqqN9988673y+1iYmJUsWLFLO+P5+DgIHd3d5sXAAAAAACPov9cwszJyemudXLnzm3+22KxSJK5zOzSpUvq3r27YmJizFdsbKwOHz6sEiVKyM3NTT/99JMWLVqkggULasSIESpfvrwuXLjwUPojSe+9954mT56sIUOGaNOmTYqJiVFYWJiuX7+e5X5Kt/qa2XK6rPDx8VHjxo01e/Zs/fHHH1qzZo3NcsysuHTpkiIjI23Gd//+/Tp8+LAcHR3veG5CQoIaNWqkcuXKadmyZdqzZ48++ugjSTLHokuXLjp27Jjatm2r/fv3KyQkRFOmTDHb6NKlixYvXqyrV69q9uzZatWqlZydnW2uk9H9cad75mHL6HO802f7448/qk2bNmrQoIG++eYb7d27V8OGDbvr/XK7rPwtAQAAAADwOPrPJcwCAgLk5OSk77///p7Or1Spkg4ePKiSJUume+XJk0fSrVlUdevW1bvvvqt9+/YpISFBGzdulCTlyZNHKSkp2b5u2qwtSTp//rwOHTqkoKAgSVJ0dLSaNGmiV199VeXLl1fx4sV16NChe+pfVqT1M6N+dOnSRUuWLNEnn3yiEiVKqHr16jbHb968aS77k6T4+HhduHDB7EulSpUUHx+f4fhaz6LKyJ49e5SamqqJEyfqmWeeUalSpTJcxunr66uIiAgtX75cAwYM0MyZM81jDRo0kIuLi6ZPn661a9dmO+GXmZMnT9rEsn37duXKlUulS5eWlPF9ERQUpNjYWJsHSkRHR9ucdy+2bdsmPz8/DRs2TCEhIQoICNCJEyds6mTlPi1XrpxiYmJ07ty5e44FAAAAAIBH0X8uYebo6KghQ4Zo8ODBmjdvno4ePart27fr008/zdL5Q4YM0bZt29S7d2/FxMTo8OHDWrVqlbkR+zfffKMPP/xQMTExOnHihObNm6fU1FQzweHv768dO3YoISFBZ8+ezfIspLfeekvff/+9Dhw4oA4dOuiJJ55Q06ZNJd1KAq5fv17btm1TXFycunfvrj/++CP7g5NFPj4+cnJy0tq1a/XHH3+YT3uUpLCwMLm7u2v06NHq2LFjunNz586tPn36aMeOHdqzZ486dOigZ555RlWqVJEkjRgxQvPmzVNkZKR+/vlnxcXFafHixXrzzTfvGlfJkiV148YNTZkyRceOHdPnn3+ujz/+2KZO//79tW7dOh0/flw//fSTNm3aZCbrpFvLFzt06KChQ4cqICDAZins/XB0dFT79u0VGxurLVu2qG/fvmrZsqUKFCgg6dZ9sW/fPsXHx+vs2bO6ceOG2rRpY5534MABbdq0SX369FHbtm1tHlKRXQEBATp58qQWL16so0eP6sMPP9SKFSts6vj7++v48eOKiYnR2bNnbfYeS9O6dWsVKFBATZs2VXR0tI4dO6Zly5ale6osAAAAAACPm/9cwkyShg8frgEDBmjEiBEKCgpSq1atsrx3V7ly5fTDDz/o0KFDqlGjhipWrKgRI0aoUKFCkiRPT08tX75ctWvXVlBQkD7++GMtWrRIZcuWlXTriYh2dnYqU6aMvL29s7xv1Lhx49SvXz9VrlxZv//+u77++mtzptebb76pSpUqKSwsTLVq1TKTGA+Lvb29PvzwQ82YMUOFChVSkyZNzGO5cuVShw4dlJKSonbt2qU719nZWUOGDNErr7yi6tWry9XVVUuWLDGPh4WF6ZtvvtF3332np556Ss8884w++OAD+fn53TWu8uXL6/3339f48eP15JNPasGCBRo7dqxNnZSUFPXq1UtBQUEKDw9XqVKlNG3aNJs6nTt31vXr1zNM+N2rkiVLqlmzZmrQoIHq1auncuXK2Vy3a9euKl26tEJCQuTt7a3o6Gg5Oztr3bp1OnfunJ566ik1b95cderU0dSpU+8rlhdeeEGvvfaaevfurQoVKmjbtm0aPny4TZ2XXnpJ4eHheu655+Tt7a1FixalaydPnjz67rvv5OPjowYNGig4OFjjxo2TnZ3dfcUHAAAAAEBO+889JfNxk/aUzPPnz8vT0zOnw8mSzp07688//9RXX31lUz5nzhz179//oe7n9iBs2bJFderU0alTp+5rJleazJ44+V+XnaeTAAB4SiaAxwtPyQTwKMrO71D7fygm/AdcvHhR+/fv18KFC9Mlyx4HycnJ+vPPPzVq1Ci1aNHigSTLAAAAAADA4+c/uSTzURIRESFXV9cMXxERETkS05gxYzKNqX79zP/vdpMmTVSvXj1FRETo+eeff+BxLViwINO40pa83o9FixbJz89PFy5c0LvvvvsAIgYAAAAAAI8jlmTmsDNnzigpKSnDY+7u7vLx8fmHI5LOnTuX6ZMPnZycVLhw4X84olv+/vvvTB9mkDt37iztc4ZHB0syASB7WJIJ4HHCkkwAjyKWZD5GfHx8ciQpdideXl7y8vLK6TDScXNzk5ubW06HAQAAAAAA/uVYkgkAAAAAAABYIWEGAAAAAAAAWCFhBgAAAAAAAFghYQYAAAAAAABYYdN/AACAxwBPnAMAAPjnMMMMAAAAAAAAsELCDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsGKf0wEAAAAAyNiMz8NyOgTgnnRvuy6nQwCA+8IMMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJM+A/bunSpQoODpaTk5Py5cununXr6vLly5KkWbNmKSgoSI6OjgoMDNS0adPM8zp16qRy5copOTlZknT9+nVVrFhR7dq1y5F+AAAAAADwoJAwA/7DEhMT1bp1a3Xq1ElxcXGKiopSs2bNZBiGFixYoBEjRuidd95RXFycxowZo+HDh2vu3LmSpA8//FCXL1/WG2+8IUkaNmyYLly4oKlTp2Z4reTkZCUlJdm8AAAAAAB4FNnndAAAck5iYqJu3rypZs2ayc/PT5IUHBwsSRo5cqQmTpyoZs2aSZKKFSumgwcPasaMGWrfvr1cXV01f/58hYaGys3NTZMmTdKmTZvk7u6e4bXGjh2ryMjIf6ZjAAAAAADcB4thGEZOBwEgZ6SkpCgsLEw7d+5UWFiY6tWrp+bNmytPnjxydXWVk5OTcuX6/xNRb968KQ8PD/3xxx9m2f/+9z+NHTtWQ4YM0bhx4zK9VnJysrl8U5KSkpLk6+urixcvZppkAwDgv27G52E5HQJwT7q3XZfTIQBAOklJSfLw8MjS71BmmAH/YXZ2dlq/fr22bdum7777TlOmTNGwYcP09ddfS5Jmzpypp59+Ot05aVJTUxUdHS07OzsdOXLkjtdycHCQg4PDg+8EAAAAAAAPGHuYAf9xFotF1atXV2RkpPbu3as8efIoOjpahQoV0rFjx1SyZEmbV7Fixcxz33vvPf3yyy/64YcftHbtWs2ePTsHewIAAAAAwIPBDDPgP2zHjh36/vvvVa9ePfn4+GjHjh36888/FRQUpMjISPXt21ceHh4KDw9XcnKydu/erfPnz+v111/X3r17NWLECC1dulTVq1fX+++/r379+ik0NFTFixfP6a4BAAAAAHDPSJgB/2Hu7u7avHmzJk2apKSkJPn5+WnixImqX7++JMnZ2VnvvfeeBg0aJBcXFwUHB6t///66du2aXn31VXXo0EGNGzeWJHXr1k3ffvut2rZtq82bN9ss3QQAAAAA4HHCpv8AckR2NlsEAOC/ik3/8bhi038Aj6Ls/A5lDzMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwIp9TgcAAAAAIGPd267L6RAAAPhPYoYZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYMU+pwMAAAAA8OgYsjQ8p0PAv8D45mtzOgQAuC/MMAMAAAAAAACskDADAAAAAAAArJAwAwAAAAAAAKyQMAMAAAAAAACskDADAAAAAAAArJAwAwAAAAAAAKyQMAMAAAAAAACskDADAAAAAAAArJAwAwAAAAAAAKyQMAMAAAAAAACskDADsmjUqFGqUKFCToeRo/z9/TVp0qScDgMAAAAAgIeKhBmQRQMHDtT333+f02EAAAAAAICHzD6nAwAeF66urnJ1db2vNm7cuKHcuXM/oIgAAAAAAMDDwAwz3JdatWqpb9++Gjx4sLy8vFSgQAGNGjVKkpSQkCCLxaKYmBiz/oULF2SxWBQVFSVJioqKksVi0bp161SxYkU5OTmpdu3aOnPmjNasWaOgoCC5u7vrlVde0ZUrV7IcU58+fdS/f3/lzZtX+fPn18yZM3X58mV17NhRbm5uKlmypNasWWOek5KSos6dO6tYsWJycnJS6dKlNXnyZJt2b1+SmZqaqrfeektFihSRg4ODKlSooLVr15rH0/q/ZMkShYaGytHRUQsWLMg07qSkJDk5OdnEJUkrVqyQm5ub2f9Tp06pZcuW8vT0lJeXl5o0aaKEhASzflRUlKpUqSIXFxd5enqqevXqOnHihCQpNjZWzz33nNzc3OTu7q7KlStr9+7d5rlbt25VjRo15OTkJF9fX/Xt21eXL1/OMF7DMDRq1CgVLVpUDg4OKlSokPr27Ztp/5KTk5WUlGTzAgAAAADgUUTCDPdt7ty5cnFx0Y4dO/Tuu+/qrbfe0vr167PVxqhRozR16lRt27bNTAhNmjRJCxcu1LfffqvvvvtOU6ZMyVZMTzzxhHbu3Kk+ffqoR48eatGihapVq6affvpJ9erVU9u2bc0kVGpqqooUKaIvv/xSBw8e1IgRI/S///1PX3zxRabXmDx5siZOnKgJEyZo3759CgsL0wsvvKDDhw/b1HvjjTfUr18/xcXFKSwsLNP23N3d1ahRIy1cuNCmfMGCBWratKmcnZ1148YNhYWFyc3NTVu2bFF0dLRcXV0VHh6u69ev6+bNm2ratKlCQ0O1b98+/fjjj+rWrZssFoskqU2bNipSpIh27dqlPXv26I033jBnvB09elTh4eF66aWXtG/fPi1ZskRbt25V7969M4x32bJl+uCDDzRjxgwdPnxYK1euVHBwcKb9Gzt2rDw8PMyXr69vpnUBAAAAAMhJFsMwjJwOAo+vWrVqKSUlRVu2bDHLqlSpotq1aysiIkLFihXT3r17zZlZFy5cUN68ebVp0ybVqlVLUVFReu6557RhwwbVqVNHkjRu3DgNHTpUR48eVfHixSVJERERSkhIsJnBldWYUlJS5OHhoWbNmmnevHmSpN9//10FCxbUjz/+qGeeeSbDdnr37q3ff/9dS5culXQrqbdy5UpzxlzhwoXVq1cv/e9//7Pp+1NPPaWPPvpICQkJKlasmCZNmqR+/fplaTxXrlyptm3b6o8//pCzs7OSkpKUP39+rVixQuHh4Zo/f75Gjx6tuLg4Mwl2/fp1eXp6auXKlQoJCVG+fPkUFRWl0NDQdO27u7trypQpat++fbpjXbp0kZ2dnWbMmGGWbd26VaGhobp8+bIcHR3l7++v/v37q3///nr//fc1Y8YMHThwIEvLTJOTk5WcnGy+T0pKkq+vry5evCh3d/csjQ8AAHj4hiwNz+kQ8C8wvvnd/7sdAP5pSUlJ8vDwyNLvUGaY4b6VK1fO5n3BggV15syZe24jf/78cnZ2NpNlaWXZadO6PTs7O+XLl89m9lP+/PklyabNjz76SJUrV5a3t7dcXV31ySef6OTJkxm2n5SUpN9++03Vq1e3Ka9evbri4uJsykJCQrIcd4MGDZQ7d2599dVXkm7N4nJ3d1fdunUl3VpSeeTIEbm5uZl7qnl5eenatWs6evSovLy81KFDB4WFhalx48aaPHmyEhMTzfZff/11denSRXXr1tW4ceN09OhR81hsbKzmzJljtuvq6qqwsDClpqbq+PHj6WJt0aKFrl69quLFi6tr165asWKFbt68mWnfHBwc5O7ubvMCAAAAAOBRRMIM9+322UUWi0WpqanKlevW7WU9ifHGjRt3bcNisWTa5v3EdPs1JJltLl68WAMHDlTnzp313XffKSYmRh07dtT169ezfM3MuLi4ZLlunjx51Lx5c3NZ5sKFC9WqVSvZ2996PselS5dUuXJlxcTE2LwOHTqkV155RZI0e/Zs/fjjj6pWrZqWLFmiUqVKafv27ZJuzZL7+eef1bBhQ23cuFFlypTRihUrzLa7d+9u025sbKwOHz6sEiVKpIvV19dX8fHxmjZtmpycnNSzZ0/VrFkz088YAAAAAIDHBU/JxEPj7e0tSUpMTFTFihUlyeYBAI+S6OhoVatWTT179jTLrGdf3c7d3V2FChVSdHS0zdLH6OhoValS5b5iadOmjZ5//nn9/PPP2rhxo0aPHm0eq1SpkpYsWSIfH587ztCqWLGiKlasqKFDh6pq1apauHChufS0VKlSKlWqlF577TW1bt1as2fP1osvvqhKlSrp4MGDKlmyZJZjdXJyUuPGjdW4cWP16tVLgYGB2r9/vypVqnTvAwAAAAAAQA5jhhkeGicnJz3zzDMaN26c4uLi9MMPP+jNN9/M6bAyFBAQoN27d2vdunU6dOiQhg8frl27dt3xnEGDBmn8+PFasmSJ4uPj9cYbbygmJibL+5VlpmbNmipQoIDatGmjYsWK6emnnzaPtWnTRk888YSaNGmiLVu26Pjx44qKilLfvn11+vRpHT9+XEOHDtWPP/6oEydO6LvvvtPhw4cVFBSkq1evqnfv3oqKitKJEycUHR2tXbt2KSgoSJI0ZMgQbdu2Tb1791ZMTIwOHz6sVatWZbrp/5w5c/Tpp5/qwIEDOnbsmObPny8nJyf5+fndV/8BAAAAAMhpJMzwUH322We6efOmKleurP79+9vMlnqUdO/eXc2aNVOrVq309NNP66+//rKZbZaRvn376vXXX9eAAQMUHBystWvX6quvvlJAQMB9xWKxWNS6dWvFxsaqTZs2NsecnZ21efNmFS1aVM2aNVNQUJA6d+6sa9euyd3dXc7Ozvrll1/00ksvqVSpUurWrZt69eql7t27y87OTn/99ZfatWunUqVKqWXLlqpfv74iIyMl3dr37YcfftChQ4dUo0YNVaxYUSNGjFChQoUyjNPT01MzZ85U9erVVa5cOW3YsEFff/218uXLd1/9BwAAAAAgp/GUTCCLhg4dqi1btmjr1q05Hcq/QnaeTgIAAP45PCUTDwJPyQTwKOIpmcADZBiGjh49qu+//15ly5bN6XAAAAAAAMBDRsIMj5WTJ0/K1dU109fJkycf+DUvXryoMmXKKE+ePPrf//53X23Vr18/09jHjBnzgCIGAAAAAAD3g6dk4rFSqFChOz5pM7P9tu6Hp6enkpOTH0hbs2bN0tWrVzM85uXl9UCuAQAAAAAA7g8JMzxW7O3tVbJkyZwO454VLlw4p0MAAAAAAAB3wZJMAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAqb/gMAAAAwjW++NqdDAAAgxzHDDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDAAAAAAAALBCwgwAAAAAAACwQsIMAAAAAAAAsELCDAAAAAAAALBin9MBAAAAAACypsHKATkdQpasbjoxp0MAgPvCDDMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTMAAAAAAADACgkzAAAAAAAAwAoJMwAAAAAAAMAKCTPgPiQkJMhisSgmJianQ7kvHTp0UNOmTXM6DAAAAAAAHgn2OR0AkFM6dOigCxcuaOXKlTkdSo6bPHmyDMPI6TAAAAAAAHgkkDADHgPXr19Xnjx5Hlr7Hh4eD61tAAAAAAAeNyzJxL/e0qVLFRwcLCcnJ+XLl09169bVoEGDNHfuXK1atUoWi0UWi0VRUVF3bWvnzp2qWLGiHB0dFRISor1796arc+DAAdWvX1+urq7Knz+/2rZtq7Nnz5rHa9Wqpd69e6t3797y8PDQE088oeHDh9vM8PL399fbb7+tdu3ayd3dXd26dZMkbd26VTVq1JCTk5N8fX3Vt29fXb582Txv2rRpCggIkKOjo/Lnz6/mzZvfcRzSzr19SWZycrL69u0rHx8fOTo66tlnn9WuXbvM41FRUbJYLPr+++8VEhIiZ2dnVatWTfHx8Xf/QAAAAAAAeMSRMMO/WmJiolq3bq1OnTopLi5OUVFRatasmUaOHKmWLVsqPDxciYmJSkxMVLVq1e7Y1qVLl9SoUSOVKVNGe/bs0ahRozRw4ECbOhcuXFDt2rVVsWJF7d69W2vXrtUff/yhli1b2tSbO3eu7O3ttXPnTk2ePFnvv/++Zs2aZVNnwoQJKl++vPbu3avhw4fr6NGjCg8P10svvaR9+/ZpyZIl2rp1q3r37i1J2r17t/r27au33npL8fHxWrt2rWrWrHnHcchsGebgwYO1bNkyzZ07Vz/99JNKliypsLAwnTt3zqbesGHDNHHiRO3evVv29vbq1KlTpuOXnJyspKQkmxcAAAAAAI8ilmTiXy0xMVE3b95Us2bN5OfnJ0kKDg6WJDk5OSk5OVkFChTIUlsLFy5UamqqPv30Uzk6Oqps2bI6ffq0evToYdaZOnWqKlasqDFjxphln332mXx9fXXo0CGVKlVKkuTr66sPPvhAFotFpUuX1v79+/XBBx+oa9eu5nm1a9fWgAEDzPddunRRmzZt1L9/f0lSQECAPvzwQ4WGhmr69Ok6efKkXFxc1KhRI7m5ucnPz08VK1a86zjc7vLly5o+fbrmzJmj+vXrS5Jmzpyp9evX69NPP9WgQYPMuu+8845CQ0MlSW+88YYaNmyoa9euydHRMV27Y8eOVWRkZJbGGgAAAACAnMQMM/yrlS9fXnXq1FFwcLBatGihmTNn6vz58/fUVlxcnMqVK2eTDKpatapNndjYWG3atEmurq7mKzAwUJJ09OhRs94zzzwji8Vi087hw4eVkpJiloWEhKRre86cOTZth4WFKTU1VcePH9fzzz8vPz8/FS9eXG3bttWCBQt05cqVbI/D0aNHdePGDVWvXt0sy507t6pUqaK4uDibuuXKlTP/XbBgQUnSmTNnMmx36NChunjxovk6depUhvUAAAAAAMhpJMzwr2ZnZ6f169drzZo1KlOmjKZMmaLSpUvr+PHjD+V6ly5dUuPGjRUTE2PzOnz4sLk8MqtcXFzStd29e3ebdmNjY3X48GGVKFFCbm5u+umnn7Ro0SIVLFhQI0aMUPny5XXhwoWHNg65c+c2/52WAExNTc2wroODg9zd3W1eAAAAAAA8ikiY4V/PYrGoevXqioyM1N69e5UnTx6tWLFCefLksZnRdTdBQUHat2+frl27ZpZt377dpk6lSpX0888/y9/fXyVLlrR5WSfAduzYYXPe9u3bFRAQIDs7u0yvX6lSJR08eDBduyVLljSfoGlvb6+6devq3Xff1b59+5SQkKCNGzfecRxuV6JECeXJk0fR0dFm2Y0bN7Rr1y6VKVMmy+MFAAAAAMDjioQZ/tV27NihMWPGaPfu3Tp58qSWL1+uP//8U0FBQfL399e+ffsUHx+vs2fP6saNG3ds65VXXpHFYlHXrl118OBBrV69WhMmTLCp06tXL507d06tW7fWrl27dPToUa1bt04dO3a0Sc6dPHlSr7/+uuLj47Vo0SJNmTJF/fr1u+P1hwwZom3btql3797mrLVVq1aZm/5/8803+vDDDxUTE6MTJ05o3rx5Sk1NVenSpe84DrdzcXFRjx49NGjQIK1du1YHDx5U165ddeXKFXXu3DmrQw8AAAAAwGOLTf/xr+bu7q7Nmzdr0qRJSkpKkp+fnyZOnKj69esrJCREUVFRCgkJ0aVLl7Rp0ybVqlUr07ZcXV319ddfKyIiQhUrVlSZMmU0fvx4vfTSS2adQoUKKTo6WkOGDFG9evWUnJwsPz8/hYeHK1eu/5+fbteuna5evaoqVarIzs5O/fr1U7du3e7Yl3LlyumHH37QsGHDVKNGDRmGoRIlSqhVq1aSJE9PTy1fvlyjRo3StWvXFBAQoEWLFqls2bKKi4vLdBwyMm7cOKWmpqpt27b6+++/FRISonXr1ilv3rzZGH0AAAAAAB5PFsMwjJwOAvgvqVWrlipUqKBJkybldCg5KikpSR4eHrp48SL7mQEAAGRRg5UD7l7pEbC66cScDgEA0snO71CWZAIAAAAAAABWSJgB/2fMmDFydXXN8JXZ0kUAAAAAAPDvwx5mwP+JiIhQy5YtMzzm5OT0wK4TFRX1wNoCAAAAAAAPHgkz4P94eXnJy8srp8MAAAAAAAA5jCWZAAAAAAAAgBUSZgAAAAAAAIAVEmYAAAAAAACAFRJmAAAAAAAAgBU2/QcAAACAx8TqphNzOgQA+E9ghhkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAOCBabh8Sk6HAAD3jYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGQAAAAAAAGCFhBkAAAAAAABghYQZAAAAAAAAYIWEGe5LQkKCLBaLYmJi/rFrdujQQU2bNr1jnVq1aql///4PPRZ/f39NmjTpoV8HAAAAAAD8c+xzOgA8Pjp06KALFy5o5cqVZpmvr68SExP1xBNP5FxgAAAAAAAAD9A9zzD7/PPPVb16dRUqVEgnTpyQJE2aNEmrVq16YMHhwbp+/foDb9POzk4FChSQvT2514fhxo0bOR1COo9iTAAAAAAAPEj3lDCbPn26Xn/9dTVo0EAXLlxQSkqKJMnT05PlaY+QWrVqqXfv3urfv7+eeOIJhYWF6cCBA6pfv75cXV2VP39+tW3bVmfPnjXPWbp0qYKDg+Xk5KR8+fKpbt26unz5skaNGqW5c+dq1apVslgsslgsioqKSrckMyoqShaLRd9//71CQkLk7OysatWqKT4+3ia20aNHy8fHR25uburSpYveeOMNVahQIVv9i4yMlLe3t9zd3RUREXHHhOD58+fVrl075c2bV87Ozqpfv74OHz5sU2fZsmUqW7asHBwc5O/vr4kTJ9ocP3PmjBo3biwnJycVK1ZMCxYsyFa8FotF06dPV/369eXk5KTixYtr6dKl5vG0sVyyZIlCQ0Pl6OhoXmPWrFkKCgqSo6OjAgMDNW3aNPO869evq3fv3ipYsKAcHR3l5+ensWPHSpIMw9CoUaNUtGhROTg4qFChQurbt69NTNYzBqVbf8dz5sy5r5gykpycrKSkJJsXAAAAAACPontKmE2ZMkUzZ87UsGHDZGdnZ5aHhIRo//79Dyw43L+5c+cqT548io6O1rhx41S7dm1VrFhRu3fv1tq1a/XHH3+oZcuWkqTExES1bt1anTp1UlxcnKKiotSsWTMZhqGBAweqZcuWCg8PV2JiohITE1WtWrVMrzts2DBNnDhRu3fvlr29vTp16mQeW7Bggd555x2NHz9ee/bsUdGiRTV9+vRs9ev77783Y1y0aJGWL1+uyMjITOt36NBBu3fv1ldffaUff/xRhmGoQYMG5mypPXv2qGXLlnr55Ze1f/9+jRo1SsOHDzcTR2ltnDp1Sps2bdLSpUs1bdo0nTlzJltxDx8+XC+99JJiY2PVpk0bvfzyy4qLi7Op88Ybb6hfv36Ki4tTWFiYFixYoBEjRuidd95RXFycxowZo+HDh2vu3LmSpA8//FBfffWVvvjiC8XHx2vBggXy9/eXdCsJ+MEHH2jGjBk6fPiwVq5cqeDg4GzFfC8xZWTs2LHy8PAwX76+vtmOAwAAAACAf4RxDxwdHY2EhATDMAzD1dXVOHr0qGEYhnHo0CHD0dHxXprEQxAaGmpUrFjRfP/2228b9erVs6lz6tQpQ5IRHx9v7Nmzx5Bkfra3a9++vdGkSRObsuPHjxuSjL179xqGYRibNm0yJBkbNmww63z77beGJOPq1auGYRjG008/bfTq1cumnerVqxvly5fPUr/at29veHl5GZcvXzbLpk+fbri6uhopKSlm3/v162cYxq37UpIRHR1t1j979qzh5ORkfPHFF4ZhGMYrr7xiPP/88zbXGTRokFGmTBnDMAwjPj7ekGTs3LnTPB4XF2dIMj744IMsxS3JiIiIsCl7+umnjR49ehiG8f/HctKkSTZ1SpQoYSxcuNCm7O233zaqVq1qGIZh9OnTx6hdu7aRmpqa7poTJ040SpUqZVy/fj3TmFasWGFT5uHhYcyePfu+YsrItWvXjIsXL5qvtHvv4sWLmZ4DAACAx0+DZR/mdAgAkKGLFy9m+XfoPc0wK1asWIZPRVy7dq2CgoLupUk8JJUrVzb/HRsbq02bNsnV1dV8BQYGSpKOHj2q8uXLq06dOgoODlaLFi00c+ZMnT9//p6uW65cOfPfBQsWlCRzNlZ8fLyqVKliU//293dTvnx5OTs7m++rVq2qS5cu6dSpU+nqxsXFyd7eXk8//bRZli9fPpUuXdqc3RUXF6fq1avbnFe9enUdPnxYKSkpZhvW4xkYGChPT89sxV21atV072+fYRYSEmL++/Llyzp69Kg6d+5s87mNHj1aR48elXRr5ltMTIxKly6tvn376rvvvjPPb9Giha5evarixYura9euWrFihW7evJmtmO8lpow4ODjI3d3d5gUAAAAAwKPonnZqf/3119WrVy9du3ZNhmFo586dWrRokcaOHatZs2Y96BhxH1xcXMx/X7p0SY0bN9b48ePT1StYsKDs7Oy0fv16bdu2Td99952mTJmiYcOGaceOHSpWrFi2rps7d27z3xaLRZKUmpp6j734b7n9M5OkmTNn2iT8JJnLoStVqqTjx49rzZo12rBhg1q2bKm6detq6dKl8vX1VXx8vDZs2KD169erZ8+eeu+99/TDDz8od+7cslgsMgzDpt2MNvXPbkwAAAAAADzO7mmGWZcuXTR+/Hi9+eabunLlil555RVNnz5dkydP1ssvv/ygY8QDUqlSJf3888/y9/dXyZIlbV5pCRGLxaLq1asrMjJSe/fuVZ48ebRixQpJUp48ecwHPNyP0qVLa9euXTZlt7+/m9jYWF29etV8v337drm6uma4L1ZQUJBu3rypHTt2mGV//fWX4uPjVaZMGbNOdHS0zXnR0dEqVaqU7OzsFBgYqJs3b2rPnj3m8fj4eF24cCFbcW/fvj3d+zvNysyfP78KFSqkY8eOpfvMrJOY7u7uatWqlWbOnKklS5Zo2bJlOnfunCTJyclJjRs31ocffqioqCj9+OOP5l6D3t7eSkxMNNs5fPiwrly5csc+ZDUmAAAAAAAeV9meYXbz5k0tXLhQYWFhatOmja5cuaJLly7Jx8fnYcSHB6hXr16aOXOmWrdurcGDB8vLy0tHjhzR4sWLNWvWLO3evVvff/+96tWrJx8fH+3YsUN//vmnmdDx9/fXunXrFB8fr3z58snDw+Oe4ujTp4+6du2qkJAQVatWTUuWLNG+fftUvHjxLLdx/fp1de7cWW+++aYSEhI0cuRI9e7dW7lypc8BBwQEqEmTJuratatmzJghNzc3vfHGGypcuLCaNGkiSRowYICeeuopvf3222rVqpV+/PFHTZ061XzyY+nSpRUeHq7u3btr+vTpsre3V//+/eXk5JStvn/55ZcKCQnRs88+qwULFmjnzp369NNP73hOZGSk+vbtKw8PD4WHhys5OVm7d+/W+fPn9frrr+v9999XwYIFVbFiReXKlUtffvmlChQoYD7tMiUlRU8//bScnZ01f/58OTk5yc/PT5JUu3ZtTZ06VVWrVlVKSoqGDBliMzvwXmMCAAAAAOBxlu0ZZvb29oqIiNC1a9ckSc7OziTLHhOFChVSdHS0UlJSVK9ePQUHB6t///7y9PRUrly55O7urs2bN6tBgwYqVaqU3nzzTU2cOFH169eXJHXt2lWlS5dWSEiIvL29083Iyqo2bdpo6NChGjhwoLmcsEOHDnJ0dMxyG3Xq1FFAQIBq1qypVq1a6YUXXtCoUaMyrT979mxVrlxZjRo1UtWqVWUYhlavXm0mhypVqqQvvvhCixcv1pNPPqkRI0borbfeUocOHWzaKFSokEJDQ9WsWTN169Yt2/d+ZGSkFi9erHLlymnevHlatGiROcstM126dNGsWbM0e/ZsBQcHKzQ0VHPmzDFnc7m5uendd99VSEiInnrqKSUkJGj16tXKlSuXPD09NXPmTFWvXl3lypXThg0b9PXXXytfvnySpIkTJ8rX11c1atTQK6+8ooEDB9rsDXevMQEAAAAA8DizGLdvYJQFtWrVUv/+/dW0adOHEBL+i55//nkVKFBAn3/+eU6H8tBYLBatWLGCv5v/k5SUJA8PD128eJEHAAAAAPyLNFw+Rd8265PTYQBAOtn5HXpPm/737NlTAwYM0OnTp1W5cmWbDcEl2yckAre7cuWKPv74Y4WFhcnOzk6LFi0yN6UHAAAAAADIafeUMEvb2L9v375mWdrT9iwWywPZGB7/XhaLRatXr9Y777yja9euqXTp0lq2bJnq1q0rSXJ1dc303DVr1qhGjRr/VKhZtmDBAnXv3j3DY35+fvr555//4YgAAAAAAMC9uqeE2fHjxx90HPgPcXJy0oYNGzI9HhMTk+mxwoULP4SI7t8LL7ygp59+OsNjafuk3cPqZwAAAAAAkAPuKWGW9oQ94GEoWbJkToeQbW5ubnJzc8vpMAAAAAAAwANwTwmzefPm3fF4u3bt7ikYAAAAAAAAIKfdU8KsX79+Nu9v3LihK1euKE+ePHJ2diZhBgAAAAAAgMdWrns56fz58zavS5cuKT4+Xs8++6wWLVr0oGMEAAAAAAAA/jH3lDDLSEBAgMaNG5du9hkAAAAAAADwOHlgCTNJsre312+//fYgmwQAAAAAPEa+bdYnp0MAgPt2T3uYffXVVzbvDcNQYmKipk6dqurVqz+QwAAAAAAAAICccE8Js6ZNm9q8t1gs8vb2Vu3atTVx4sQHERcAAAAAAACQI+4pYZaamvqg4wAAAAAAAAAeCfe0h9lbb72lK1eupCu/evWq3nrrrfsOCgAAAAAAAMgpFsMwjOyeZGdnp8TERPn4+NiU//XXX/Lx8VFKSsoDCxDAv1NSUpI8PDx08eJFubu753Q4AAAAAIB/uez8Dr2nGWaGYchisaQrj42NlZeX1700CQAAAAAAADwSsrWHWd68eWWxWGSxWFSqVCmbpFlKSoouXbqkiIiIBx4kAAAAAAAA8E/JVsJs0qRJMgxDnTp1UmRkpDw8PMxjefLkkb+/v6pWrfrAgwQAAAAAAAD+KdlKmLVv316SVKxYMVWrVk25c+d+KEEBAAAAAAAAOSVbCbM0oaGh5r+vXbum69ev2xxnA28AAAAAAAA8ru5p0/8rV66od+/e8vHxkYuLi/LmzWvzAgAAAAAAAB5X95QwGzRokDZu3Kjp06fLwcFBs2bNUmRkpAoVKqR58+Y96BgBAAAAAACAf8w9Lcn8+uuvNW/ePNWqVUsdO3ZUjRo1VLJkSfn5+WnBggVq06bNg44TAAAAAAAA+Efc0wyzc+fOqXjx4pJu7Vd27tw5SdKzzz6rzZs3P7joAAAAAAAAgH/YPSXMihcvruPHj0uSAgMD9cUXX0i6NfPM09PzgQUHAAAAAAAA/NPuKWHWseP/a+/Ow2s69///v7ZEJpkaEkmIJAjCiXloqKlCcOpQai5CUG1TVY3SY0qooSpq6uDDqdCTltZUrZk2pTHFrEQQTaM9UVWSSMzJ/v3hZ3/3bohEEfT5uK59Xdlr3ete77V2dp28zn3fq78OHjwoSRo1apQ++OAD2dnZ6Y033tCIESPua4EAAAAAAADAw2QwGo3Gv9rJzz//rL1796py5cqqWbPm/agLwBMuKytLLi4uyszMlLOzc3GXAwAAAAB4whXl79B7GmFm7sqVK/L19VXnzp0Jy/C3lZqaKoPBoAMHDvylfvz8/DRz5sz7UtPDFhsby5RsAAAAAMAT4Z4Cs9zcXE2cOFHlypWTo6OjTp06JUkaO3as/vOf/9zXAgHcGwIsAAAAAADuzT0FZpMmTVJsbKymTZsmGxsb0/Z//OMfWrBgwX0rDkDxy83NVV5eXnGXAQAAAADAQ3NPgdnixYv1f//3f+rdu7esrKxM22vVqqVjx47dt+KAR01eXp6mTZumypUry9bWVhUqVNCkSZNM+0+dOqWWLVvKwcFBtWrV0o4dOyyOX758uWrUqCFbW1v5+fkpJiamwPNlZGRo4MCBcnd3l7Ozs5599lnTAzck6eDBg2rZsqWcnJzk7OysevXqac+ePYqPj1f//v2VmZkpg8Egg8GgqKgoSdLVq1cVGRmpcuXKqVSpUmrUqJHi4+NNfd4ambZ69WpVr15dtra2SktL04ULF9S3b1899dRTcnBwULt27XTixIm/flMBAAAAAHjE3FNg9uuvv6py5cr5tufl5en69et/uSjgUfX2229r6tSpGjt2rI4eParPPvtMZcuWNe0fPXq0IiMjdeDAAVWpUkU9e/bUjRs3JEl79+5Vt27d1KNHDx0+fFhRUVEaO3asYmNj73i+rl276uzZs1q3bp327t2runXrqlWrVjp//rwkqXfv3ipfvrwSExO1d+9ejRo1SiVLllTjxo01c+ZMOTs7Kz09Xenp6YqMjJQkRUREaMeOHVqyZIkOHTqkrl27qm3bthbh16VLl/Tuu+9qwYIFOnLkiDw8PBQWFqY9e/Zo9erV2rFjh4xGo9q3b1/o7/zVq1eVlZVl8QIAAAAA4FFkfS8HVa9eXdu2bZOvr6/F9mXLlqlOnTr3pTDgUXPx4kXNmjVLc+fOVb9+/SRJlSpV0jPPPKPU1FRJUmRkpP75z39KkqKjo1WjRg2dPHlS1apV04wZM9SqVSuNHTtWklSlShUdPXpU7733nsLCwvKd74cfftDu3bt19uxZ2draSpKmT5+uVatWadmyZRo8eLDS0tI0YsQIVatWTZIUEBBgOt7FxUUGg0Genp6mbWlpaVq4cKHS0tLk7e1tqnn9+vVauHChJk+eLEm6fv26PvzwQ9WqVUuSdOLECa1evVoJCQlq3LixJCkuLk4+Pj5atWqVunbtetf7N2XKFEVHRxfuZgMAAAAAUIzuKTAbN26c+vXrp19//VV5eXlasWKFkpOTtXjxYn3zzTf3u0bgkZCUlKSrV6+qVatWd2xj/qRYLy8vSdLZs2dVrVo1JSUlqWPHjhbtmzRpopkzZyo3N9dierN0c7pldna2SpcubbH98uXLSklJkSQNHz5cAwcO1KeffqqQkBB17dpVlSpVumN9hw8fVm5urqpUqWKx/erVqxbnsbGxsbiWpKQkWVtbq1GjRqZtpUuXVtWqVZWUlHTH85l7++23NXz4cNP7rKws+fj4FOpYAAAAAAAepiIFZqdOnZK/v786duyor7/+WhMmTFCpUqU0btw41a1bV19//bVat279oGoFipW9vf1d25QsWdL0s8FgkKR7XjA/OztbXl5eFuuL3XLr6ZdRUVHq1auX1qxZo3Xr1mn8+PFasmSJnn/++Tv2aWVlpb179+YL6BwdHU0/29vbm+q/X2xtbU0j5QAAAAAAeJQVKTALCAhQenq6PDw81LRpU7m5uenw4cMWazgBT6qAgADZ29try5YtGjhwYJGPDwwMVEJCgsW2hIQEValSJV94JUl169bVmTNnZG1tLT8/vzv2W6VKFVWpUkVvvPGGevbsqYULF+r555+XjY2NcnNzLdrWqVNHubm5Onv2rJo2bVqk2m/cuKFdu3aZpmT+8ccfSk5OVvXq1QvdDwAAAAAAj4MiLfpvNBot3q9bt045OTn3tSDgUWVnZ6eRI0fqrbfe0uLFi5WSkqKdO3fqP//5T6GOf/PNN7VlyxZNnDhRx48f16JFizR37lzTYvx/FhISouDgYHXq1EkbN25Uamqqtm/frtGjR2vPnj26fPmyIiIiFB8fr59//lkJCQlKTExUYGCgJMnPz0/Z2dnasmWLzp07p0uXLqlKlSrq3bu3+vbtqxUrVuinn37S7t27NWXKFK1Zs+aOtQcEBKhjx44aNGiQfvjhBx08eFAvvviiypUrl2+aKQAAAAAAj7t7ekrmLX8O0IAn3dixY/Xmm29q3LhxCgwMVPfu3XX27NlCHVu3bl198cUXWrJkif7xj39o3LhxmjBhwm0X/JduTulcu3atmjVrpv79+6tKlSrq0aOHfv75Z5UtW1ZWVlb6448/1LdvX1WpUkXdunVTu3btTAvrN27cWEOGDFH37t3l7u6uadOmSZIWLlyovn376s0331TVqlXVqVMnJSYmqkKFCgXWv3DhQtWrV0/PPfecgoODZTQatXbtWotpqAAAAAAAPAkMxiKkXlZWVjpz5ozc3d0lSU5OTjp06JD8/f0fWIEAnkxZWVlycXFRZmamnJ2di7scAAAAAMATrih/hxZpDTOj0aiwsDDTwt1XrlzRkCFDVKpUKYt2K1asKGLJAAAAAAAAwKOhSIFZv379LN6/+OKL97UYAAAAAAAAoLgVKTBbuHDhg6oDAAAAAAAAeCT8pUX/AQAAAAAAgCcNgRkAAAAAAABghsAMAAAAAAAAMENgBgAAAAAAAJghMAMAAAAAAADMEJgBAAAAAAAAZgjMAAAAAAAAADMEZgAAAAAAAIAZAjMAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzAAAAAAAAAAzBGYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGCGwAwAAAAAAAAwQ2AGAAAAAAAAmCEwAwAAAAAAAMwQmAEAAAAAAABmCMwAAAAAAAAAMwRmAAAAAAAAgBkCMzyRDAaDVq1aVdxlPBaOHTump59+WnZ2dqpdu7ZSU1NlMBh04MCB4i4NAAAAAIBiQWCGR0JYWJg6depU3GU8MPHx8TIYDMrIyCjuUvIZP368SpUqpeTkZG3ZsuWe+njSPz8AAAAAwN8LgRnwN5eSkqJnnnlGvr6+Kl26dHGXAwAAAABAsSMww0O1bNkyBQUFyd7eXqVLl1ZISIhGjBihRYsW6auvvpLBYJDBYFB8fHyB/Vy7dk0RERHy8vKSnZ2dfH19NWXKlDu2P3z4sJ599lnTeQcPHqzs7GzT/lsjpKKjo+Xu7i5nZ2cNGTJE165dM7XJy8vTlClT5O/vL3t7e9WqVUvLli276zWnpqaqZcuWkqSnnnpKBoNBYWFhWrx4sUqXLq2rV69atO/UqZP69OkjSYqKilLt2rU1b948+fj4yMHBQd26dVNmZqbFMQsWLFBgYKDs7OxUrVo1ffjhh3etS7o5dXXv3r2aMGGCDAaDoqKi8rXJzc1VeHi46bqrVq2qWbNmmfZHRUUV6vO7evWqsrKyLF4AAAAAADyKrIu7APx9pKenq2fPnpo2bZqef/55Xbx4Udu2bVPfvn2VlpamrKwsLVy4UJLk5uZWYF+zZ8/W6tWr9cUXX6hChQo6ffq0Tp8+fdu2OTk5Cg0NVXBwsBITE3X27FkNHDhQERERio2NNbXbsmWL7OzsFB8fr9TUVPXv31+lS5fWpEmTJElTpkzRf//7X3388ccKCAjQ1q1b9eKLL8rd3V3Nmze/Y60+Pj5avny5unTpouTkZDk7O8ve3l42NjYaOnSoVq9era5du0qSzp49qzVr1mjjxo2m40+ePKkvvvhCX3/9tbKyshQeHq5XXnlFcXFxkqS4uDiNGzdOc+fOVZ06dbR//34NGjRIpUqVUr9+/e76mYSEhKht27aKjIyUo6Ojzp07Z9EmLy9P5cuX15dffqnSpUtr+/btGjx4sLy8vNStWzdFRkYqKSnprp/flClTFB0dXWA9AAAAAAA8CgjM8NCkp6frxo0b6ty5s3x9fSVJQUFBkiR7e3tdvXpVnp6eheorLS1NAQEBeuaZZ2QwGEz93c5nn32mK1euaPHixSpVqpQkae7cuerQoYPeffddlS1bVpJkY2OjTz75RA4ODqpRo4YmTJigESNGaOLEibp+/bomT56szZs3Kzg4WJJUsWJF/fDDD5o3b16BgZmVlZUpQPLw8JCrq6tpX69evbRw4UJTYPbf//5XFSpUUIsWLUxtbtVerlw5SdKcOXP0z3/+UzExMfL09NT48eMVExOjzp07S5L8/f119OhRzZs3766Bmaenp6ytreXo6Gi6938OzEqWLGkRdPn7+2vHjh364osv1K1bNzk6Ohbq83v77bc1fPhw0/usrCz5+PgUWB8AAAAAAMWBwAwPTa1atdSqVSsFBQUpNDRUbdq00QsvvKCnnnqqyH2FhYWpdevWqlq1qtq2bavnnntObdq0uW3bpKQk1apVyxSWSVKTJk2Ul5en5ORkU2BWq1YtOTg4mNoEBwcrOztbp0+fVnZ2ti5duqTWrVtb9H3t2jXVqVOnyPXfMmjQIDVo0EC//vqrypUrp9jYWIWFhclgMJjaVKhQwRSW3arrVu1OTk5KSUlReHi4Bg0aZGpz48YNubi43HNdf/bBBx/ok08+UVpami5fvqxr166pdu3aRerD1tZWtra2960mAAAAAAAeFAIzPDRWVlbatGmTtm/fro0bN2rOnDkaPXq0du3aVeS+6tatq59++knr1q3T5s2b1a1bN4WEhBRqTbF7cWu9szVr1liEV5L+UghUp04d1apVS4sXL1abNm105MgRrVmzpsh1zZ8/X40aNbLYZ2Vldc91mVuyZIkiIyMVExOj4OBgOTk56b333runzw0AAAAAgMcBgRkeKoPBoCZNmqhJkyYaN26cfH19tXLlStnY2Cg3N7dIfTk7O6t79+7q3r27XnjhBbVt21bnz5/Pt35WYGCgYmNjlZOTYxpllpCQoBIlSqhq1aqmdgcPHtTly5dlb28vSdq5c6ccHR3l4+MjNzc32draKi0trcDpl3diY2MjSbe9xoEDB2rmzJn69ddfFRISkm+aYlpamv73v//J29vbVNet2suWLStvb2+dOnVKvXv3LnJdhZGQkKDGjRvrlVdeMW1LSUmxaHMvnx8AAAAAAI8qnpKJh2bXrl2aPHmy9uzZo7S0NK1YsUK///67AgMD5efnp0OHDik5OVnnzp3T9evXC+xrxowZ+vzzz3Xs2DEdP35cX375pTw9PS3WB7uld+/esrOzU79+/fTjjz/qu+++02uvvaY+ffqYpmNKN6dXhoeH6+jRo1q7dq3Gjx+viIgIlShRQk5OToqMjNQbb7yhRYsWKSUlRfv27dOcOXO0aNGiu167r6+vDAaDvvnmG/3+++8WT+js1auXfvnlF82fP18DBgzId+yt2g8ePKht27Zp6NCh6tatm2m9sOjoaE2ZMkWzZ8/W8ePHdfjwYS1cuFAzZsy4a12FERAQoD179mjDhg06fvy4xo4dq8TERIs2Rf38AAAAAAB4lBGY4aFxdnbW1q1b1b59e1WpUkVjxoxRTEyM2rVrp0GDBqlq1aqqX7++3N3dlZCQUGBfTk5OmjZtmurXr68GDRooNTVVa9euVYkS+X+lHRwctGHDBp0/f14NGjTQCy+8oFatWmnu3LkW7Vq1aqWAgAA1a9ZM3bt317/+9S9FRUWZ9k+cOFFjx47VlClTFBgYqLZt22rNmjXy9/e/67WXK1dO0dHRGjVqlMqWLauIiAjTPhcXF3Xp0kWOjo7q1KlTvmMrV66szp07q3379mrTpo1q1qypDz/80LR/4MCBWrBggRYuXKigoCA1b95csbGxhaqrMF566SV17txZ3bt3V6NGjfTHH39YjDaTVOTPDwAAAACAR5nBaDQai7sIoLiFhYUpIyNDq1atKpbzt2rVSjVq1NDs2bMttkdFRWnVqlU6cOBAsdT1IGVlZcnFxUWZmZlydnYu7nIAAAAAAE+4ovwdyhpmQDG6cOGC4uPjFR8fbzFqDAAAAAAAFB+mZOKRNHnyZDk6Ot721a5du+IuL58hQ4bcsd4hQ4bc8bg6deooLCxM7777rsUDCO6Xx+0+AgAAAADwKGBKJh5J58+f1/nz52+7z97eXuXKlXvIFRXs7NmzysrKuu0+Z2dneXh4POSKbnqU7yNTMgEAAAAADxNTMvHYc3Nzk5ubW3GXUWgeHh7FFooV5HG7jwAAAAAAPAqYkgkAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzAAAAAAAAAAzBGYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGCGwAwAAAAAAAAwQ2AGAAAAAAAAmCEwAwAAAAAAAMwQmAEAAAAAAABmCMwAAAAAAAAAMwRmAAAAAAAAgBkCMwAAAAAAAMAMgRkAAAAAAABghsAMAAAAAAAAMENgBgAAAAAAAJghMAMAAAAAAADMEJgBAAAAAAAAZgjMAAAAAAAAADMEZgAAAAAAAIAZAjMAAAAAAADADIEZHkupqakyGAw6cOBAcZfyl4SFhalTp07FXQYAAAAAADBjXdwF4O8nLCxMGRkZWrVqVXGXUuxmzZolo9FY3GX8ZS1atFDt2rU1c+bM4i4FAAAAAIC/jMAMKMC1a9dkY2PzwPp3cXF5YH0/DA/6/gAAAAAAUByYkokHZtmyZQoKCpK9vb1Kly6tkJAQjRgxQosWLdJXX30lg8Egg8Gg+Pj4u/a1e/du1alTR3Z2dqpfv77279+fr82PP/6odu3aydHRUWXLllWfPn107tw50/4WLVooIiJCERERcnFxUZkyZTR27FiLEV5+fn6aOHGi+vbtK2dnZw0ePFiS9MMPP6hp06ayt7eXj4+Phg4dqpycHNNxH374oQICAmRnZ6eyZcvqhRdeKPA+3Dr2z1Myr169qqFDh8rDw0N2dnZ65plnlJiYaNofHx8vg8GgLVu2qH79+nJwcFDjxo2VnJx89w9E0sGDB9WyZUs5OTnJ2dlZ9erV0549e0z7Y2NjVaFCBTk4OOj5559XTEyMXF1dTfujoqJUu3ZtLViwQP7+/rKzs1NYWJi+//57zZo1y/SZpqamFqoeAAAAAAAeRQRmeCDS09PVs2dPDRgwQElJSYqPj1fnzp01fvx4devWTW3btlV6errS09PVuHHjAvvKzs7Wc889p+rVq2vv3r2KiopSZGSkRZuMjAw9++yzqlOnjvbs2aP169frt99+U7du3SzaLVq0SNbW1tq9e7dmzZqlGTNmaMGCBRZtpk+frlq1amn//v0aO3asUlJS1LZtW3Xp0kWHDh3S0qVL9cMPPygiIkKStGfPHg0dOlQTJkxQcnKy1q9fr2bNmhV4H+40DfOtt97S8uXLtWjRIu3bt0+VK1dWaGiozp8/b9Fu9OjRiomJ0Z49e2Rtba0BAwbc/UOR1Lt3b5UvX16JiYnau3evRo0apZIlS0qSdu3apfDwcEVEROjAgQNq2bKl3nnnnXx9nDx5UsuXL9eKFSt04MABzZo1S8HBwRo0aJDpM/Xx8cl33NWrV5WVlWXxAgAAAADgkWQEHoC9e/caJRlTU1Pz7evXr5+xY8eOhe5r3rx5xtKlSxsvX75s2vbRRx8ZJRn3799vNBqNxokTJxrbtGljcdzp06eNkozJyclGo9FobN68uTEwMNCYl5dnajNy5EhjYGCg6b2vr6+xU6dOFv2Eh4cbBw8ebLFt27ZtxhIlShgvX75sXL58udHZ2dmYlZWVr/aC7oPRaHkvsrOzjSVLljTGxcWZ9l+7ds3o7e1tnDZtmtFoNBq/++47oyTj5s2bTW3WrFljlGRxf+7EycnJGBsbe9t9PXv2NLZv395iW/fu3Y0uLi6m9+PHjzeWLFnSePbsWYt2zZs3N77++usFnnv8+PFGSflemZmZd60bAAAAAIC/KjMzs9B/hzLCDA9ErVq11KpVKwUFBalr166aP3++Lly4cE99JSUlqWbNmrKzszNtCw4Otmhz8OBBfffdd3J0dDS9qlWrJklKSUkxtXv66adlMBgs+jlx4oRyc3NN2+rXr5+v79jYWIu+Q0NDlZeXp59++kmtW7eWr6+vKlasqD59+iguLk6XLl0q8n1ISUnR9evX1aRJE9O2kiVLqmHDhkpKSrJoW7NmTdPPXl5ekqSzZ88WcBdvGj58uAYOHKiQkBBNnTrV4t4kJSWpUaNGFu3/fJ8lydfXV+7u7nc915+9/fbbyszMNL1Onz5d5D4AAAAAAHgYCMzwQFhZWWnTpk1at26dqlevrjlz5qhq1ar66aefHsj5srOz1aFDBx04cMDideLECdP0yMIqVapUvr5feukli34PHjyoEydOqFKlSnJyctK+ffv0+eefy8vLS+PGjVOtWrWUkZHxwO7DrWmUkkwBYF5e3l2Pi4qK0pEjR/TPf/5T3377rapXr66VK1cW6dx/vj+FZWtrK2dnZ4sXAAAAAACPIgIzPDAGg0FNmjRRdHS09u/fLxsbG61cuVI2NjYWI7ruJjAwUIcOHdKVK1dM23bu3GnRpm7dujpy5Ij8/PxUuXJli5d5wLNr1y6L43bu3KmAgABZWVnd8fx169bV0aNH8/VbuXJl0xMira2tFRISomnTpunQoUNKTU3Vt99+W+B9+LNKlSrJxsZGCQkJpm3Xr19XYmKiqlevXuj7dTdVqlTRG2+8oY0bN6pz585auHChpJv3+Xb3pzCK+pkCAAAAAPAoIzDDA7Fr1y5NnjxZe/bsUVpamlasWKHff/9dgYGB8vPz06FDh5ScnKxz587p+vXrBfbVq1cvGQwGDRo0SEePHtXatWs1ffp0izavvvqqzp8/r549eyoxMVEpKSnasGGD+vfvbxHkpKWlafjw4UpOTtbnn3+uOXPm6PXXXy/w/CNHjtT27dtNi+GfOHFCX331lWnR/2+++UazZ8/WgQMH9PPPP2vx4sXKy8tT1apVC7wPf1aqVCm9/PLLGjFihNavX6+jR49q0KBBunTpksLDwwt76+/o8uXLioiIUHx8vH7++WclJCQoMTHRVMvQoUO1fv16TZ8+XSdOnNDcuXO1fv36QvXt5+enXbt2KTU1VefOnSvUaDcAAAAAAB5VBGZ4IJydnbV161a1b99eVapU0ZgxYxQTE6N27dpp0KBBqlq1qurXry93d3eLEVW34+joqK+//lqHDx9WnTp1NHr0aL377rsWbby9vZWQkKDc3Fy1adNGQUFBGjZsmFxdXVWixP/7Ne/bt68uX76shg0b6tVXX9Xrr7+uwYMHF3j+mjVr6vvvv9fx48fVtGlT1alTR+PGjZO3t7ckydXVVStWrNCzzz6rwMBAffzxx/r8889Vo0aNAu/D7UydOlVdunRRnz59VLduXZ08eVIbNmzQU089VZjbXiArKyv98ccf6tu3r6pUqaJu3bqpXbt2io6OlnRzfbf58+dr1qxZqlWrljZu3KgxY8YUqu/IyEhZWVmpevXqcnd3V1pa2l+uFwAAAACA4mIwGo3G4i4CeBhatGih2rVra+bMmcVdymMjNjZWw4YNU0ZGxn3vOysrSy4uLsrMzGQ9MwAAAADAA1eUv0MZYQYAAAAAAACYITBDsZs8ebIcHR1v+7rT1EXcXo0aNe54L+Pi4oq7PAAAAAAAHgtMyUSxO3/+vM6fP3/bffb29ipXrtxDrujx9fPPP9/xIQply5aVk5PTQ67ozpiSCQAAAAB4mIryd6j1Q6oJuCM3Nze5ubkVdxlPBF9f3+IuAQAAAACAxx5TMgEAAAAAAAAzBGYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGCGwAwAAAAAAAAwQ2AGAAAAAAAAmCEwAwAAAAAAAMwQmAEAAAAAAABmCMwAAAAAAAAAMwRmAAAAAAAAgBkCMwAAAAAAAMAMgRkAAAAAAABgxrq4CwAAAAAAPFneXZmeb9vI572KoRIAuDeMMAMAAAAAAADMEJgBAAAAAAAAZgjMAAAAAAAAADMEZgAAAAAAAIAZAjMAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzFCg2NhYubq6FncZf1thYWHq1KlTgW38/Pw0c+bMh1JPQVq0aKFhw4YVdxkAAAAAAPxlBGZ4pD3MEOZRCZ6KKjExUYMHDy7uMgAAAAAAeGJYF3cBwO1cu3ZNNjY2f7kfo9Go3NxcWVs/ub/q7u7uxV0CAAAAAABPFEaYPWJatGih1157TcOGDdNTTz2lsmXLav78+crJyVH//v3l5OSkypUra926dZKk3NxchYeHy9/fX/b29qpatapmzZpl6u/KlSuqUaOGxQiklJQUOTk56ZNPPil0XRs2bFBgYKAcHR3Vtm1bpaenW+xfsGCBAgMDZWdnp2rVqunDDz+02D9y5EhVqVJFDg4OqlixosaOHavr16+b9kdFRal27dpasGCB/P39ZWdnp7CwMH3//feaNWuWDAaDDAaDUlNTC6wzPj5eBoNB69atU7169WRra6sffvhBKSkp6tixo8qWLStHR0c1aNBAmzdvtrjvP//8s9544w3TuW754Ycf1LRpU9nb28vHx0dDhw5VTk5Ooe7bp59+qvr168vJyUmenp7q1auXzp49a9HmyJEjeu655+Ts7CwnJyc1bdpUKSkpFm2mT58uLy8vlS5dWq+++qrFvfvzyLiMjAwNHDhQ7u7ucnZ21rPPPquDBw9Kko4fPy6DwaBjx45Z9P/++++rUqVKpvc//vij2rVrJ0dHR5UtW1Z9+vTRuXPnTPtzcnLUt29fOTo6ysvLSzExMXe9F1evXlVWVpbFCwAAAACARxGB2SNo0aJFKlOmjHbv3q3XXntNL7/8srp27arGjRtr3759atOmjfr06aNLly4pLy9P5cuX15dffqmjR49q3Lhx+ve//60vvvhCkmRnZ6e4uDgtWrRIX331lXJzc/Xiiy+qdevWGjBgQKHquXTpkqZPn65PP/1UW7duVVpamiIjI0374+LiNG7cOE2aNElJSUmaPHmyxo4dq0WLFpnaODk5KTY2VkePHtWsWbM0f/58vf/++xbnOXnypJYvX64VK1bowIEDmjVrloKDgzVo0CClp6crPT1dPj4+hap51KhRmjp1qpKSklSzZk1lZ2erffv22rJli/bv36+2bduqQ4cOSktLkyStWLFC5cuX14QJE0znkm6Gi23btlWXLl106NAhLV26VD/88IMiIiIKVcf169c1ceJEHTx4UKtWrVJqaqrCwsJM+3/99Vc1a9ZMtra2+vbbb7V3714NGDBAN27cMLX57rvvlJKSou+++06LFi1SbGysYmNj73jOrl276uzZs1q3bp327t2runXrqlWrVjp//ryqVKmi+vXrKy4uzuKYuLg49erVS9LNwO3ZZ59VnTp1tGfPHq1fv16//fabunXrZmo/YsQIff/99/rqq6+0ceNGxcfHa9++fQXeiylTpsjFxcX0KuxnCQAAAADAQ2fEI6V58+bGZ555xvT+xo0bxlKlShn79Olj2paenm6UZNyxY8dt+3j11VeNXbp0sdg2bdo0Y5kyZYwRERFGLy8v47lz5wpVz8KFC42SjCdPnjRt++CDD4xly5Y1va9UqZLxs88+szhu4sSJxuDg4Dv2+9577xnr1atnej9+/HhjyZIljWfPnrVo17x5c+Prr79eqFqNRqPxu+++M0oyrlq16q5ta9SoYZwzZ47pva+vr/H999+3aBMeHm4cPHiwxbZt27YZS5QoYbx8+XKh67olMTHRKMl48eJFo9FoNL799ttGf39/47Vr127bvl+/fkZfX1/jjRs3TNu6du1q7N69+23r3rZtm9HZ2dl45coVi34qVapknDdvntFoNBrff/99Y6VKlUz7kpOTjZKMSUlJRqPx5mfXpk0bi+NPnz5tlGRMTk42Xrx40WhjY2P84osvTPv/+OMPo729fYGf1ZUrV4yZmZmm160+MzMz73gMAAAAHk9TV/wv3wsAiltmZmah/w59chd2eozVrFnT9LOVlZVKly6toKAg07ayZctKkmlq3wcffKBPPvlEaWlpunz5sq5du6batWtb9Pnmm29q1apVmjt3rtatW6fSpUsXuh4HBweL6XpeXl6mc+fk5CglJUXh4eEaNGiQqc2NGzfk4uJier906VLNnj1bKSkpys7O1o0bN+Ts7GxxHl9f3/u2Hlf9+vUt3mdnZysqKkpr1qxRenq6bty4ocuXL5tGmN3JwYMHdejQIYsRWUajUXl5efrpp58UGBhY4PF79+5VVFSUDh48qAsXLigvL0+SlJaWpurVq+vAgQNq2rSpSpYsecc+atSoISsrK9N7Ly8vHT58+I71Zmdn5/t8L1++bJrm2aNHD0VGRmrnzp16+umnFRcXp7p166patWqmPr777js5Ojrm6z8lJcX0O9aoUSPTdjc3N1WtWrXAe2FraytbW9sC2wAAAAAA8CggMHsE/Tk8MRgMFttura+Vl5enJUuWKDIyUjExMQoODpaTk5Pee+897dq1y6KPs2fP6vjx47KystKJEyfUtm3bv1SP0WiUdDOIkqT58+dbBCiSTCHPjh071Lt3b0VHRys0NFQuLi5asmRJvnWvSpUqVeia7ubPfUVGRmrTpk2aPn26KleuLHt7e73wwgu6du1agf1kZ2frpZde0tChQ/Ptq1ChQoHH5uTkKDQ0VKGhoYqLi5O7u7vS0tIUGhpqOq+9vf1dr+V29/9W8Ha7er28vBQfH59vn6urqyTJ09NTzz77rD777DM9/fTT+uyzz/Tyyy9b9NGhQwe9++67+frw8vLSyZMn71ozAAAAAACPMwKzx1xCQoIaN26sV155xbTtzwvGS9KAAQMUFBRkGgkWEhJy19FRhVG2bFl5e3vr1KlT6t27923bbN++Xb6+vho9erRp288//1yo/m1sbJSbm/uX60xISFBYWJief/55STdDoT8/QOB256pbt66OHj2qypUrF/mcx44d0x9//KGpU6ea1uvas2ePRZuaNWtq0aJFun79eoGjzAqrbt26OnPmjKytreXn53fHdr1799Zbb72lnj176tSpU+rRo4dFH8uXL5efn99tny5aqVIllSxZUrt27TKFhhcuXNDx48fVvHnzv3wNAAAAAAAUNxb9f8wFBARoz5492rBhg44fP66xY8cqMTHRos0HH3ygHTt2aNGiRerdu7c6deqk3r1733V0VWFFR0drypQpmj17to4fP67Dhw9r4cKFmjFjhqnGtLQ0LVmyRCkpKZo9e7ZWrlxZqL79/Py0a9cupaam6ty5c3ccWXU3AQEBpocJHDx4UL169crXl5+fn7Zu3apff/3V9ETIkSNHavv27YqIiNCBAwd04sQJffXVV4Va9L9ChQqysbHRnDlzdOrUKa1evVoTJ060aBMREaGsrCz16NFDe/bs0YkTJ/Tpp58qOTn5nq4zJCREwcHB6tSpkzZu3KjU1FRt375do0ePtgjrOnfurIsXL+rll19Wy5Yt5e3tbdr36quv6vz58+rZs6cSExOVkpKiDRs2qH///srNzZWjo6PCw8M1YsQIffvtt/rxxx8VFhamEiX4zwkAAAAA4MnAX7iPuZdeekmdO3dW9+7d1ahRI/3xxx8Wo82OHTumESNG6MMPPzSNcvrwww917tw5jR079r7UMHDgQC1YsEALFy5UUFCQmjdvrtjYWPn7+0uS/vWvf+mNN95QRESEateure3btxf63JGRkbKyslL16tVNUxrvxYwZM/TUU0+pcePG6tChg0JDQ1W3bl2LNhMmTFBqaqoqVapkWkutZs2a+v7773X8+HE1bdpUderU0bhx4ywCpjtxd3dXbGysvvzyS1WvXl1Tp07V9OnTLdqULl1a3377rbKzs9W8eXPVq1dP8+fPv+fRZgaDQWvXrlWzZs3Uv39/ValSRT169NDPP/9sWvtOuvnU0g4dOujgwYP5RgZ6e3srISFBubm5atOmjYKCgjRs2DC5urqaQrH33ntPTZs2VYcOHRQSEqJnnnlG9erVu6eaAQAAAAB41BiMtxajAoCHKCsrSy4uLsrMzMz3AAgAAAA83t5dmZ5v28jnvYqhEgD4f4rydygjzAAAAAAAAAAzBGZ/c+3atZOjo+NtX5MnTy7u8vIZMmTIHesdMmTIQ61l27Ztd6zF0dHxodYCAAAAAADuH56S+Te3YMECXb58+bb73NzcHnI1dzdhwgRFRkbedt/DntZXv359HThw4KGeEwAAAAAAPHgEZn9z5cqVK+4SisTDw0MeHh7FXYYkyd7eXpUrVy7uMgAAAAAAwH3GlEwAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYYdF/AAAAAMB9NfJ5r+IuAQD+EkaYAQAAAAAAAGYIzAAAAAAAAAAzBGYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGCGwAwAAAAAAAAwQ2AGAAAAAAAAmLEu7gIAAAAAAE+WdUvPFXcJ90277mWKuwQAxYARZgAAAAAAAIAZAjMAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzAAAAAAAAAAzBGYAAAAAAACAGQKzJ0xqaqoMBoMOHDjw0M4ZFhamTp06FdimRYsWGjZs2AOvxc/PTzNnznzg53mSFMfvDAAAAAAAjzLr4i4A9y4sLEwZGRlatWqVaZuPj4/S09NVpkyZ4isMAAAAAADgMcYIs2J07dq1+96nlZWVPD09ZW1NFvogXL9+vbhLyOdRrAkAAAAAgMcZgdlD1KJFC0VERGjYsGEqU6aMQkND9eOPP6pdu3ZydHRU2bJl1adPH507d850zLJlyxQUFCR7e3uVLl1aISEhysnJUVRUlBYtWqSvvvpKBoNBBoNB8fHx+abXxcfHy2AwaMuWLapfv74cHBzUuHFjJScnW9T2zjvvyMPDQ05OTho4cKBGjRql2rVrF+n6oqOj5e7uLmdnZw0ZMqTAQPDChQvq27evnnrqKTk4OKhdu3Y6ceKERZvly5erRo0asrW1lZ+fn2JiYiz2nz17Vh06dJC9vb38/f0VFxdXpHoNBoM++ugjtWvXTvb29qpYsaKWLVtm2n/rXi5dulTNmzeXnZ2d6RwLFixQYGCg7OzsVK1aNX344Yem465du6aIiAh5eXnJzs5Ovr6+mjJliiTJaDQqKipKFSpUkK2trby9vTV06FCLmsxHDEqSq6urYmNj/1JNRfX999+rYcOGsrW1lZeXl0aNGqUbN26Y9l+8eFG9e/dWqVKl5OXlpffff/+hTbsFAAAAAOBBIzB7yBYtWiQbGxslJCRo6tSpevbZZ1WnTh3t2bNH69ev12+//aZu3bpJktLT09WzZ08NGDBASUlJio+PV+fOnWU0GhUZGalu3bqpbdu2Sk9PV3p6uho3bnzH844ePVoxMTHas2ePrK2tNWDAANO+uLg4TZo0Se+++6727t2rChUq6KOPPirSdW3ZssVU4+eff64VK1YoOjr6ju3DwsK0Z88erV69Wjt27JDRaFT79u1No6X27t2rbt26qUePHjp8+LCioqI0duxYU3B0q4/Tp0/ru+++07Jly/Thhx/q7NmzRap77Nix6tKliw4ePKjevXurR48eSkpKsmgzatQovf7660pKSlJoaKji4uI0btw4TZo0SUlJSZo8ebLGjh2rRYsWSZJmz56t1atX64svvlBycrLi4uLk5+cn6WYI+P7772vevHk6ceKEVq1apaCgoCLVfC81FcWvv/6q9u3bq0GDBjp48KA++ugj/ec//9E777xjajN8+HAlJCRo9erV2rRpk7Zt26Z9+/YV2O/Vq1eVlZVl8QIAAAAA4FHEvL2HLCAgQNOmTZN0c1RXnTp1NHnyZNP+Tz75RD4+Pjp+/Liys7N148YNde7cWb6+vpJkEa7Y29vr6tWr8vT0vOt5J02apObNm0u6Gbb885//1JUrV2RnZ6c5c+YoPDxc/fv3lySNGzdOGzduVHZ2dqGvy8bGRp988okcHBxUo0YNTZgwQSNGjNDEiRNVooRlLnvixAmtXr1aCQkJppAvLi5OPj4+WrVqlbp27aoZM2aoVatWGjt2rCSpSpUqOnr0qN577z2FhYXp+PHjWrdunXbv3q0GDRpIkv7zn/8oMDCw0DVLUteuXTVw4EBJ0sSJE7Vp0ybNmTPHYnTWsGHD1LlzZ9P78ePHKyYmxrTN399fR48e1bx589SvXz+lpaUpICBAzzzzjAwGg+mzk6S0tDR5enoqJCREJUuWVIUKFdSwYcMi1XwvNRXFhx9+KB8fH82dO1cGg0HVqlXT//73P40cOVLjxo1TTk6OFi1apM8++0ytWrWSJC1cuFDe3t4F9jtlypQCQ1QAAAAAAB4VjDB7yOrVq2f6+eDBg/ruu+/k6OhoelWrVk2SlJKSolq1aqlVq1YKCgpS165dNX/+fF24cOGezluzZk3Tz15eXpJkGo2VnJycL7QpaohTq1YtOTg4mN4HBwcrOztbp0+fztc2KSlJ1tbWatSokWlb6dKlVbVqVdPorqSkJDVp0sTiuCZNmujEiRPKzc019WF+P6tVqyZXV9ci1R0cHJzv/Z9HmNWvX9/0c05OjlJSUhQeHm7xub3zzjtKSUmRdHPk24EDB1S1alUNHTpUGzduNB3ftWtXXb58WRUrVtSgQYO0cuVKi6mOhVXUmooiKSlJwcHBMhgMpm1NmjRRdna2fvnlF506dUrXr1+3+B1xcXFR1apVC+z37bffVmZmpul1u98NAAAAAAAeBYwwe8hKlSpl+jk7O1sdOnTQu+++m6+dl5eXrKystGnTJm3fvl0bN27UnDlzNHr0aO3atUv+/v5FOm/JkiVNP98KQvLy8u7xKv5e/vyZSdL8+fMtAj/p5gMXJKlu3br66aeftG7dOm3evFndunVTSEiIli1bJh8fHyUnJ2vz5s3atGmTXnnlFb333nv6/vvvVbJkSRkMBhmNRot+b7eof1FrehTY2trK1ta2uMsAAAAAAOCuGGFWjOrWrasjR47Iz89PlStXtnjdCkQMBoOaNGmi6Oho7d+/XzY2Nlq5cqWkm9Mgc3Nz/3IdVatWVWJiosW2P7+/m4MHD+ry5cum9zt37pSjo6N8fHzytQ0MDNSNGze0a9cu07Y//vhDycnJql69uqlNQkKCxXEJCQmqUqWKrKysVK1aNd24cUN79+417U9OTlZGRkaR6t65c2e+9wVN6yxbtqy8vb116tSpfJ+ZeYjp7Oys7t27a/78+Vq6dKmWL1+u8+fPS7o5lbZDhw6aPXu24uPjtWPHDh0+fFiS5O7urvT0dFM/J06c0KVLlwq8hsLWVFiBgYGmdeVuSUhIkJOTk8qXL6+KFSuqZMmSFr8jmZmZOn78eJHPBQAAAADAo4gRZsXo1Vdf1fz589WzZ0+99dZbcnNz08mTJ7VkyRItWLBAe/bs0ZYtW9SmTRt5eHho165d+v33302Bjp+fnzZs2KDk5GSVLl1aLi4u91THa6+9pkGDBql+/fpq3Lixli5dqkOHDqlixYqF7uPatWsKDw/XmDFjlJqaqvHjxysiIiLf+mXSzXXcOnbsqEGDBmnevHlycnLSqFGjVK5cOXXs2FGS9Oabb6pBgwaaOHGiunfvrh07dmju3LmmtcWqVq2qtm3b6qWXXtJHH30ka2trDRs2TPb29kW69i+//FL169fXM888o7i4OO3evVv/+c9/CjwmOjpaQ4cOlYuLi9q2baurV69qz549unDhgoYPH64ZM2bIy8tLderUUYkSJfTll1/K09PT9LTL3NxcNWrUSA4ODvrvf/8re3t70zpnzz77rObOnavg4GDl5uZq5MiRFqMD77WmonjllVc0c+ZMvfbaa4qIiFBycrLGjx+v4cOHq0SJEnJyclK/fv00YsQIubm5ycPDQ+PHj1eJEiUspnECAAAAAPC4YoRZMfL29lZCQoJyc3PVpk0bBQUFadiwYXJ1dVWJEiXk7OysrVu3qn379qpSpYrGjBmjmJgYtWvXTpI0aNAgVa1aVfXr15e7u3u+EVmF1bt3b7399tuKjIw0TScMCwuTnZ1dofto1aqVAgIC1KxZM3Xv3l3/+te/FBUVdcf2CxcuVL169fTcc88pODhYRqNRa9euNYVDdevW1RdffKElS5boH//4h8aNG6cJEyYoLCzMog9vb281b95cnTt31uDBg+Xh4VGka4+OjtaSJUtUs2ZNLV68WJ9//rlplNudDBw4UAsWLNDChQsVFBSk5s2bKzY21jSay8nJSdOmTVP9+vXVoEEDpaamau3atSpRooRcXV01f/58NWnSRDVr1tTmzZv19ddfq3Tp0pKkmJgY+fj4qGnTpurVq5ciIyMt1oa715qKoly5clq7dq12796tWrVqaciQIaYw9JYZM2YoODhYzz33nEJCQtSkSRMFBgYW6XcGAAAAAIBHlcH45wWTAEmtW7eWp6enPv300+Iu5YExGAxauXKlOnXqVNylPPZycnJUrlw5xcTEKDw8vFDHZGVlycXFRZmZmXJ2dn7AFQIAAOBhWrf0XHGXcN+0616muEsAcJ8U5e9QpmRCly5d0scff6zQ0FBZWVnp888/Ny1KD9zO/v37dezYMTVs2FCZmZmaMGGCJJmm1AIAAAAA8DhjSiZkMBi0du1aNWvWTPXq1dPXX3+t5cuXKyQkRJLk6Oh4x9e2bduKufrbi4uLu2PNNWrUKO7yHqrJkyff8V7cmt57L6ZPn65atWopJCREOTk52rZtm8qU4f99AwAAAAA8/piSibs6efLkHfeVK1euyAvtPwwXL17Ub7/9dtt9JUuWNC2y/3dw/vx50xM6/8ze3l7lypV7yBXdxJRMAACAJxdTMgE8ipiSifuqcuXKxV1CkTk5OcnJyam4y3gkuLm5yc3NrbjLAAAAAADgscGUTAAAAAAAAMAMgRkAAAAAAABghsAMAAAAAAAAMENgBgAAAAAAAJhh0X8AAAAAwH3FkyUBPO4YYQYAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzAAAAAAAAAAzBGYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGDGurgLAAAAAAA8WY58/Ftxl/DYqjGkbHGXAECMMAMAAAAAAAAsEJgBAAAAAAAAZgjMAAAAAAAAADMEZgAAAAAAAIAZAjMAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzAAAAAAAAAAzBGZAIYWFhalTp07FXUahpaamymAw6MCBA8VdCgAAAAAAjxUCM/xtXLt2rbhLAAAAAAAAjwECMzyxWrRooYiICA0bNkxlypRRaGiofvzxR7Vr106Ojo4qW7as+vTpo3PnzpmOWbZsmYKCgmRvb6/SpUsrJCREOTk5ioqK0qJFi/TVV1/JYDDIYDAoPj7+rjWcPn1a3bp1k6urq9zc3NSxY0elpqZatPnkk09Uo0YN2draysvLSxEREaZ9x44d0zPPPCM7OztVr15dmzdvlsFg0KpVq+56bn9/f0lSnTp1ZDAY1KJFC23dulUlS5bUmTNnLNoOGzZMTZs2lSTFxsbK1dVVq1atUkBAgOzs7BQaGqrTp09bHPPVV1+pbt26srOzU8WKFRUdHa0bN27csZ6rV68qKyvL4gUAAAAAwKOIwAxPtEWLFsnGxkYJCQmaOnWqnn32WdWpU0d79uzR+vXr9dtvv6lbt26SpPT0dPXs2VMDBgxQUlKS4uPj1blzZxmNRkVGRqpbt25q27at0tPTlZ6ersaNGxd47uvXrys0NFROTk7atm2bEhIS5OjoqLZt25pGu3300Ud69dVXNXjwYB0+fFirV69W5cqVJUm5ubnq1KmTHBwctGvXLv3f//2fRo8eXehr3717tyRp8+bNSk9P14oVK9SsWTNVrFhRn376qUWdcXFxGjBggGnbpUuXNGnSJC1evFgJCQnKyMhQjx49TPu3bdumvn376vXXX9fRo0c1b948xcbGatKkSXesZ8qUKXJxcTG9fHx8Cn0tAAAAAAA8TAaj0Wgs7iKAB6FFixbKysrSvn37JEnvvPOOtm3bpg0bNpja/PLLL/Lx8VFycrKys7NVr149paamytfXN19/YWFhysjIKNToLkn673//q3feeUdJSUkyGAySbk4LvTV6q02bNipXrpz69++vd955J9/x69evV4cOHXT69Gl5enpKuhl+tW7dWitXrrzremqpqany9/fX/v37Vbt2bdP2adOmKTY2VkePHpUkrVixQv369dOZM2dUqlQpxcbGqn///tq5c6caNWok6eZIt8DAQO3atUsNGzZUSEiIWrVqpbffftviet966y3973//u209V69e1dWrV03vs7Ky5OPjo8zMTDk7O9/9hgIAAOCxceTj34q7hMdWjSFli7sE4ImVlZUlFxeXQv0dyggzPNHq1atn+vngwYP67rvv5OjoaHpVq1ZNkpSSkqJatWqpVatWCgoKUteuXTV//nxduHDhns998OBBnTx5Uk5OTqbzubm56cqVK0pJSdHZs2f1v//9T61atbrt8cnJyfLx8TGFZZLUsGHDe67nlrCwMJ08eVI7d+6UdHMKZrdu3VSqVClTG2trazVo0MD0vlq1anJ1dVVSUpLp2iZMmGBxLwcNGqT09HRdunTptue1tbWVs7OzxQsAAAAAgEeRdXEXADxI5iFQdna2OnTooHfffTdfOy8vL1lZWWnTpk3avn27Nm7cqDlz5mj06NHatWuXaT2worg1Yi0uLi7fPnd3d5UoUTx5tYeHhzp06KCFCxfK399f69atK9R6bOays7MVHR2tzp0759tnZ2d3nyoFAAAAAKB4EJjhb6Nu3bpavny5/Pz8ZG19+199g8GgJk2aqEmTJho3bpx8fX21cuVKDR8+XDY2NsrNzS3S+ZYuXSoPD487jqby8/PTli1b1LJly3z7qlatqtOnT+u3335T2bI3h2UnJiYW+vw2NjaSdNuaBw4cqJ49e6p8+fKqVKmSmjRpYrH/xo0b2rNnj2lEW3JysjIyMhQYGGi6tuTkZNN6awAAAAAAPEmYkom/jVdffVXnz59Xz549lZiYqJSUFG3YsEH9+/dXbm6udu3apcmTJ2vPnj1KS0vTihUr9Pvvv5tCIj8/Px06dEjJyck6d+6crl+/XuD5evfurTJlyqhjx47atm2bfvrpJ8XHx2vo0KH65ZdfJElRUVGKiYnR7NmzdeLECe3bt09z5syRJLVu3VqVKlVSv379dOjQISUkJGjMmDGSZFoTrSAeHh6yt7c3PdwgMzPTtC80NFTOzs5655131L9//3zHlixZUq+99pp27dqlvXv3KiwsTE8//bQpQBs3bpwWL16s6OhoHTlyRElJSVqyZImpPgAAAAAAHmcEZvjb8Pb2VkJCgnJzc9WmTRsFBQVp2LBhcnV1VYkSJeTs7KytW7eqffv2qlKlisaMGaOYmBi1a9dOkjRo0CBVrVpV9evXl7u7uxISEgo8n4ODg7Zu3aoKFSqoc+fOCgwMVHh4uK5cuWIacdavXz/NnDlTH374oWrUqKHnnntOJ06ckCRZWVlp1apVys7OVoMGDTRw4EDTUzILM+3R2tpas2fP1rx58+Tt7a2OHTua9pUoUUJhYWHKzc1V3759b1v7yJEj1atXLzVp0kSOjo5aunSpaX9oaKi++eYbbdy4UQ0aNNDTTz+t999//7YPSwAAAAAA4HHDUzKBx0hCQoKeeeYZnTx5UpUqVfpLfYWHh+v333/X6tWrLbbHxsZq2LBhysjI+Ev9301Rnk4CAACAxwtPybx3PCUTeHCK8ncoa5gBj7CVK1fK0dFRAQEBOnnypF5//XU1adLkL4VlmZmZOnz4sD777LN8YRkAAAAAAGBKJnDPJk+eLEdHx9u+bk3j/KsuXryoV199VdWqVVNYWJgaNGigr7766i+dv2PHjmrTpo2GDBmi1q1b35c6AQAAAAB4kjAlE7hH58+f1/nz52+7z97eXuXKlXuiz/9XMSUTAADgycWUzHvHlEzgwWFKJvAQuLm5yc3N7W97fgAAAAAAnlRMyQQAAAAAAADMEJgBAAAAAAAAZgjMAAAAAAAAADMEZgAAAAAAAIAZFv0HAAAAANxXPOkRwOOOEWYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGCGwAwAAAAAAAAwQ2AGAAAAAAAAmCEwAwAAAAAAAMwQmAEAAAAAAABmrIu7AAAAAADAk+VMzLHiLgEw8XyzWnGXgMcQI8wAAAAAAAAAMwRmAAAAAAAAgBkCMwAAAAAAAMAMgRkAAAAAAABghsAMAAAAAAAAMENgBgAAAAAAAJghMAMAAAAAAADMEJgBAAAAAAAAZgjMAAAAAAAAADOPdWCWmpoqg8GgAwcOFHcp912LFi00bNiw4i4D94Gfn59mzpx5X/sMCwtTp06d7mufBYmPj5fBYFBGRsZDOycAAAAAAMXFurgLeNS1aNFCtWvXvu+Bx92sWLFCJUuWvC99paamyt/fX/v371ft2rXvS58ovMTERJUqVaq4y/hLGjdurPT0dLm4uBR3KQAAAAAAPHAEZo8oNze34i4B94m7u3txl/CX2djYyNPTs7jLAAAAAADgoXgspmTm5eVp2rRpqly5smxtbVWhQgVNmjTJtP/UqVNq2bKlHBwcVKtWLe3YscPi+B9++EFNmzaVvb29fHx8NHToUOXk5Jj2f/jhhwoICJCdnZ3Kli2rF154QdLNaW/ff/+9Zs2aJYPBIIPBoNTU1AJrvTV1bc2aNapZs6bs7Oz09NNP68cffzS1+eOPP9SzZ0+VK1dODg4OCgoK0ueff27Rz5+nZPr5+Wny5MkaMGCAnJycVKFCBf3f//1foe6fv7+/JKlOnToyGAxq0aKFtm7dqpIlS+rMmTMWbYcNG6amTZtKkmJjY+Xq6qpVq1aZ7k9oaKhOnz5tccxXX32lunXrys7OThUrVlR0dLRu3LhRqNoMBoMWLFig559/Xg4ODgoICNDq1ast2nz//fdq2LChbG1t5eXlpVGjRln036JFCw0dOlRvvfWW3Nzc5OnpqaioqLuee+TIkapSpYocHBxUsWJFjR07VtevXzftj4qKUu3atfXpp5/Kz89PLi4u6tGjhy5evGhqc/HiRfXu3VulSpWSl5eX3n///dt+duYjFO92zbm5uQoPD5e/v7/s7e1VtWpVzZo1q1D383ZatGihiIgIRUREyMXFRWXKlNHYsWNlNBpNbT799FPVr19fTk5O8vT0VK9evXT27FnT/j9Pybz1u7FhwwYFBgbK0dFRbdu2VXp6+j3XCQAAAADAo+KxCMzefvttTZ06VWPHjtXRo0f12WefqWzZsqb9o0ePVmRkpA4cOKAqVaqoZ8+epkAlJSVFbdu2VZcuXXTo0CEtXbpUP/zwgyIiIiRJe/bs0dChQzVhwgQlJydr/fr1atasmSRp1qxZCg4O1qBBg5Senq709HT5+PgUquYRI0YoJiZGiYmJcnd3V4cOHUxhzJUrV1SvXj2tWbNGP/74owYPHqw+ffpo9+7dBfYZExOj+vXra//+/XrllVf08ssvKzk5+a613Op38+bNSk9P14oVK9SsWTNVrFhRn376qand9evXFRcXpwEDBpi2Xbp0SZMmTdLixYuVkJCgjIwM9ejRw7R/27Zt6tu3r15//XUdPXpU8+bNU2xsrEWgeTfR0dHq1q2bDh06pPbt26t37946f/68JOnXX39V+/bt1aBBAx08eFAfffSR/vOf/+idd96x6GPRokUqVaqUdu3apWnTpmnChAnatGlTged1cnJSbGysjh49qlmzZmn+/Pl6//33LdqkpKRo1apV+uabb/TNN9/o+++/19SpU037hw8froSEBK1evVqbNm3Stm3btG/fvr90zXl5eSpfvry+/PJLHT16VOPGjdO///1vffHFF4W6n7ezaNEiWVtba/fu3Zo1a5ZmzJihBQsWmPZfv35dEydO1MGDB7Vq1SqlpqYqLCyswD4vXbqk6dOn69NPP9XWrVuVlpamyMjIO7a/evWqsrKyLF4AAAAAADyKDEbzYSaPoIsXL8rd3V1z587VwIEDLfbdWptrwYIFCg8PlyQdPXpUNWrUUFJSkqpVq6aBAwfKyspK8+bNMx33ww8/qHnz5srJydHatWvVv39//fLLL3Jycsp3/qKuYRYfH6+WLVtqyZIl6t69uyTp/PnzKl++vGJjY9WtW7fbHvfcc8+pWrVqmj59+m3P6+fnp6ZNm5oCLqPRKE9PT0VHR2vIkCEF1nSnNcymTZtmCoykm+um9evXT2fOnFGpUqUUGxur/v37a+fOnWrUqJEk6dixYwoMDNSuXbvUsGFDhYSEqFWrVnr77bdN/f73v//VW2+9pf/97393vV8Gg0FjxozRxIkTJUk5OTlydHTUunXr1LZtW40ePVrLly9XUlKSDAaDpJsjAkeOHKnMzEyVKFFCLVq0UG5urrZt22bqt2HDhnr22Wctwq27mT59upYsWaI9e/ZIujnC7L333tOZM2dMvxtvvfWWtm7dqp07d+rixYsqXbq0PvvsM9OoxMzMTHl7e2vQoEEWn92wYcNMo87uds23ExERoTNnzmjZsmWSbo5+zMjI0KpVq+56XS1atNDZs2d15MgR0z0cNWqUVq9ebfrs/2zPnj1q0KCBLl68KEdHR9Pv9YULF+Tq6mr63Th58qQqVaok6ebnMmHChHyjFm+JiopSdHR0vu2ZmZlydna+63UAAADg8XEm5lhxlwCYeL5ZrbhLwCMiKytLLi4uhfo79JEfYZaUlKSrV6+qVatWd2xTs2ZN089eXl6SZJpOdvDgQcXGxsrR0dH0Cg0NVV5enn766Se1bt1avr6+qlixovr06aO4uDhdunTpL9cdHBxs+tnNzU1Vq1ZVUlKSpJtT7iZOnKigoCC5ubnJ0dFRGzZsUFpaWoF9ml+nwWCQp6enxbS5ogoLC9PJkye1c+dOSTIFeuYL1FtbW6tBgwam99WqVZOrq6vpWg4ePKgJEyZY3N9bI/IKex/Nr6tUqVJydnY2XVdSUpKCg4NNQY8kNWnSRNnZ2frll19u24d08/fgVh9DhgyxqO+WpUuXqkmTJvL09JSjo6PGjBmT7zPw8/OzCFLN+z116pSuX7+uhg0bmva7uLioatWqf+maJemDDz5QvXr15O7uLkdHR/3f//3fXX8/CvL0009b3MPg4GCdOHFCubm5kqS9e/eqQ4cOqlChgpycnNS8eXNJKvCcDg4OprBMsrw3t/P2228rMzPT9Prz1F4AAAAAAB4Vj/yi//b29ndtY/40yVuhQF5eniQpOztbL730koYOHZrvuAoVKsjGxkb79u1TfHy8Nm7cqHHjxikqKkqJiYlydXW9PxfxJ++9955mzZqlmTNnKigoSKVKldKwYcN07dq1Ao/781MzDQaD6TrvhYeHhzp06KCFCxfK399f69atU3x8fJH6yM7OVnR0tDp37pxvn52dXaH6uB/XVVAfEyZMyDdVcMeOHerdu7eio6MVGhoqFxcXLVmyRDExMfe9tqLWu2TJEkVGRiomJkbBwcFycnLSe++9p127dv3l895OTk6OQkNDFRoaqri4OLm7uystLU2hoaEF/k7e7hoKGrBqa2srW1vb+1Y3AAAAAAAPyiMfmAUEBMje3l5btmzJNyWzMOrWraujR4+qcuXKd2xjbW2tkJAQhYSEaPz48XJ1ddW3336rzp07y8bGxjQKpyh27typChUqSJIuXLig48ePKzAwUJKUkJCgjh076sUXX5R0M9w7fvy4qlevXuTzFIaNjY0k3fY6Bg4cqJ49e6p8+fKqVKmSmjRpYrH/xo0b2rNnj2kUVXJysjIyMkzXUrduXSUnJxd4f/+KwMBALV++XEaj0RSGJiQkyMnJSeXLly9UHx4eHvLw8LDYtn37dvn6+mr06NGmbT///HORaqtYsaJKliypxMRE02edmZmp48ePm9bBuxcJCQlq3LixXnnlFdO2lJSUe+5PUr6wbefOnQoICJCVlZWOHTumP/74Q1OnTjWt0XdrWioAAAAAAH9Hj3xgZmdnp5EjR+qtt96SjY2NmjRpot9//11HjhwpcJrmLSNHjtTTTz+tiIgIDRw4UKVKldLRo0e1adMmzZ07V998841OnTqlZs2a6amnntLatWuVl5dnmlbn5+enXbt2KTU1VY6OjnJzc1OJEnefyTphwgSVLl1aZcuW1ejRo1WmTBl16tRJ0s0QcNmyZdq+fbueeuopzZgxQ7/99tsDC8w8PDxkb2+v9evXq3z58rKzs5OLi4skKTQ0VM7OznrnnXc0YcKEfMeWLFlSr732mmbPni1ra2tFRETo6aefNgVo48aN03PPPacKFSrohRdeUIkSJXTw4EH9+OOP+RbmvxevvPKKZs6cqddee00RERFKTk7W+PHjNXz48EJ9DncSEBCgtLQ0LVmyRA0aNNCaNWu0cuXKIvXh5OSkfv36acSIEXJzc5OHh4fGjx+vEiVKWEx/vJfaFi9erA0bNsjf31+ffvqpEhMTTU87vRdpaWkaPny4XnrpJe3bt09z5swxjaa7NdJyzpw5GjJkiH788UfT+moAAAAAAPwdPfJrmEnS2LFj9eabb2rcuHEKDAxU9+7dC712V82aNfX999/r+PHjatq0qerUqaNx48bJ29tbkuTq6qoVK1bo2WefVWBgoD7++GN9/vnnqlGjhiQpMjJSVlZWql69ummqWmFMnTpVr7/+uurVq6czZ87o66+/No30GjNmjOrWravQ0FC1aNFCnp6epjDtQbC2ttbs2bM1b948eXt7q2PHjqZ9JUqUUFhYmHJzc9W3b998xzo4OGjkyJHq1auXmjRpIkdHRy1dutS0PzQ0VN988402btyoBg0a6Omnn9b7778vX1/f+1J7uXLltHbtWu3evVu1atXSkCFDFB4erjFjxvylfv/1r3/pjTfeUEREhGrXrq3t27dr7NixRe5nxowZCg4O1nPPPaeQkBA1adJEgYGBhZ6OejsvvfSSOnfurO7du6tRo0b6448/LEab3Yu+ffvq8uXLatiwoV599VW9/vrrGjx4sCTJ3d1dsbGx+vLLL1W9enVNnTrV9PAJAAAAAAD+jh75p2Q+bv78NMHHQXh4uH7//XetXr3aYntsbKyGDRumjIyM4insMZSTk6Ny5copJibG9OTW4lbUJ70+LEV5OgkAAAAeLzwlE48SnpKJW4ryd+gjPyUTD05mZqYOHz6szz77LF9YhsLZv3+/jh07poYNGyozM9M0rdV8FB8AAAAAAHi8PBZTMh8lQ4YMkaOj421fQ4YMKZaaJk+efMea2rVrd8fjOnbsqDZt2mjIkCFq3br1fa8rLi7ujnXdmvL6JJg+fbpq1aqlkJAQ5eTkaNu2bSpTpsxDOXdaWtod77Gjo2OhpxADAAAAAID/hymZRXT27FllZWXddp+zs3O+pzE+DOfPn9f58+dvu8/e3l7lypV7yBXddPHiRf3222+33VeyZMn7ts7Z39mNGzeUmpp6x/1+fn6ytn40B5IyJRMAAODJxZRMPEqYkolbmJL5AHl4eBRLKFYQNzc3ubm5FXcZ+Tg5OcnJyam4y3iiWVtbq3LlysVdBgAAAAAATxSmZAIAAAAAAABmCMwAAAAAAAAAMwRmAAAAAAAAgBkCMwAAAAAAAMAMi/4DAAAAAO4rnkoI4HHHCDMAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzAAAAAAAAAAz1sVdAAAAAADgyXJ2znfFXQKAh8zjtZbFXcJ9xQgzAAAAAAAAwAyBGQAAAAAAAGCGwAwAAAAAAAAwQ2AGAAAAAAAAmCEwAwAAAAAAAMwQmAEAAAAAAABmCMwAAAAAAAAAMwRmAAAAAAAAgBkCMwAAAAAAAMAMgRkAAAAAAABghsAMd2UwGLRq1ariLgOSYmNj5erqel/7TE1NlcFg0IEDB+5rvwAAAAAAPK4IzJ5AYWFh6tSpU3GX8cDEx8fLYDAoIyOjuEt5Ivj4+Cg9PV3/+Mc/irsUAAAAAAAeCdbFXQCA4mVlZSVPT8/iLgMAAAAAgEcGI8weY8uWLVNQUJDs7e1VunRphYSEaMSIEVq0aJG++uorGQwGGQwGxcfHF9jPtWvXFBERIS8vL9nZ2cnX11dTpky5Y/vDhw/r2WefNZ138ODBys7ONu2/NcItOjpa7u7ucnZ21pAhQ3Tt2jVTm7y8PE2ZMkX+/v6yt7dXrVq1tGzZsrtec2pqqlq2bClJeuqpp2QwGBQWFqbFixerdOnSunr1qkX7Tp06qU+fPpKkqKgo1a5dW/PmzZOPj48cHBzUrVs3ZWZmWhyzYMECBQYGys7OTtWqVdOHH35417qk2498O3DggAwGg1JTUyX9vymVq1atUkBAgOzs7BQaGqrTp0+bjjl48KBatmwpJycnOTs7q169etqzZ88dz/vRRx+pUqVKsrGxUdWqVfXpp59a7DcYDProo4/Url072dvbq2LFihb3+s9TMm9dx5YtW1S/fn05ODiocePGSk5Otuj3nXfekYeHh5ycnDRw4ECNGjVKtWvXvmOdV69eVVZWlsULAAAAAIBHEYHZYyo9PV09e/bUgAEDlJSUpPj4eHXu3Fnjx49Xt27d1LZtW6Wnpys9PV2NGzcusK/Zs2dr9erV+uKLL5ScnKy4uDj5+fndtm1OTo5CQ0P11FNPKTExUV9++aU2b96siIgIi3Zbtmwx1fX5559rxYoVio6ONu2fMmWKFi9erI8//lhHjhzRG2+8oRdffFHff/99gbX6+Pho+fLlkqTk5GSlp6dr1qxZ6tq1q3Jzc7V69WpT27Nnz2rNmjUaMGCAadvJkyf1xRdf6Ouvv9b69eu1f/9+vfLKK6b9cXFxGjdunCZNmqSkpCRNnjxZY8eO1aJFiwqsqyguXbqkSZMmafHixUpISFBGRoZ69Ohh2t+7d2+VL19eiYmJ2rt3r0aNGqWSJUvetq+VK1fq9ddf15tvvqkff/xRL730kvr376/vvvvOot3YsWPVpUsXHTx4UL1791aPHj2UlJRUYJ2jR49WTEyM9uzZI2tra4v7GBcXp0mTJundd9/V3r17VaFCBX300UcF9jdlyhS5uLiYXj4+Pne7VQAAAAAAFAumZD6m0tPTdePGDXXu3Fm+vr6SpKCgIEmSvb29rl69WuhpdmlpaQoICNAzzzwjg8Fg6u92PvvsM125ckWLFy9WqVKlJElz585Vhw4d9O6776ps2bKSJBsbG33yySdycHBQjRo1NGHCBI0YMUITJ07U9evXNXnyZG3evFnBwcGSpIoVK+qHH37QvHnz1Lx58zue38rKSm5ubpIkDw8PiwXwe/XqpYULF6pr166SpP/+97+qUKGCWrRoYWpzq/Zy5cpJkubMmaN//vOfiomJkaenp8aPH6+YmBh17txZkuTv76+jR49q3rx56tevX6Hu591cv35dc+fOVaNGjSRJixYtUmBgoHbv3q2GDRsqLS1NI0aMULVq1SRJAQEBd+xr+vTpCgsLM4V+w4cP186dOzV9+nTTSDxJ6tq1qwYOHChJmjhxojZt2qQ5c+YUOHpu0qRJps9i1KhR+uc//6krV67Izs5Oc+bMUXh4uPr37y9JGjdunDZu3Ggx0vDP3n77bQ0fPtz0Pisri9AMAAAAAPBIYoTZY6pWrVpq1aqVgoKC1LVrV82fP18XLly4p77CwsJ04MABVa1aVUOHDtXGjRvv2DYpKUm1atUyhWWS1KRJE+Xl5VlM2atVq5YcHBxM74ODg5Wdna3Tp0/r5MmTunTpklq3bi1HR0fTa/HixUpJSbmna5CkQYMGaePGjfr1118l3Zz+GBYWJoPBYGpToUIFU1h2q65btefk5CglJUXh4eEWdb3zzjt/qa4/s7a2VoMGDUzvq1WrJldXV9OIr+HDh2vgwIEKCQnR1KlTCzx3UlKSmjRpYrGtSZMm+UaP3Qomzd/fbYRZzZo1TT97eXlJujlqT7o5uq9hw4YW7f/8/s9sbW3l7Oxs8QIAAAAA4FHECLPHlJWVlTZt2qTt27dr48aNmjNnjkaPHq1du3YVua+6devqp59+0rp167R582Z169ZNISEhhVpT7F7cGoW0Zs0ai/BKuhmq3Ks6deqoVq1aWrx4sdq0aaMjR45ozZo1Ra5r/vz5ptFft1hZWd31+BIlbubPRqPRtO369euFPv8tUVFR6tWrl9asWaN169Zp/PjxWrJkiZ5//vki9/VXmE8DvRU65uXlPdQaAAAAAAAoDowwe4wZDAY1adJE0dHR2r9/v2xsbLRy5UrZ2NgoNze3SH05Ozure/fumj9/vpYuXarly5fr/Pnz+doFBgbq4MGDysnJMW1LSEhQiRIlVLVqVdO2gwcP6vLly6b3O3fulKOjo3x8fFS9enXZ2toqLS1NlStXtngVZoqejY2NJN32GgcOHKjY2FgtXLhQISEh+fpLS0vT//73P4u6btVetmxZeXt769SpU/nq8vf3v2td7u7ukm5Ol73l1kL65m7cuGGxiH9ycrIyMjIUGBho2lalShW98cYb2rhxozp37qyFCxfe9pyBgYFKSEiw2JaQkKDq1atbbNu5c2e+9+bnK6qqVasqMTHRYtuf3wMAAAAA8LhihNljateuXdqyZYvatGkjDw8P7dq1S7///rsCAwN15coVbdiwQcnJySpdurRcXFzuuGi8JM2YMUNeXl6qU6eOSpQooS+//FKenp4W64Pd0rt3b40fP179+vVTVFSUfv/9d7322mvq06ePaf0y6eaTN8PDwzVmzBilpqZq/PjxioiIUIkSJeTk5KTIyEi98cYbysvL0zPPPKPMzEwlJCTI2dn5rmuF+fr6ymAw6JtvvlH79u1lb28vR0dHSTfXMYuMjNT8+fO1ePHifMfa2dmpX79+mj59urKysjR06FB169bNtN5bdHS0hg4dKhcXF7Vt21ZXr17Vnj17dOHCBYv1t27nVuAXFRWlSZMm6fjx44qJicnXrmTJknrttdc0e/ZsWVtbKyIiQk8//bQaNmyoy5cva8SIEXrhhRfk7++vX375RYmJierSpcttzzlixAh169ZNderUUUhIiL7++mutWLFCmzdvtmj35Zdfqn79+nrmmWcUFxen3bt36z//+U+B11OQ1157TYMGDVL9+vXVuHFjLV26VIcOHVLFihXvuU8AAAAAAB4VBGaPKWdnZ23dulUzZ85UVlaWfH19FRMTo3bt2ql+/fqKj49X/fr1lZ2dre+++85i4fs/c3Jy0rRp03TixAlZWVmpQYMGWrt2rWmKoTkHBwdt2LBBr7/+uho0aCAHBwd16dJFM2bMsGjXqlUrBQQEqFmzZrp69ap69uypqKgo0/6JEyfK3d1dU6ZM0alTp+Tq6qq6devq3//+912vvVy5coqOjtaoUaPUv39/9e3bV7GxsZIkFxcXdenSRWvWrFGnTp3yHVu5cmV17txZ7du31/nz5/Xcc89ZLHw/cOBAOTg46L333tOIESNUqlQpBQUFadiwYXetq2TJkvr888/18ssvq2bNmmrQoIHeeecd00MIzO/hyJEj1atXL/36669q2rSpKbyysrLSH3/8ob59++q3335TmTJl1LlzZ4snjJrr1KmTZs2apenTp+v111+Xv7+/Fi5cmO/zjo6O1pIlS/TKK6/Iy8tLn3/+eb5RaEXRu3dvnTp1SpGRkbpy5Yq6deumsLAw7d69+577BAAAAADgUWEwmi+4BNwHYWFhysjI0KpVq4rl/K1atVKNGjU0e/Zsi+1RUVFatWrVbadJPiyxsbEaNmyYMjIyHto5DQaDVq5cedsA8X5q3bq1PD099emnnxaqfVZWllxcXJSZmckDAAAAAJ4wZ+d8V9wlAHjIPF5rWdwl3FVR/g5lhBmeGBcuXFB8fLzi4+MtRo3h/rt06ZI+/vhjhYaGysrKSp9//rk2b96sTZs2FXdpAAAAAAD8ZSz6/zcwefJkOTo63vbVrl274i4vnyFDhtyx3iFDhtzxuDp16igsLEzvvvuuxQMI7pfH7T4+SAaDQWvXrlWzZs1Ur149ff3111q+fLlCQkKKuzQAAAAAAP4ypmT+DZw/f/62T7yUJHt7e5UrV+4hV1Sws2fPKisr67b7nJ2d5eHh8ZAruulxu4+POqZkAgAAPLmYkgn8/TAlE48dNzc3ubm5FXcZhebh4VFsoVhBHrf7CAAAAAAA7g1TMgEAAAAAAAAzBGYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGCGRf8BAAAAAPfV4/C0PAAoCCPMAAAAAAAAADMEZgAAAAAAAIAZpmQCKBZGo1GSlJWVVcyVAAAAAAD+Dm79/Xnr79GCEJgBKBYXL16UJPn4+BRzJQAAAACAv5OLFy/KxcWlwDYGY2FiNQC4z/Ly8vS///1PTk5OMhgM973/rKws+fj46PTp03J2dr7v/QNPEr4vQOHwXQEKh+8KUHh8Xx4uo9GoixcvytvbWyVKFLxKGSPMABSLEiVKqHz58g/8PM7OzvzDAxQS3xegcPiuAIXDdwUoPL4vD8/dRpbdwqL/AAAAAAAAgBkCMwAAAAAAAMAMgRmAJ5Ktra3Gjx8vW1vb4i4FeOTxfQEKh+8KUDh8V4DC4/vy6GLRfwAAAAAAAMAMI8wAAAAAAAAAMwRmAAAAAAAAgBkCMwAAAAAAAMAMgRkAAAAAAABghsAMwBNj0qRJaty4sRwcHOTq6lqoY8LCwmQwGCxebdu2fbCFAsXsXr4rRqNR48aNk5eXl+zt7RUSEqITJ0482EKBR8D58+fVu3dvOTs7y9XVVeHh4crOzi7wmBYtWuT7t2XIkCEPqWLg4fjggw/k5+cnOzs7NWrUSLt37y6w/Zdffqlq1arJzs5OQUFBWrt27UOqFCh+Rfm+xMbG5vs3xM7O7iFWi1sIzAA8Ma5du6auXbvq5ZdfLtJxbdu2VXp6uun1+eefP6AKgUfDvXxXpk2bptmzZ+vjjz/Wrl27VKpUKYWGhurKlSsPsFKg+PXu3VtHjhzRpk2b9M0332jr1q0aPHjwXY8bNGiQxb8t06ZNewjVAg/H0qVLNXz4cI0fP1779u1TrVq1FBoaqrNnz962/fbt29WzZ0+Fh4dr//796tSpkzp16qQff/zxIVcOPHxF/b5IkrOzs8W/IT///PNDrBi3GIxGo7G4iwCA+yk2NlbDhg1TRkbGXduGhYUpIyNDq1ateuB1AY+awn5XjEajvL299eabbyoyMlKSlJmZqbJlyyo2NlY9evR4CNUCD19SUpKqV6+uxMRE1a9fX5K0fv16tW/fXr/88ou8vb1ve1yLFi1Uu3ZtzZw58yFWCzw8jRo1UoMGDTR37lxJUl5ennx8fPTaa69p1KhR+dp3795dOTk5+uabb0zbnn76adWuXVsff/zxQ6sbKA5F/b4U5W8ZPFiMMAPwtxcfHy8PDw9VrVpVL7/8sv7444/iLgl4pPz00086c+aMQkJCTNtcXFzUqFEj7dixoxgrAx6sHTt2yNXV1RSWSVJISIhKlCihXbt2FXhsXFycypQpo3/84x96++23denSpQddLvBQXLt2TXv37rX4N6FEiRIKCQm5478JO3bssGgvSaGhofwbgifevXxfJCk7O1u+vr7y8fFRx44ddeTIkYdRLv7EurgLAIDi1LZtW3Xu3Fn+/v5KSUnRv//9b7Vr1047duyQlZVVcZcHPBLOnDkjSSpbtqzF9rJly5r2AU+iM2fOyMPDw2KbtbW13NzcCvzd79Wrl3x9feXt7a1Dhw5p5MiRSk5O1ooVKx50ycADd+7cOeXm5t7234Rjx47d9pgzZ87wbwj+lu7l+1K1alV98sknqlmzpjIzMzV9+nQ1btxYR44cUfny5R9G2fj/McIMwCNt1KhR+Ra9/PPrTv/YFEaPHj30r3/9S0FBQerUqZO++eYbJSYmKj4+/v5dBPAQPOjvCvAkedDfl8GDBys0NFRBQUHq3bu3Fi9erJUrVyolJeU+XgUA4EkUHBysvn37qnbt2mrevLlWrFghd3d3zZs3r7hL+9thhBmAR9qbb76psLCwAttUrFjxvp2vYsWKKlOmjE6ePKlWrVrdt36BB+1Bflc8PT0lSb/99pu8vLxM23/77TfVrl37nvoEilNhvy+enp75FmW+ceOGzp8/b/peFEajRo0kSSdPnlSlSpWKXC/wKClTpoysrKz022+/WWz/7bff7vi98PT0LFJ74ElxL9+XPytZsqTq1KmjkydPPogSUQACMwCPNHd3d7m7uz+08/3yyy/6448/LEIB4HHwIL8r/v7+8vT01JYtW0wBWVZWlnbt2lXkp9ICj4LCfl+Cg4OVkZGhvXv3ql69epKkb7/9Vnl5eaYQrDAOHDggSfzbgieCjY2N6tWrpy1btqhTp06Sbi5ivmXLFkVERNz2mODgYG3ZskXDhg0zbdu0aZOCg4MfQsVA8bmX78uf5ebm6vDhw2rfvv0DrBS3w5RMAE+MtLQ0HThwQGlpacrNzdWBAwd04MABZWdnm9pUq1ZNK1eulHRzMc0RI0Zo586dSk1N1ZYtW9SxY0dVrlxZoaGhxXUZwANX1O+KwWDQsGHD9M4772j16tU6fPiw+vbtK29vb9P/+AOeRIGBgWrbtq0GDRqk3bt3KyEhQREREerRo4fpCZm//vqrqlWrpt27d0uSUlJSNHHiRO3du1epqalavXq1+vbtq2bNmqlmzZrFeTnAfTN8+HDNnz9fixYtUlJSkl5++WXl5OSof//+kqS+ffvq7bffNrV//fXXtX79esXExOjYsWOKiorSnj17Ch0YAI+zon5fJkyYoI0bN+rUqVPat2+fXnzxRf38888aOHBgcV3C3xYjzAA8McaNG6dFixaZ3tepU0eS9N1336lFixaSpOTkZGVmZkqSrKysdOjQIS1atEgZGRny9vZWmzZtNHHiRNna2j70+oGHpajfFUl66623lJOTo8GDBysjI0PPPPOM1q9fLzs7u4daO/CwxcXFKSIiQq1atVKJEiXUpUsXzZ4927T/+vXrSk5ONj0F08bGRps3b9bMmTOVk5MjHx8fdenSRWPGjCmuSwDuu+7du+v333/XuHHjdObMGdWuXVvr1683LWyelpamEiX+39iMxo0b67PPPtOYMWP073//WwEBAVq1apX+8Y9/FNclAA9NUb8vFy5c0KBBg3TmzBk99dRTqlevnrZv367q1asX1yX8bRmMRqOxuIsAAAAAAAAAHhVMyQQAAAAAAADMEJgBAAAAAAAAZgjMAAAAAAAAADMEZgAAAAAAAIAZAjMAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYITADAAAA7tGZM2fUunVrlSpVSq6urnfcZjAYtGrVqkL1GRUVpdq1az+Qeh+Gx71+AAAkAjMAAAA8gc6cOaPXXntNFStWlK2trXx8fNShQwdt2bLlvp7n/fffV3p6ug4cOKDjx4/fcVt6erratWtXqD4jIyPve52xsbGm8O5OYmJi9NRTT+nKlSv59l26dEnOzs6aPXv2fa0LAIBHFYEZAAAAniipqamqV6+evv32W7333ns6fPiw1q9fr5YtW+rVV1+9r+dKSUlRvXr1FBAQIA8Pjztu8/T0lK2tbaH6dHR0VOnSpe9rnYXRp08f5eTkaMWKFfn2LVu2TNeuXdOLL7740OsCAKA4EJgBAADgifLKK6/IYDBo9+7d6tKli6pUqaIaNWpo+PDh2rlzp6ldWlqaOnbsKEdHRzk7O6tbt2767bffLPr66quvVLduXdnZ2alixYqKjo7WjRs3JEl+fn5avny5Fi9eLIPBoLCwsNtuk/JPyfzll1/Us2dPubm5qVSpUqpfv7527dol6fZTGhcsWKDAwEDZ2dmpWrVq+vDDD037UlNTZTAYtGLFCrVs2VIODg6qVauWduzYIUmKj49X//79lZmZKYPBIIPBoKioqHz3zcPDQx06dNAnn3ySb98nn3yiTp06yc3NTSNHjlSVKlXk4OCgihUrauzYsbp+/fodP48WLVpo2LBhFts6depkujeSdPXqVUVGRqpcuXIqVaqUGjVqpPj4+Dv2CQDAg2Zd3AUAAAAA98v58+e1fv16TZo0SaVKlcq3/9a0xLy8PFNY9v333+vGjRt69dVX1b17d1NQs23bNvXt21ezZ89W06ZNlZKSosGDB0uSxo8fr8TERPXt21fOzs6aNWuW7O3tde3atXzb/iw7O1vNmzdXuXLltHr1anl6emrfvn3Ky8u77TXFxcVp3Lhxmjt3rurUqaP9+/dr0KBBKlWqlPr162dqN3r0aE2fPl0BAQEaPXq0evbsqZMnT6px48aaOXOmxo0bp+TkZEk3R7HdTnh4uJ577jn9/PPP8vX1lSSdOnVKW7du1YYNGyRJTk5Oio2Nlbe3tw4fPqxBgwbJyclJb731ViE+oduLiIjQ0aNHtWTJEnl7e2vlypVq27atDh8+rICAgHvuFwCAe0VgBgAAgCfGyZMnZTQaVa1atQLbbdmyRYcPH9ZPP/0kHx8fSdLixYtVo0YNJSYmqkGDBoqOjtaoUaNMoVTFihU1ceJEvfXWWxo/frzc3d1la2sre3t7eXp6mvq+3TZzn332mX7//XclJibKzc1NklS5cuU71jp+/HjFxMSoc+fOkiR/f38dPXpU8+bNswjMIiMj9c9//lOSFB0drRo1aujkyZOqVq2aXFxcZDAY7ljTLaGhofL29tbChQtNo9BiY2Pl4+OjVq1aSZLGjBljau/n56fIyEgtWbLkngOztLQ0LVy4UGlpafL29jZdy/r167Vw4UJNnjz5nvoFAOCvIDADAADAE8NoNBaqXVJSknx8fExhmSRVr15drq6uSkpKUoMGDXTw4EElJCRo0qRJpja5ubm6cuWKLl26JAcHh3uq8cCBA6pTp44pLCtITk6OUlJSFB4erkGDBpm237hxQy4uLhZta9asafrZy8tLknT27Nm7hofmrKys1K9fP8XGxmr8+PEyGo1atGiR+vfvrxIlbq7msnTpUs2ePVspKSnKzs7WjRs35OzsXOhz/Nnhw4eVm5urKlWqWGy/evVqsazlBgCARGAGAACAJ0hAQIAMBoOOHTv2l/vKzs5WdHS0aWSXOTs7u3vu93bTNAuqQZLmz5+vRo0aWeyzsrKyeF+yZEnTzwaDQZLuOM2zIAMGDNCUKVP07bffKi8vT6dPn1b//v0lSTt27FDv3r0VHR2t0NBQubi4aMmSJYqJibljfyVKlMgXZJqveZadnS0rKyvt3bs33zXdaeooAAAPGoEZAAAAnhhubm4KDQ3VBx98oKFDh+ZbxywjI0Ourq4KDAzU6dOndfr0adMos6NHjyojI0PVq1eXJNWtW1fJyckFTpe8FzVr1tSCBQt0/vz5u44yK1u2rLy9vXXq1Cn17t37ns9pY2Oj3NzcQrWtVKmSmjdvrk8++URGo1EhISGm9cy2b98uX19fjR492tT+559/LrA/d3d3paenm97n5ubqxx9/VMuWLSVJderUUW5urs6ePaumTZsW9dIAAHggeEomAAAAnigffPCBcnNz1bBhQy1fvlwnTpxQUlKSZs+ereDgYElSSEiIgoKC1Lt3b+3bt0+7d+9W37591bx5c9WvX1+SNG7cOC1evFjR0dE6cuSIkpKStGTJEos1vO5Fz5495enpqU6dOikhIUGnTp3S8uXLTU+1/LPo6GhNmTJFs2fP1vHjx3X48GEtXLhQM2bMKPQ5/fz8lJ2drS1btujcuXO6dOlSge3Dw8O1YsUKrVy5UuHh4abtAQEBSktL05IlS5SSkqLZs2dr5cqVBfb17LPPas2aNVqzZo2OHTuml19+WRkZGab9VapUUe/evdW3b1+tWLFCP/30k3bv3q0pU6ZozZo1hb5GAADuJwIzAAAAPFEqVqyoffv2qWXLlnrzzTf1j3/8Q61bt9aWLVv00UcfSbo5ZfGrr77SU089pWbNmikkJEQVK1bU0qVLTf2Ehobqm2++0caNG9WgQQM9/fTTev/9902jre6VjY2NNm7cKA8PD7Vv315BQUGaOnVqvumItwwcOFALFizQwoULFRQUpObNmys2Nlb+/v6FPmfjxo01ZMgQde/eXe7u7po2bVqB7bt06SJbW1s5ODioU6dOpu3/+te/9MYbbygiIkK1a9fW9u3bNXbs2AL7GjBggPr162cKJCtWrGgaXXbLwoUL1bdvX7355puqWrWqOnXqpMTERFWoUKHQ1wgAwP1kMBZ2ZVQAAAAAAADgb4ARZgAAAAAAAIAZAjMAAAAAAADADIEZAAAAAAAAYIbADAAAAAAAADBDYAYAAAAAAACYITADAAAAAAAAzBCYAQAAAAAAAGYIzAAAAAAAAAAzBGYAAAAAAACAGQIzAAAAAAAAwAyBGQAAAAAAAGDm/wNeZjTG3p5hIgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the features and target columns\n",
    "feature_columns = [col_name for col_name in train.columns if col_name != \"target\"]\n",
    "target_column = \"target\"\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "transformed_train = assembler.transform(train)\n",
    "\n",
    "lasso = LogisticRegression(featuresCol=\"features\", \n",
    "                         labelCol=target_column, \n",
    "                         elasticNetParam=1.0, \n",
    "                         regParam=0.03,\n",
    "                         fitIntercept=False)\n",
    "\n",
    "lasso_model = lasso.fit(transformed_train)\n",
    "\n",
    "coefficients = lasso_model.coefficients.toArray()\n",
    "\n",
    "coef_scores = sorted(list(zip(feature_columns, coefficients)), key=lambda x: x[1])\n",
    "\n",
    "feature_importance = pd.DataFrame.from_records(coef_scores, columns = [\"Coefficient\", \"Importance\"])\n",
    "\n",
    "# Create a barplot to visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(y=\"Coefficient\", x=\"Importance\", data=feature_importance)\n",
    "plt.title(\"Updated Feature Coefficients Using Lasso Model\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cholesterol', 'st_slope_type_flat']\n",
      "+---+----------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+----------------+----------------------------+--------------------------------+-----------------------+----------------------------------+--------------------------+\n",
      "|sex|resting_blood_pressure|rest_ecg_type|max_heart_rate_achieved|exercise_induced_angina|st_depression|num_major_vessels|target|vessels_coloured|chest_pain_type_asymptomatic|chest_pain_type_non-anginal_pain|st_slope_type_upsloping|thalassemia_type_reversible_defect|resting_blood_pressure_log|\n",
      "+---+----------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+----------------+----------------------------+--------------------------------+-----------------------+----------------------------------+--------------------------+\n",
      "|  1|                   130|            0|                    202|                      0|          0.0|                0|     1|               0|                           0|                               0|                      1|                                 0|         4.867534450455582|\n",
      "|  0|                   118|            1|                    192|                      0|          0.7|                0|     1|               0|                           0|                               0|                      1|                                 0|         4.770684624465665|\n",
      "|  1|                   118|            0|                    174|                      0|          0.0|                0|     1|               0|                           0|                               0|                      1|                                 0|         4.770684624465665|\n",
      "|  1|                   120|            1|                    130|                      1|          1.6|                0|     0|               0|                           1|                               0|                      0|                                 1|         4.787491742782046|\n",
      "|  0|                   138|            1|                    182|                      0|          1.4|                0|     1|               0|                           1|                               0|                      1|                                 0|         4.927253685157205|\n",
      "+---+----------------------+-------------+-----------------------+-----------------------+-------------+-----------------+------+----------------+----------------------------+--------------------------------+-----------------------+----------------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_variables = [coef for coef, score in coef_scores if score == 0 and coef in heart.columns]\n",
    "pprint(dropped_variables)\n",
    "heart = heart.drop(*dropped_variables)\n",
    "heart = heart.withColumn(\"resting_blood_pressure_log\", log(train[\"resting_blood_pressure\"]))\n",
    "\n",
    "train = heart.filter(col(\"partition\") == \"train\").drop(\"partition\")\n",
    "test = heart.filter(col(\"partition\") == \"test\").drop(\"partition\")\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=train.toPandas(), x='target')\n",
    "plt.title(\"Target Variable Distribution Within Train Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "train = train.toPandas()\n",
    "\n",
    "train_x, train_y = train.drop(\"target\",axis=1), train[\"target\"]\n",
    "\n",
    "sm = SMOTE(random_state=722)\n",
    "new_x,new_y = sm.fit_resample(train_x, train_y)\n",
    "\n",
    "train = new_x\n",
    "train[\"target\"] = new_y\n",
    "\n",
    "train = spark.createDataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5PUlEQVR4nO3deVhWdf7/8dcNyg2ioCirIQK5i4qYpJl7AjY6LqO5zAwuo2Vqk0zlMFMqTUWllTWazmRqpWa7Zn2/rrmL5pL5y8qFSEvFHUhUQDi/P7q4v94Cyup9c3o+rutcF+dzPuec9zlww4tzPue+LYZhGAIAADApF0cXAAAAUJUIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIO8BtMGPGDFkslnKt27hxY/3ud7+7Zb9NmzbJYrFo06ZN5dpPZbidNRR3Ti0WiyZNmlTl+5akxYsXy2Kx6Mcff7wt+6tM3bt3V/fu3Uvdt3Xr1rfs9+OPP8pisWjx4sUVK+42s1gsmjFjhqPLQBUj7KAIi8VSqsmRf1SLs2PHDs2YMUMZGRk37ZeXl6cGDRqoS5cuJfYxDEPBwcFq3759JVdZfRT+8SqcatasqQYNGqhz5876xz/+oePHj1favp577jmtWLGi0rZXmZyttpYtW6pt27ZF2j/55BNZLBZ169atyLKFCxfKYrFo7dq1xW7z5MmTmjFjhvbv31/Z5ZZLYZC81dS4cWNHl1qsVatWqVu3bvLz81OtWrUUFhamoUOHavXq1eXanrP9DFZHNRxdAJzPO++8Yzf/9ttva926dUXaW7RocTvLuqUdO3YoKSlJo0aNUt26dUvsV7NmTQ0ZMkT/+c9/dOzYMYWEhBTps2XLFv3888+aMmVKpdT25JNP6u9//3ulbOt2Gz58uPr27auCggJdvHhRu3fv1uzZs/Xqq6/qzTff1LBhw2x9u3btqitXrsjNza1M+3juuef0hz/8QQMGDCj1OrfrnJZU25/+9CcNGzZMVqu1ymu4XpcuXfTmm28qMzNT3t7etvbt27erRo0a2r17t/Ly8lSzZk27Za6ururUqZMkFQk9J0+eVFJSkho3bqx27dqVq66QkBBduXLFbr/l1bVr1yK/b/7yl7+oY8eOGj9+vK2tdu3aFd7XlStXVKNG5f0pnDVrlh5//HF169ZNiYmJqlWrlo4ePar169dr+fLlio2NLfM2y/P6gD3CDor44x//aDe/c+dOrVu3rkh7eRiGoatXr8rDw6PC26qIkSNHav78+Xr33XeL/YO5bNkyubi42P0hL4/s7Gx5enqqRo0alfoL9XZq3759ke/9sWPH1KdPH8XHx6tFixa2Kw0uLi5yd3ev0nqc5Zy6urrK1dX1tu+3S5cueuONN7Rjxw7FxcXZ2rdv366hQ4dq2bJl2rt3r+6++27bsm3btqlNmzaqU6eOJJU5jJaGxWKptO99WFiYwsLC7NoeeughhYWF3fT30LVr11RQUFCm46vMn9dr167pX//6l+67775ir6KdOXOm0vaFsuE2Fspl0aJF6tmzp/z8/GS1WtWyZUvNmzevSL/C8SZr1qxRhw4d5OHhof/85z+Sfv2D2b9/f3l6esrPz09TpkzRmjVrir1FtmvXLsXGxsrb21u1atVSt27dtH37dtvyGTNm6PHHH5ckhYaG2i5zlzSe4p577lHjxo21bNmyIsvy8vL04YcfqkePHgoKCtKBAwc0atQohYWFyd3dXQEBARozZozOnz9vt17hGJJvv/1WI0aMUL169Wy3yoobX1Lac1ho7dq1ateundzd3dWyZUt9/PHHJfYty7krj5CQEC1evFi5ubl68cUXbe3Fjdk5cuSIBg8erICAALm7u+uOO+7QsGHDlJmZKenXP5LZ2dl66623bN+3UaNGSSr7OS20dOlSNWvWTO7u7oqKitKWLVvslo8aNarYWyA3bvNmtZU0Zuf1119Xq1atZLVaFRQUpIkTJxa5tVo4Dubbb79Vjx49VKtWLTVs2NDuXJak8Piv/x5evXpV+/bt06BBgxQWFma37OzZszp8+LDdbdvrx+xs2rRJd911lyRp9OjRtuO8cezNrWotbszOqFGjVLt2bZ04cUIDBgxQ7dq15evrq8cee0z5+fm3PNabKdzfrFmzNHv2bIWHh8tqterbb79Vbm6upk2bpqioKHl7e8vT01P33nuvNm7cWGQ7N47ZKfwZOHr0qO0qsbe3t0aPHq3Lly/ftKZz584pKytL99xzT7HL/fz87OZzcnI0ffp03XnnnbJarQoODtYTTzyhnJwcu/pK+hlE6VXPfzXhcPPmzVOrVq3Uv39/1ahRQ6tWrdLDDz+sgoICTZw40a7voUOHNHz4cD344IMaN26cmjVrpuzsbPXs2VOnTp3SX//6VwUEBGjZsmXF/jL64osvFBcXp6ioKE2fPl0uLi62oLB161Z17NhRgwYN0uHDh/Xuu+/qlVdeUYMGDSRJvr6+xdZvsVg0YsQIPffcczp48KBatWplW7Z69WpduHBBI0eOlCStW7dOP/zwg0aPHq2AgAAdPHhQ//3vf3Xw4EHt3LmzyB/cIUOGqEmTJnruuedkGEalnMMjR47ogQce0EMPPaT4+HgtWrRIQ4YM0erVq3XfffeVuI/SnLvy6tSpk8LDw7Vu3boS++Tm5iomJkY5OTmaPHmyAgICdOLECX322WfKyMiQt7e33nnnnSK3KMLDw+22U9pzKkmbN2/We++9p0ceeURWq1Wvv/66YmNj9eWXX5ZqoO31SlPb9WbMmKGkpCT17t1bEyZM0KFDhzRv3jzt3r1b27dvt7vFc/HiRcXGxmrQoEEaOnSoPvzwQ02dOlURERF2V2xuFBYWpqCgIG3bts3Wtnv3buXm5qpz587q3Lmztm/frr/97W+Sfr29K6nEMWotWrTQ008/rWnTpmn8+PG69957JUmdO3eucK2SlJ+fr5iYGEVHR2vWrFlav369XnrpJYWHh2vChAk3Xbc0Fi1apKtXr2r8+PGyWq3y8fFRVlaWFixYoOHDh2vcuHH65Zdf9OabbyomJkZffvllqW7VDR06VKGhoUpOTta+ffu0YMEC+fn56YUXXihxHT8/P3l4eGjVqlWaPHmyfHx8SuxbUFCg/v37a9u2bRo/frxatGih//f//p9eeeUVHT582DZGp6w/gyiBAdzCxIkTjRt/VC5fvlykX0xMjBEWFmbXFhISYkgyVq9ebdf+0ksvGZKMFStW2NquXLliNG/e3JBkbNy40TAMwygoKDCaNGlixMTEGAUFBXb7Dw0NNe677z5b28yZMw1JRlpaWqmO6+DBg4YkIzEx0a592LBhhru7u5GZmVnisb777ruGJGPLli22tunTpxuSjOHDhxfpX7jsemU9hx999JGtLTMz0wgMDDQiIyNtbRs3biz3uStOWlqaIcmYOXNmiX1+//vfG5Js5+rGGr766itDkvHBBx/cdF+enp5GfHx8kfaynlNJhiRjz549trZjx44Z7u7uxsCBA21t8fHxRkhISKm2WVJtixYtsvt5O3PmjOHm5mb06dPHyM/Pt/WbM2eOIclYuHChra1bt26GJOPtt9+2teXk5BgBAQHG4MGDi+zrRkOGDDE8PDyM3NxcwzAMIzk52QgNDTUMwzBef/11w8/Pz9b3scceMyQZJ06csNt/t27dbPO7d+82JBmLFi0qsq/S1lr483L9NuLj4w1JxtNPP223zcjISCMqKuqWx3m9G78Phfvz8vIyzpw5Y9f32rVrRk5Ojl3bxYsXDX9/f2PMmDF27ZKM6dOn2+YLfwZu7Ddw4ECjfv36t6xz2rRphiTD09PTiIuLM5599llj7969Rfq98847houLi7F161a79vnz5xuSjO3bt5d47Cg7bmOhXK4fc5OZmalz586pW7du+uGHH2y3JwqFhoYqJibGrm316tVq2LCh+vfvb2tzd3fXuHHj7Prt379fR44c0YgRI3T+/HmdO3dO586dU3Z2tnr16qUtW7aooKCgXMfQsmVLRUZGavny5ba27Oxsffrpp/rd734nLy+vIsd69epVnTt3zjYeYt++fUW2+9BDD5Vq/2U5h0FBQRo4cKBt3svLS3/+85/11VdfKT09vdjtV+W5K1Q4QPSXX34pdnnhANo1a9bc8hbAzZT2nEq/XnGKioqyzTdq1Ei///3vtWbNmgrfOrmZ9evXKzc3V48++qhcXP7vV+u4cePk5eWlzz//3K5/7dq17cafuLm5qWPHjvrhhx9uua8uXbroypUr2rt3r6Rfb2kVXom55557dObMGR05csS2LDQ0VEFBQeU+torUKhX9/t17772lXvdWBg8eXOQKrqurq23cTkFBgS5cuKBr166pQ4cOxb5mS1vz+fPnlZWVddP1kpKStGzZMkVGRmrNmjX65z//qaioKLVv317fffedrd8HH3ygFi1aqHnz5rbX5rlz59SzZ09JKvYqN8qPsINy2b59u3r37i1PT0/VrVtXvr6++sc//iFJxYadGx07dkzh4eFFbgHdeeeddvOFv7Dj4+Pl6+trNy1YsEA5OTlF9lcWI0eOVFpamu1S/4oVK3T58mXbLSxJunDhgv7617/K399fHh4e8vX1tR1Tcfsu7niLU5ZzeOeddxY5V02bNpWkEsclVfW5k6RLly5Jkm3g641CQ0OVkJCgBQsWqEGDBoqJidHcuXPLvN/SnlNJatKkSZG2pk2b6vLlyzp79myZ9lsWx44dkyQ1a9bMrt3NzU1hYWG25YXuuOOOIt/TevXq6eLFi7fc1/XjdgzD0I4dO2zjRFq3bi0vLy9t375dV69e1d69e2/6NgulUZFa3d3di4SR0q5bGiX9bLz11ltq06aN3N3dVb9+ffn6+urzzz8v9c9eo0aN7Obr1asnSaWqe/jw4dq6dasuXryotWvXasSIEfrqq6/Ur18/Xb16VdKvr8+DBw8WeW0Wvq4ZzFy5GLODMktNTVWvXr3UvHlzvfzyywoODpabm5v+53/+R6+88kqRqwUVefKqcFszZ84s8T57RR4/HT58uJ544gktW7ZMnTt31rJly1SvXj317dvX1mfo0KHasWOHHn/8cbVr1061a9dWQUGBYmNji70yUprjLes5LI+qPneS9M0338jPz892Faw4L730kkaNGqWVK1dq7dq1euSRR5ScnKydO3fqjjvuKNV+KvvpvZIGNlfllZ8blfQkl3GLMUmS1LZtW9WpU0fbtm1T3759deHCBduVHRcXF0VHR2vbtm0KDw9Xbm5uhcNORWqt6ifWivvZWLJkiUaNGqUBAwbo8ccfl5+fn1xdXZWcnKzU1NRSbbcix1zIy8tL9913n+677z7VrFlTb731lnbt2qVu3bqpoKBAERERevnll4tdNzg4uNT7wa0RdlBmq1atUk5Ojj799FO7/37Kctk1JCRE3377rQzDsPvDc/ToUbt+hQPxvLy81Lt375tuszzvUBwUFKQePXrogw8+0FNPPaV169Zp1KhRtkvgFy9e1IYNG5SUlKRp06bZ1iu8alJeZT2HR48eLXKuDh8+LEklvrFaWc5deaSkpCg1NbVUb0kQERGhiIgIPfnkk7arEPPnz9czzzwjqXzfu5IU9705fPiwatWqZbvCUK9evWLffPLGqy9lqa3w/ZoOHTpk99h0bm6u0tLSKvV74Orqqrvvvlvbt2/Xtm3b5OXlpYiICNvyzp0767333rNdKb1V2KnM8+8MPvzwQ4WFhenjjz+2O7bp06c7rKYOHTrorbfe0qlTpyT9+vr8+uuv1atXr1uef7N9fxyB21gos8L/eK7/DyczM1OLFi0q9TZiYmJ04sQJffrpp7a2q1ev6o033rDrFxUVpfDwcM2aNct2y+R619+W8PT0lKRbvoPyjUaOHKkzZ87owQcfVF5ent0trOKOVZJmz55dpn3cqKzn8OTJk/rkk09s81lZWXr77bfVrl07BQQEFLtOWc5dWR07dswWCgsf+S9OVlaWrl27ZtcWEREhFxcXu8drPT09y/x9K0lKSorduIyffvpJK1euVJ8+fWznPTw8XJmZmTpw4ICt36lTp+zOcVlr6927t9zc3PTaa6/ZfV8L3wDw/vvvr8BRFdWlSxedPXtWixYtUnR0tN04oc6dO+vQoUNauXKl6tevf8s3AC3va8dZFff62rVrl1JSUqp0v5cvXy5xH//7v/8r6f9ucw4dOlQnTpwo8jtP+vWNDrOzs23zlfn6+K3iyg7KrE+fPnJzc1O/fv304IMP6tKlS3rjjTfk5+dn+6/lVh588EHNmTNHw4cP11//+lcFBgZq6dKltjf4KvxPxsXFRQsWLFBcXJxatWql0aNHq2HDhjpx4oQ2btwoLy8vrVq1SpJsg1L/+c9/atiwYapZs6b69etn+0VeksGDB+vhhx/WypUrFRwcrK5du9qWeXl5qWvXrnrxxReVl5enhg0bau3atUpLSyvzebteWc9h06ZNNXbsWO3evVv+/v5auHChTp8+fdOAWZZzdzP79u3TkiVLVFBQoIyMDO3evVsfffSRLBaL3nnnHbVp06bEdb/44gtNmjRJQ4YMUdOmTXXt2jW98847cnV11eDBg239oqKitH79er388ssKCgpSaGiooqOjb1lbcVq3bq2YmBi7R8+lXweOFho2bJimTp2qgQMH6pFHHtHly5c1b948NW3atMgA1tLW5uvrq8TERCUlJSk2Nlb9+/fXoUOH9Prrr+uuu+6qlDflvF7h1ZqUlJQin+109913y2KxaOfOnerXr98trwyEh4erbt26mj9/vurUqSNPT09FR0eXaayUM/nd736njz/+WAMHDtT999+vtLQ0zZ8/Xy1btiw2+FeWy5cvq3Pnzrr77rsVGxur4OBgZWRkaMWKFdq6dasGDBigyMhISb++A/f777+vhx56SBs3btQ999yj/Px8ff/993r//fdt700mVe7r4zfLQU+BoRop7tHzTz/91GjTpo3h7u5uNG7c2HjhhReMhQsXFnn0OyQkxLj//vuL3e4PP/xg3H///YaHh4fh6+tr/O1vfzM++ugjQ5Kxc+dOu75fffWVMWjQIKN+/fqG1Wo1QkJCjKFDhxobNmyw6/evf/3LaNiwoeHi4lKmx9CHDBliSDKeeOKJIst+/vlnY+DAgUbdunUNb29vY8iQIcbJkydLfGT17NmzRbZR3CPNZT2Ha9asMdq0aWNYrVajefPmRR7nvvGx77KeuxsVPtpbONWoUcPw8fExoqOjjcTEROPYsWNF1rmxhh9++MEYM2aMER4ebri7uxs+Pj5Gjx49jPXr19ut9/333xtdu3Y1PDw8DEm2x2zLek4lGRMnTjSWLFliNGnSxLBarUZkZGSRc2IYhrF27VqjdevWhpubm9GsWTNjyZIlxW6zpNpufPS80Jw5c4zmzZsbNWvWNPz9/Y0JEyYYFy9etOvTrVs3o1WrVkVqKumR+OJkZ2cbNWrUMCQZa9euLbK8TZs2hiTjhRdeKLLsxkfPDcMwVq5cabRs2dK2zcJHyEtba0mPnnt6ehZZt7jzfCslPXpe3FsjFBQUGM8995wREhJi+xn47LPPij2/pX0dl/T9vl5eXp7xxhtvGAMGDLDtu1atWkZkZKQxc+bMIo/D5+bmGi+88ILRqlUrw2q1GvXq1TOioqKMpKQk29s5GEbJP4MoPYthlGG0FVDFZs+erSlTpujnn39Ww4YNHV0OAMAECDtwmCtXrhR5D5vIyEjl5+fbBt8CAFBRjNmBwwwaNEiNGjVSu3btlJmZqSVLluj777/X0qVLHV0aAMBECDtwmJiYGC1YsEBLly5Vfn6+WrZsqeXLl+uBBx5wdGkAABPhNhYAADA13mcHAACYGmEHAACYGmN29OtnCJ08eVJ16tThbbkBAKgmDMPQL7/8oqCgILt3Eb8RYUe/vhU/H7oGAED19NNPP930g4UJO5Lq1Kkj6deTdbNPbwYAAM4jKytLwcHBtr/jJSHs6P8+h8nLy4uwAwBANXOrISgMUAYAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZWw9EF/Fbs6dDR0SUATqnDni8dXUKFxT71nqNLAJzS6n894OgSJHFlBwAAmBxhBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmJpDw86WLVvUr18/BQUFyWKxaMWKFXbLLRZLsdPMmTNtfRo3blxk+fPPP3+bjwQAADgrh4ad7OxstW3bVnPnzi12+alTp+ymhQsXymKxaPDgwXb9nn76abt+kydPvh3lAwCAasChHxcRFxenuLi4EpcHBATYza9cuVI9evRQWFiYXXudOnWK9AUAAJCq0Zid06dP6/PPP9fYsWOLLHv++edVv359RUZGaubMmbp27dpNt5WTk6OsrCy7CQAAmFO1+SDQt956S3Xq1NGgQYPs2h955BG1b99ePj4+2rFjhxITE3Xq1Cm9/PLLJW4rOTlZSUlJVV0yAABwAtUm7CxcuFAjR46Uu7u7XXtCQoLt6zZt2sjNzU0PPvigkpOTZbVai91WYmKi3XpZWVkKDg6umsIBAIBDVYuws3XrVh06dEjvvffeLftGR0fr2rVr+vHHH9WsWbNi+1it1hKDEAAAMJdqMWbnzTffVFRUlNq2bXvLvvv375eLi4v8/PxuQ2UAAMDZOfTKzqVLl3T06FHbfFpamvbv3y8fHx81atRI0q+3mD744AO99NJLRdZPSUnRrl271KNHD9WpU0cpKSmaMmWK/vjHP6pevXq37TgAAIDzcmjY2bNnj3r06GGbLxxHEx8fr8WLF0uSli9fLsMwNHz48CLrW61WLV++XDNmzFBOTo5CQ0M1ZcoUu/E4AADgt82hYad79+4yDOOmfcaPH6/x48cXu6x9+/bauXNnVZQGAABMolqM2QEAACgvwg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1h4adLVu2qF+/fgoKCpLFYtGKFSvslo8aNUoWi8Vuio2Ntetz4cIFjRw5Ul5eXqpbt67Gjh2rS5cu3cajAAAAzsyhYSc7O1tt27bV3LlzS+wTGxurU6dO2aZ3333XbvnIkSN18OBBrVu3Tp999pm2bNmi8ePHV3XpAACgmqjhyJ3HxcUpLi7upn2sVqsCAgKKXfbdd99p9erV2r17tzp06CBJ+ve//62+fftq1qxZCgoKqvSaAQBA9eL0Y3Y2bdokPz8/NWvWTBMmTND58+dty1JSUlS3bl1b0JGk3r17y8XFRbt27XJEuQAAwMk49MrOrcTGxmrQoEEKDQ1Vamqq/vGPfyguLk4pKSlydXVVenq6/Pz87NapUaOGfHx8lJ6eXuJ2c3JylJOTY5vPysqqsmMAAACO5dRhZ9iwYbavIyIi1KZNG4WHh2vTpk3q1atXubebnJyspKSkyigRAAA4Oae/jXW9sLAwNWjQQEePHpUkBQQE6MyZM3Z9rl27pgsXLpQ4zkeSEhMTlZmZaZt++umnKq0bAAA4TrUKOz///LPOnz+vwMBASVKnTp2UkZGhvXv32vp88cUXKigoUHR0dInbsVqt8vLyspsAAIA5OfQ21qVLl2xXaSQpLS1N+/fvl4+Pj3x8fJSUlKTBgwcrICBAqampeuKJJ3TnnXcqJiZGktSiRQvFxsZq3Lhxmj9/vvLy8jRp0iQNGzaMJ7EAAIAkB1/Z2bNnjyIjIxUZGSlJSkhIUGRkpKZNmyZXV1cdOHBA/fv3V9OmTTV27FhFRUVp69atslqttm0sXbpUzZs3V69evdS3b1916dJF//3vfx11SAAAwMk49MpO9+7dZRhGicvXrFlzy234+Pho2bJllVkWAAAwkWo1ZgcAAKCsCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUHBp2tmzZon79+ikoKEgWi0UrVqywLcvLy9PUqVMVEREhT09PBQUF6c9//rNOnjxpt43GjRvLYrHYTc8///xtPhIAAOCsHBp2srOz1bZtW82dO7fIssuXL2vfvn166qmntG/fPn388cc6dOiQ+vfvX6Tv008/rVOnTtmmyZMn347yAQBANVDDkTuPi4tTXFxcscu8vb21bt06u7Y5c+aoY8eOOn78uBo1amRrr1OnjgICAqq0VgAAUD1VqzE7mZmZslgsqlu3rl37888/r/r16ysyMlIzZ87UtWvXbrqdnJwcZWVl2U0AAMCcHHplpyyuXr2qqVOnavjw4fLy8rK1P/LII2rfvr18fHy0Y8cOJSYm6tSpU3r55ZdL3FZycrKSkpJuR9kAAMDBqkXYycvL09ChQ2UYhubNm2e3LCEhwfZ1mzZt5ObmpgcffFDJycmyWq3Fbi8xMdFuvaysLAUHB1dN8QAAwKGcPuwUBp1jx47piy++sLuqU5zo6Ghdu3ZNP/74o5o1a1ZsH6vVWmIQAgAA5uLUYacw6Bw5ckQbN25U/fr1b7nO/v375eLiIj8/v9tQIQAAcHYODTuXLl3S0aNHbfNpaWnav3+/fHx8FBgYqD/84Q/at2+fPvvsM+Xn5ys9PV2S5OPjIzc3N6WkpGjXrl3q0aOH6tSpo5SUFE2ZMkV//OMfVa9ePUcdFgAAcCIODTt79uxRjx49bPOF42ji4+M1Y8YMffrpp5Kkdu3a2a23ceNGde/eXVarVcuXL9eMGTOUk5Oj0NBQTZkyxW48DgAA+G1zaNjp3r27DMMocfnNlklS+/bttXPnzsouCwAAmEi1ep8dAACAsiLsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUytX2OnZs6cyMjKKtGdlZalnz54VrQkAAKDSlCvsbNq0Sbm5uUXar169qq1bt1a4KAAAgMpSoyydDxw4YPv622+/VXp6um0+Pz9fq1evVsOGDSuvOgAAgAoqU9hp166dLBaLLBZLsberPDw89O9//7vSigMAAKioMt3GSktLU2pqqgzD0Jdffqm0tDTbdOLECWVlZWnMmDGl3t6WLVvUr18/BQUFyWKxaMWKFXbLDcPQtGnTFBgYKA8PD/Xu3VtHjhyx63PhwgWNHDlSXl5eqlu3rsaOHatLly6V5bAAAICJlSnshISEqHHjxiooKFCHDh0UEhJimwIDA+Xq6lqmnWdnZ6tt27aaO3dusctffPFFvfbaa5o/f7527dolT09PxcTE6OrVq7Y+I0eO1MGDB7Vu3Tp99tln2rJli8aPH1+mOgAAgHmV6TbW9Y4cOaKNGzfqzJkzKigosFs2bdq0Um0jLi5OcXFxxS4zDEOzZ8/Wk08+qd///veSpLffflv+/v5asWKFhg0bpu+++06rV6/W7t271aFDB0nSv//9b/Xt21ezZs1SUFBQeQ8PAACYRLnCzhtvvKEJEyaoQYMGCggIkMVisS2zWCylDjs3k5aWpvT0dPXu3dvW5u3trejoaKWkpGjYsGFKSUlR3bp1bUFHknr37i0XFxft2rVLAwcOLHbbOTk5ysnJsc1nZWVVuF4AAOCcyhV2nnnmGT377LOaOnVqZddjU/ikl7+/v127v7+/bVl6err8/PzslteoUUM+Pj52T4rdKDk5WUlJSZVcMQAAcEblep+dixcvasiQIZVdy22TmJiozMxM2/TTTz85uiQAAFBFyhV2hgwZorVr11Z2LXYCAgIkSadPn7ZrP336tG1ZQECAzpw5Y7f82rVrunDhgq1PcaxWq7y8vOwmAABgTuW6jXXnnXfqqaee0s6dOxUREaGaNWvaLX/kkUcqXFhoaKgCAgK0YcMGtWvXTtKvY2t27dqlCRMmSJI6deqkjIwM7d27V1FRUZKkL774QgUFBYqOjq5wDQAAoPorV9j573//q9q1a2vz5s3avHmz3TKLxVLqsHPp0iUdPXrUNp+Wlqb9+/fLx8dHjRo10qOPPqpnnnlGTZo0UWhoqJ566ikFBQVpwIABkqQWLVooNjZW48aN0/z585WXl6dJkyZp2LBhPIkFAAAklTPspKWlVcrO9+zZox49etjmExISJEnx8fFavHixnnjiCWVnZ2v8+PHKyMhQly5dtHr1arm7u9vWWbp0qSZNmqRevXrJxcVFgwcP1muvvVYp9QEAgOrPYhiG4egiHC0rK0ve3t7KzMyssvE7ezp0rJLtAtVdhz1fOrqECot96j1HlwA4pdX/eqBKt1/av9/lurJzq4+EWLhwYXk2CwAAUOnKFXYuXrxoN5+Xl6dvvvlGGRkZxX5AKAAAgKOUK+x88sknRdoKCgo0YcIEhYeHV7goAACAylKu99kpdkMuLkpISNArr7xSWZsEAACosEoLO5KUmpqqa9euVeYmAQAAKqRct7EKHxEvZBiGTp06pc8//1zx8fGVUhgAAEBlKFfY+eqrr+zmXVxc5Ovrq5deeumWT2oBAADcTuUKOxs3bqzsOgAAAKpEucJOobNnz+rQoUOSpGbNmsnX17dSigIAAKgs5RqgnJ2drTFjxigwMFBdu3ZV165dFRQUpLFjx+ry5cuVXSMAAEC5lSvsJCQkaPPmzVq1apUyMjKUkZGhlStXavPmzfrb3/5W2TUCAACUW7luY3300Uf68MMP1b17d1tb37595eHhoaFDh2revHmVVR8AAECFlOvKzuXLl+Xv71+k3c/Pj9tYAADAqZQr7HTq1EnTp0/X1atXbW1XrlxRUlKSOnXqVGnFAQAAVFS5bmPNnj1bsbGxuuOOO9S2bVtJ0tdffy2r1aq1a9dWaoEAAAAVUa6wExERoSNHjmjp0qX6/vvvJUnDhw/XyJEj5eHhUakFAgAAVES5wk5ycrL8/f01btw4u/aFCxfq7Nmzmjp1aqUUBwAAUFHlGrPzn//8R82bNy/S3qpVK82fP7/CRQEAAFSWcoWd9PR0BQYGFmn39fXVqVOnKlwUAABAZSlX2AkODtb27duLtG/fvl1BQUEVLgoAAKCylGvMzrhx4/Too48qLy9PPXv2lCRt2LBBTzzxBO+gDAAAnEq5ws7jjz+u8+fP6+GHH1Zubq4kyd3dXVOnTlViYmKlFggAAFAR5Qo7FotFL7zwgp566il999138vDwUJMmTWS1Wiu7PgAAgAopV9gpVLt2bd11112VVQsAAEClK9cAZQAAgOqCsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEzN6cNO48aNZbFYikwTJ06UJHXv3r3IsoceesjBVQMAAGdRw9EF3Mru3buVn59vm//mm2903333aciQIba2cePG6emnn7bN16pV67bWCAAAnJfThx1fX1+7+eeff17h4eHq1q2bra1WrVoKCAi43aUBAIBqwOlvY10vNzdXS5Ys0ZgxY2SxWGztS5cuVYMGDdS6dWslJibq8uXLDqwSAAA4E6e/snO9FStWKCMjQ6NGjbK1jRgxQiEhIQoKCtKBAwc0depUHTp0SB9//HGJ28nJyVFOTo5tPisrqyrLBgAADlStws6bb76puLg4BQUF2drGjx9v+zoiIkKBgYHq1auXUlNTFR4eXux2kpOTlZSUVOX1AgAAx6s2t7GOHTum9evX6y9/+ctN+0VHR0uSjh49WmKfxMREZWZm2qaffvqpUmsFAADOo9pc2Vm0aJH8/Px0//3337Tf/v37JUmBgYEl9rFarbJarZVZHgAAcFLVIuwUFBRo0aJFio+PV40a/1dyamqqli1bpr59+6p+/fo6cOCApkyZoq5du6pNmzYOrBgAADiLahF21q9fr+PHj2vMmDF27W5ublq/fr1mz56t7OxsBQcHa/DgwXryyScdVCkAAHA21SLs9OnTR4ZhFGkPDg7W5s2bHVARAACoLqrNAGUAAIDyIOwAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTI+wAAABTc+qwM2PGDFksFrupefPmtuVXr17VxIkTVb9+fdWuXVuDBw/W6dOnHVgxAABwNk4ddiSpVatWOnXqlG3atm2bbdmUKVO0atUqffDBB9q8ebNOnjypQYMGObBaAADgbGo4uoBbqVGjhgICAoq0Z2Zm6s0339SyZcvUs2dPSdKiRYvUokUL7dy5U3ffffftLhUAADghp7+yc+TIEQUFBSksLEwjR47U8ePHJUl79+5VXl6eevfubevbvHlzNWrUSCkpKTfdZk5OjrKysuwmAABgTk4ddqKjo7V48WKtXr1a8+bNU1pamu6991798ssvSk9Pl5ubm+rWrWu3jr+/v9LT02+63eTkZHl7e9um4ODgKjwKAADgSE59GysuLs72dZs2bRQdHa2QkBC9//778vDwKPd2ExMTlZCQYJvPysoi8AAAYFJOfWXnRnXr1lXTpk119OhRBQQEKDc3VxkZGXZ9Tp8+XewYn+tZrVZ5eXnZTQAAwJyqVdi5dOmSUlNTFRgYqKioKNWsWVMbNmywLT906JCOHz+uTp06ObBKAADgTJz6NtZjjz2mfv36KSQkRCdPntT06dPl6uqq4cOHy9vbW2PHjlVCQoJ8fHzk5eWlyZMnq1OnTjyJBQAAbJw67Pz8888aPny4zp8/L19fX3Xp0kU7d+6Ur6+vJOmVV16Ri4uLBg8erJycHMXExOj11193cNUAAMCZOHXYWb58+U2Xu7u7a+7cuZo7d+5tqggAAFQ31WrMDgAAQFkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKk5ddhJTk7WXXfdpTp16sjPz08DBgzQoUOH7Pp0795dFovFbnrooYccVDEAAHA2Th12Nm/erIkTJ2rnzp1at26d8vLy1KdPH2VnZ9v1GzdunE6dOmWbXnzxRQdVDAAAnE0NRxdwM6tXr7abX7x4sfz8/LR371517drV1l6rVi0FBATc7vIAAEA14NRXdm6UmZkpSfLx8bFrX7p0qRo0aKDWrVsrMTFRly9fvul2cnJylJWVZTcBAABzcuorO9crKCjQo48+qnvuuUetW7e2tY8YMUIhISEKCgrSgQMHNHXqVB06dEgff/xxidtKTk5WUlLS7SgbAAA4WLUJOxMnTtQ333yjbdu22bWPHz/e9nVERIQCAwPVq1cvpaamKjw8vNhtJSYmKiEhwTaflZWl4ODgqikcAAA4VLUIO5MmTdJnn32mLVu26I477rhp3+joaEnS0aNHSww7VqtVVqu10usEAADOx6nDjmEYmjx5sj755BNt2rRJoaGht1xn//79kqTAwMAqrg4AAFQHTh12Jk6cqGXLlmnlypWqU6eO0tPTJUne3t7y8PBQamqqli1bpr59+6p+/fo6cOCApkyZoq5du6pNmzYOrh4AADgDpw478+bNk/TrGwdeb9GiRRo1apTc3Ny0fv16zZ49W9nZ2QoODtbgwYP15JNPOqBaAADgjJw67BiGcdPlwcHB2rx5822qBgAAVEfV6n12AAAAyoqwAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATM00YWfu3Llq3Lix3N3dFR0drS+//NLRJQEAACdgirDz3nvvKSEhQdOnT9e+ffvUtm1bxcTE6MyZM44uDQAAOJgpws7LL7+scePGafTo0WrZsqXmz5+vWrVqaeHChY4uDQAAOFi1Dzu5ubnau3evevfubWtzcXFR7969lZKS4sDKAACAM6jh6AIq6ty5c8rPz5e/v79du7+/v77//vti18nJyVFOTo5tPjMzU5KUlZVVZXVeys+vsm0D1VlVvu5ul2s5lx1dAuCUqvr1Xbh9wzBu2q/ah53ySE5OVlJSUpH24OBgB1QD/MZ5ezu6AgBVxHvmmNuyn19++UXeN/ldUu3DToMGDeTq6qrTp0/btZ8+fVoBAQHFrpOYmKiEhATbfEFBgS5cuKD69evLYrFUab1wvKysLAUHB+unn36Sl5eXo8sBUIl4ff+2GIahX375RUFBQTftV+3Djpubm6KiorRhwwYNGDBA0q/hZcOGDZo0aVKx61itVlmtVru2unXrVnGlcDZeXl78MgRMitf3b8fNrugUqvZhR5ISEhIUHx+vDh06qGPHjpo9e7ays7M1evRoR5cGAAAczBRh54EHHtDZs2c1bdo0paenq127dlq9enWRQcsAAOC3xxRhR5ImTZpU4m0r4HpWq1XTp08vcisTQPXH6xvFsRi3el4LAACgGqv2byoIAABwM4QdAABgaoQdAABgaoQdAABgaoQd/KbMnTtXjRs3lru7u6Kjo/Xll186uiQAlWDLli3q16+fgoKCZLFYtGLFCkeXBCdC2MFvxnvvvaeEhARNnz5d+/btU9u2bRUTE6MzZ844ujQAFZSdna22bdtq7ty5ji4FTohHz/GbER0drbvuuktz5syR9OvHigQHB2vy5Mn6+9//7uDqAFQWi8WiTz75xPYRQgBXdvCbkJubq71796p37962NhcXF/Xu3VspKSkOrAwAUNUIO/hNOHfunPLz84t8hIi/v7/S09MdVBUA4HYg7AAAAFMj7OA3oUGDBnJ1ddXp06ft2k+fPq2AgAAHVQUAuB0IO/hNcHNzU1RUlDZs2GBrKygo0IYNG9SpUycHVgYAqGqm+dRz4FYSEhIUHx+vDh06qGPHjpo9e7ays7M1evRoR5cGoIIuXbqko0eP2ubT0tK0f/9++fj4qFGjRg6sDM6AR8/xmzJnzhzNnDlT6enpateunV577TVFR0c7uiwAFbRp0yb16NGjSHt8fLwWL158+wuCUyHsAAAAU2PMDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgCn0717dz366KOOLsPG2eoBUDaEHQCmlJub6+gSADgJwg4ApzJq1Cht3rxZr776qiwWiywWi1JTUzV27FiFhobKw8NDzZo106uvvlpkvQEDBujZZ59VUFCQmjVrJknasWOH2rVrJ3d3d3Xo0EErVqyQxWLR/v37bet+8803iouLU+3ateXv768//elPOnfuXIn1/Pjjj7frdACoBHzqOQCn8uqrr+rw4cNq3bq1nn76aUlSvXr1dMcdd+iDDz5Q/fr1tWPHDo0fP16BgYEaOnSobd0NGzbIy8tL69atkyRlZWWpX79+6tu3r5YtW6Zjx44VuR2VkZGhnj176i9/+YteeeUVXblyRVOnTtXQoUP1xRdfFFuPr6/v7TkZACoFYQeAU/H29pabm5tq1aqlgIAAW3tSUpLt69DQUKWkpOj999+3Czuenp5asGCB3NzcJEnz58+XxWLRG2+8IXd3d7Vs2VInTpzQuHHjbOvMmTNHkZGReu6552xtCxcuVHBwsA4fPqymTZsWWw+A6oOwA6BamDt3rhYuXKjjx4/rypUrys3NVbt27ez6RERE2IKOJB06dEht2rSRu7u7ra1jx45263z99dfauHGjateuXWSfqampatq0aeUeCIDbjrADwOktX75cjz32mF566SV16tRJderU0cyZM7Vr1y67fp6enmXe9qVLl9SvXz+98MILRZYFBgaWu2YAzoOwA8DpuLm5KT8/3za/fft2de7cWQ8//LCtLTU19ZbbadasmZYsWaKcnBxZrVZJ0u7du+36tG/fXh999JEaN26sGjWK/5V4Yz0AqheexgLgdBo3bqxdu3bpxx9/1Llz59SkSRPt2bNHa9as0eHDh/XUU08VCS3FGTFihAoKCjR+/Hh99913WrNmjWbNmiVJslgskqSJEyfqwoULGj58uHbv3q3U1FStWbNGo0ePtgWcG+spKCiouoMHUOkIOwCczmOPPSZXV1e1bNlSvr6+iomJ0aBBg/TAAw8oOjpa58+ft7vKUxIvLy+tWrVK+/fvV7t27fTPf/5T06ZNkyTbOJ6goCBt375d+fn56tOnjyIiIvToo4+qbt26cnFxKbae48ePV93BA6h0FsMwDEcXAQC3y9KlSzV69GhlZmbKw8PD0eUAuA0YswPA1N5++22FhYWpYcOG+vrrr23voUPQAX47CDsATC09PV3Tpk1Tenq6AgMDNWTIED377LOOLgvAbcRtLAAAYGoMUAYAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKb2/wEHBOwxHb8P+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sns.countplot(data=train.toPandas(), x='target')\n",
    "plt.title(\"Target Variable Distribution Within Train Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----+-------------------+-------------------+-----------------+-----------------+\n",
      "|index                             |0    |1                  |2                  |3                |4                |\n",
      "+----------------------------------+-----+-------------------+-------------------+-----------------+-----------------+\n",
      "|summary                           |count|mean               |stddev             |min              |max              |\n",
      "|sex                               |447  |0.6868008948545862 |0.4643142522497525 |0                |1                |\n",
      "|resting_blood_pressure            |447  |131.40939597315437 |17.289806254177034 |94               |200              |\n",
      "|rest_ecg_type                     |447  |0.4899328859060403 |0.5004587536405618 |0                |1                |\n",
      "|max_heart_rate_achieved           |447  |148.48322147651007 |23.25668929090527  |71               |202              |\n",
      "|exercise_induced_angina           |447  |0.319910514541387  |0.4669642356279164 |0                |1                |\n",
      "|st_depression                     |447  |1.0342954569152438 |1.081581962513034  |0.0              |6.199999809265137|\n",
      "|num_major_vessels                 |447  |0.6666666666666666 |0.9270877945342015 |0                |3                |\n",
      "|vessels_coloured                  |447  |0.3959731543624161 |0.48960666852143203|0                |1                |\n",
      "|chest_pain_type_asymptomatic      |447  |0.49217002237136465|0.5004988432592138 |0                |1                |\n",
      "|chest_pain_type_non-anginal_pain  |447  |0.25727069351230425|0.4376196063183999 |0                |1                |\n",
      "|st_slope_type_upsloping           |447  |0.41834451901565994|0.4938400254400386 |0                |1                |\n",
      "|thalassemia_type_reversible_defect|447  |0.378076062639821  |0.4854500602715446 |0                |1                |\n",
      "|resting_blood_pressure_log        |447  |4.870193653457915  |0.12838059391385961|4.543294782270004|5.298317366548036|\n",
      "|target                            |447  |0.5100671140939598 |0.5004587536405617 |0                |1                |\n",
      "|partition                         |447  |NULL               |NULL               |test             |train            |\n",
      "+----------------------------------+-----+-------------------+-------------------+-----------------+-----------------+\n",
      "\n",
      "None\n",
      "root\n",
      " |-- sex: long (nullable = true)\n",
      " |-- resting_blood_pressure: long (nullable = true)\n",
      " |-- rest_ecg_type: long (nullable = true)\n",
      " |-- max_heart_rate_achieved: long (nullable = true)\n",
      " |-- exercise_induced_angina: long (nullable = true)\n",
      " |-- st_depression: double (nullable = true)\n",
      " |-- num_major_vessels: long (nullable = true)\n",
      " |-- vessels_coloured: long (nullable = true)\n",
      " |-- chest_pain_type_asymptomatic: long (nullable = true)\n",
      " |-- chest_pain_type_non-anginal_pain: long (nullable = true)\n",
      " |-- st_slope_type_upsloping: long (nullable = true)\n",
      " |-- thalassemia_type_reversible_defect: long (nullable = true)\n",
      " |-- resting_blood_pressure_log: double (nullable = true)\n",
      " |-- target: long (nullable = true)\n",
      " |-- partition: string (nullable = false)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Add a \"partition\" column to train and test DataFrames\n",
    "train = train.withColumn(\"partition\", lit(\"train\"))\n",
    "test = test.withColumn(\"partition\", lit(\"test\"))\n",
    "\n",
    "heart = train.unionByName(test)\n",
    "\n",
    "\n",
    "print(spark.createDataFrame(heart.describe().toPandas().transpose().reset_index()).show(truncate=False))\n",
    "print(heart.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- resting_blood_pressure: integer (nullable = true)\n",
      " |-- rest_ecg_type: integer (nullable = true)\n",
      " |-- max_heart_rate_achieved: integer (nullable = true)\n",
      " |-- exercise_induced_angina: integer (nullable = true)\n",
      " |-- st_depression: float (nullable = true)\n",
      " |-- num_major_vessels: integer (nullable = true)\n",
      " |-- vessels_coloured: integer (nullable = true)\n",
      " |-- chest_pain_type_asymptomatic: integer (nullable = true)\n",
      " |-- chest_pain_type_non-anginal_pain: integer (nullable = true)\n",
      " |-- st_slope_type_upsloping: integer (nullable = true)\n",
      " |-- thalassemia_type_reversible_defect: integer (nullable = true)\n",
      " |-- resting_blood_pressure_log: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- partition: string (nullable = false)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "float_cols = [\"st_depression\"]\n",
    "\n",
    "string_cols = ['partition']\n",
    "\n",
    "for column in [col for col in float_cols]:\n",
    "    heart = heart.withColumn(column, heart[column].cast('float'))\n",
    "\n",
    "for column in [col for col in string_cols]:\n",
    "    heart = heart.withColumn(column, heart[column].cast('string'))\n",
    "\n",
    "for column in [col for col in heart.columns if (col not in float_cols) and (col not in string_cols)]:\n",
    "    heart = heart.withColumn(column, heart[column].cast('int'))\n",
    "\n",
    "print(heart.printSchema())\n",
    "\n",
    "heart.toPandas().to_csv(\"prepared_heart_data.csv\", index=False, header=heart.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9f522c2947469c96a6c2f4e8114293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5985ee3c3ac647e8a0c6285a17fc9109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ed5400a4b7492cbdc4469e5fdb700b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934e6b5810b34bbb90c74dba5c2266af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d6759f6f7044f6aaebd92f660d4025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9199f6a606d42c1adab8e9933b765b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5b2012623248b6bc4b41922bfc062e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ddc29019b94ecc878d9b77165887b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 01:07:39 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 255861 ms exceeds timeout 120000 ms\n",
      "23/10/12 01:07:39 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/10/12 01:07:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:07:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:07:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:07:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:07:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:07:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:08:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:08:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:08:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:08:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:25:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:25:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:25:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:25:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:26:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:27:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:27:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:27:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:27:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:44:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:44:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:44:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:58:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:58:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:59:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:59:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:59:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:59:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:59:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:59:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 01:59:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 01:59:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:14:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:14:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:14:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:14:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:15:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:15:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:15:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:15:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:15:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:15:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:15:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:15:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:27:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:27:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:27:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:27:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:27:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:27:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:27:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:27:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:27:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:27:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:44:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:44:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:44:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:44:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:45:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:45:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:45:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:45:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 02:45:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:45:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:59:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:59:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:59:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 02:59:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:00:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:00:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:00:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:00:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:15:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:16:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:16:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:16:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:16:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:16:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:16:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:33:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:33:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:33:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 03:33:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 03:33:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:33:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:33:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:33:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:51:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:51:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:51:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 03:51:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 03:51:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:51:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:51:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:51:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/12 03:52:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 03:52:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.8:60734\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/12 03:52:05 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 60745)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/stephen/Library/Python/3.9/lib/python/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/stephen/Library/Python/3.9/lib/python/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/Users/stephen/Library/Python/3.9/lib/python/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/stephen/Library/Python/3.9/lib/python/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_report = ProfileReport(train.toPandas())\n",
    "test_report = ProfileReport(test.toPandas())\n",
    "train_report.to_file(\"final_train.html\")\n",
    "test_report.to_file(\"final_test.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
